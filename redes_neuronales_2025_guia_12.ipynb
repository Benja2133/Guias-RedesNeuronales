{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRYEofSD0xoF"
   },
   "source": [
    "# PyTorch: Autoencoder convolucional Fashion-MNIST\n",
    "\n",
    "## Refs.\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "\n",
    "* https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "* https://github.com/pranay414/Fashion-MNIST-Pytorch/blob/master/fashion_mnist.ipynb\n",
    "\n",
    "## **Ejercicio 1)** Importando librerías\n",
    "\n",
    "**0)** De ser necesario, **instale PyTorch** escribiendo\n",
    "\n",
    "    !pip3 install torch torchvision torchaudio torchviz\n",
    "\n",
    "**1)** Importe las librerías estandard de Python: `os`, `datetime`, `collections` y `pickle`.\n",
    "\n",
    "**2)** Importe las siguientes librerías third party de Python: `matplotlib.pyplot`, `numpy`, `scipy`, `sklearn`, `pandas`, `dill` y `json`.\n",
    "\n",
    "**3)** Importe las librerias necesarias de **PyTorch**: `torch` y `torchvision`.\n",
    "\n",
    "**4)** Importe la librería: `google.colab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multiprocessing\n",
    "#multiprocessing.set_start_method(\"spawn\", force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jg3VSqHCGSub",
    "outputId": "45f624ae-5aa6-49e2-9116-c43b311bf3f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /home/benjamin/.local/lib/python3.10/site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in /home/benjamin/.local/lib/python3.10/site-packages (0.22.1+cu118)\n",
      "Requirement already satisfied: torchaudio in /home/benjamin/.local/lib/python3.10/site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.8.87)\n",
      "Requirement already satisfied: jinja2 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (10.3.0.86)\n",
      "Requirement already satisfied: networkx in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: fsspec in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.7.5.86)\n",
      "Requirement already satisfied: filelock in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.4.1.48)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.8.86)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/lib/python3/dist-packages (from triton==3.3.1->torch) (59.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in /home/benjamin/.local/lib/python3.10/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/benjamin/.local/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/benjamin/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# 1.0)\n",
    "#!pip3 install torch torchvision torchaudio torchviz\n",
    "# ¡Instalación con Pip apuntando directamente a la versión 11.8!\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "I8N3D_nU1_oT"
   },
   "outputs": [],
   "source": [
    "# 1.1)\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "QsfFvPYhkCGl"
   },
   "outputs": [],
   "source": [
    "# 1.2)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg as linalg\n",
    "#import sklearn as skl\n",
    "import pandas as pd\n",
    "#import dill\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "Uot5sVNnkCNa"
   },
   "outputs": [],
   "source": [
    "# 1.3\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "#from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "rVCiYt-1kCUi"
   },
   "outputs": [],
   "source": [
    "# 1.4)\n",
    "#import google.colab\n",
    "#from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "oUFvWw_kr7Bt",
    "outputId": "44d01453-6867-4827-cae1-5091bb2bf694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcaGEHAd10sb"
   },
   "source": [
    "## **Ejercicio 2)**\n",
    "\n",
    "Bajando y Jugando con el dataset **Fashion-MNIST**.\n",
    "\n",
    "**1)** Baje y transforme los conjuntos de entrenamiento y testeo de FashionMNIST.\n",
    "\n",
    "**2)** Grafique un mosaico de 3x3 imagenes de FashionMNIST, cada una titulada con su respectiva clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUoQ9bnwaZ7O",
    "outputId": "ad7eff68-8c23-4f71-eb71-2f1179f4e38b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 2.1)\\n# Define a transform to normalize the data\\ntransform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\\n\\n# Download and load the training data\\ntrain_set_orig = datasets.FashionMNIST('MNIST_data/', download = True, train = True,  transform = transform)\\nvalid_set_orig = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)\\n\\n\\nprint(len(train_set_orig))  # 60000\\nprint(len(valid_set_orig))        # 10000\""
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 2.1)\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data\n",
    "train_set_orig = datasets.FashionMNIST('MNIST_data/', download = True, train = True,  transform = transform)\n",
    "valid_set_orig = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)\n",
    "\n",
    "\n",
    "print(len(train_set_orig))  # 60000\n",
    "print(len(valid_set_orig))        # 10000'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "'''from torch.utils.data import random_split, ConcatDataset\n",
    "\n",
    "# Cargar ambos conjuntos completos (70.000)\n",
    "train_full = datasets.FashionMNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "test_full  = datasets.FashionMNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "\n",
    "# Unimos todo en un único dataset\n",
    "full_dataset = ConcatDataset([train_full, test_full])\n",
    "total = len(full_dataset)  # 70000\n",
    "\n",
    "# Definir proporciones (por ej: 85% train, 15% valid)\n",
    "#train_size = int(0.85 * total)  # 59500 aprox\n",
    "#valid_size = total - train_size # 10500 aprox\n",
    "\n",
    "train_size = 40000 # 59500 aprox\n",
    "valid_size = total - train_size # 10500 aprox\n",
    "\n",
    "train_set, valid_set = random_split(full_dataset, [train_size, valid_size])\n",
    "\n",
    "print(len(train_set))   # ~59500\n",
    "print(len(valid_set))   # ~10500'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "-wJdl9mKx5EC",
    "outputId": "ea41b46d-7034-43df-f087-bb7c1803b254"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2.2)\n",
    "figure = plt.figure()\n",
    "cols,rows = 3,3\n",
    "for i in range(1,cols*rows+1):\n",
    "    j = torch.randint(len(train_set_orig),size=(1,)).item() # Los números aleatorios tambien se pueden generar desde pytorch. Util para trabajar en la GPU.\n",
    "    image,label = train_set_orig[j]\n",
    "    figure.add_subplot(rows,cols,i)\n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")  \n",
    "    #plt.title(labels_names[label])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OWYnfxWz8RS"
   },
   "source": [
    "## Ejercicio 3) Creando un `DataSet` personalizado.\n",
    "\n",
    "**1)** Con el fin de implementar un autoencoder, cree una clase derivada de la clase `DataSet` (llámela, por ejemplo `CustomDataset`) que, en vez de retornal el label asociado a cada imagen de `FashionMNIST`, retorne la imagen misma.\n",
    "\n",
    "**2)** Utilice dicha clase para transformar los conjuntos de entrenamiento y testeo de `FashionMNIST` pensados para clasificación, a correspondientes conjuntos pensados para entrenar un autoencoder.\n",
    "Para ello, defina una clase `CustomDataset` que deriva de la clase `Dataset`, cuyo método `__getitem__(self,i)` retorne el pair `input,output` donde tanto `input` cómo `output` son iguales a la $i$-ésima imagen del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "sPjO1_Av1f87"
   },
   "outputs": [],
   "source": [
    "# 3.1)\n",
    "# Creamos una subclase de la clase Dataset que nos sirva para generar lotes de ejemplos que puedan usarse para entrenar un autoencoder\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset=dataset\n",
    "    # Redefinimos el método .__len__()\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    # Redefinimos el método .__getitem__()\n",
    "    def __getitem__(self,i):\n",
    "        image,label=self.dataset[i]\n",
    "        input  = image\n",
    "        output = image #torch.flatten(image) # retornamos la imagen como salida\n",
    "        return input,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "EbMUnqwU19gL"
   },
   "outputs": [],
   "source": [
    "# 3.2)\n",
    "# Convertimos FashionMNIST Dataset a CustomDataset\n",
    "train_set = CustomDataset(train_set_orig)\n",
    "valid_set = CustomDataset(valid_set_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKpx5sTuPJdk"
   },
   "source": [
    "## Ejercicio 4) Red Neuronal Autoencoder Convolucional\n",
    "\n",
    "**1)** Defina y cree una red neuronal *autoencoder convolucional* constituida por las siguientes capas:\n",
    "\n",
    "\n",
    "1. Capa convolucional 2D (encoder) compuesta por:\n",
    "\n",
    "  * Una capa `Conv2d` (ver [documentación](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)) que mapea una entrada con $1$ canal y dimensiones $(28,28)$ a una salida con $16$ canales y dimensiones $(26,26)$.\n",
    "    Utilice un kernel de dimensiones $(3,3)$ y el resto de los parámetros en sus valores por defecto.\n",
    "  * Una capa `ReLU`.\n",
    "  * Una capa `MaxPool2d` con un kernel de dimensiones $(2,2)$, de modo que la salida resultante tenga dimensiones $(16,13,13)$.\n",
    "  * Una capa `Dropout` con probabilidad $p$.\n",
    "\n",
    "2. Capa lineal (cuello de botella o “bottleneck”) compuesta por:\n",
    "\n",
    "  * Una capa `Flatten` que transforma una entrada de dimensiones $(16,13,13)$ en un vector de dimensión $16\\times 13\\times 13 = 2704$.\n",
    "  * Una capa `Linear` que mapea el vector de dimensión $2704$ a un vector de dimensión $n$ (donde $n$ es un número mucho menor, por ejemplo $n=128$, representando la *codificación comprimida* o *latente*).\n",
    "  * Una capa `ReLU`.\n",
    "  * Una capa `Linear` que mapea de nuevo el vector de dimensión $n$ al espacio original de dimensión $2704$.\n",
    "  * Una capa `ReLU`.\n",
    "\n",
    "3. Capa convolucional 2D transpuesta (decoder) compuesta por:\n",
    "\n",
    "  * Una capa `Unflatten` que mapea el vector de dimensión $2704$ a una representación de $16$ canales con dimensiones $(13,13)$.\n",
    "  * Una capa `ConvTranspose2d` (ver [documentación](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html)) que mapea $16$ canales de dimensiones $(13,13)$ a $1$ canal de dimensiones $(28,28)$. Utilice un kernel de dimensiones $(6,6)$, un stride de $(2,2)$, y un padding de $(1,1)$.\n",
    "  * Una capa `Sigmoid`, para asegurar que las salidas se encuentren en el rango $[0,1]$ (asumiendo que las imágenes originales también fueron normalizadas en dicho rango).\n",
    "\n",
    "**2)** Grafique, a modo de comparación, algunas imágenes de entrada y sus correspondientes reconstrucciones obtenidas con el modelo **sin entrenar** y con una probabilidad de *dropout* $p=0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "qSJqCozXCEq1"
   },
   "outputs": [],
   "source": [
    "# 4.1)\n",
    "''''''\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,n,p=0.2):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        #capa0 : convolucional 2D\n",
    "        self.conv0 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)  #De 28x28x1 a 26x26x16. Son 16 filtros convolucionales. Cada filtro extrae una característica diferente. \n",
    "        #Si aca usamos padding=1, la salida sería 28x28x16 pues mantenemos las dimensiones espaciales debido a que el padding lo que hace es agregar una capa de ceros alrededor de la imagen.\n",
    "        # Y si aca usamos stride=2, la salida sería 13x13x16, pues reducimos las dimensiones espaciales a la mitad. Ya que stride=2 significa que el filtro se mueve de a 2 pixeles en cada paso con lo cual se reduce la resolución espacial.\n",
    "        # Si el tamaño del kernel aumentara a 5, la salida sería 24x24x16, pues el tamaño del kernel afecta las dimensiones espaciales de la salida.\n",
    "        self.relu = nn.ReLU() \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #Reducción de dimensionalidad: de 26x26 a 13x13, canales siguen siendo 16. \n",
    "        self.dropout = nn.Dropout(p) \n",
    "\n",
    "        #capa 1 : bottleneck\n",
    "        self.flatten = nn.Flatten()#start_dim=(16,13,13)) #De 16x13x13 a 2704\n",
    "        self.fc2_0 = nn.Linear(16*13*13,n)  #de 2704 a n, codificación \n",
    "        #relu\n",
    "        self.fc2_1 = nn.Linear(n,16*13*13)  #de n a 2704, decodificación\n",
    "        #relu\n",
    "\n",
    "        #capa 2\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(16,13,13)) #de 2704 a 16x13x13\n",
    "        self.convtr2 = nn.ConvTranspose2d(in_channels=16, out_channels=1, kernel_size=6,stride= 2, padding=1)  #de 16x13x13 a 28x28x1, son 28 porque usamos stride=2, que duplica las dimensiones espaciales.\n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "    \n",
    "    def forward(self,x):\n",
    "        #capa0\n",
    "        x = self.conv0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        #capa1\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc2_0(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.fc2_1(x)\n",
    "        x = self.relu(x)\n",
    "        #capa2\n",
    "        x = self.unflatten(x)\n",
    "        x = self.convtr2(x)\n",
    "        x = self.sigmoid(x)\n",
    "                    \n",
    "        return x\n",
    "\n",
    "mi_red = NeuralNetwork(128,p=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass NeuralNetwork(nn.Module):\\n    def __init__(self, n, p=0.2):\\n        super(NeuralNetwork, self).__init__()\\n\\n         # Encoder convolucional\\n        self.encoder = nn.Sequential(\\n            nn.Conv2d(1, 16, 3, padding=1),\\n            nn.ReLU(),\\n            nn.MaxPool2d(2,2),  # -> 14x14\\n            nn.Dropout(p),\\n\\n            nn.Conv2d(16, 32, 3, padding=1),\\n            nn.ReLU(),\\n            nn.MaxPool2d(2,2),  # -> 7x7\\n            nn.Dropout(p),\\n        )\\n\\n        self.flatten = nn.Flatten()\\n\\n        # Bottleneck\\n        self.fc_enc = nn.Linear(32*7*7, n)\\n        self.fc_dec = nn.Linear(n, 32*7*7)\\n        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32,7,7)) #de 2704 a 32x7x7\\n\\n        # Decoder convolucional\\n        self.decoder = nn.Sequential(\\n            nn.ConvTranspose2d(32, 16, 2, stride=2),  # -> 16x14x14\\n            nn.ReLU(),\\n            nn.ConvTranspose2d(16, 1, 2, stride=2),   # -> 1x28x28\\n            nn.Sigmoid()\\n        )\\n\\n    def forward(self, x):\\n        x = self.encoder(x)\\n        x = self.flatten(x)\\n        x = self.fc_enc(x)\\n        x = self.fc_dec(x)\\n        x = self.unflatten(x)\\n        x = self.decoder(x)\\n\\n        return x\\n\\n\\nmi_red = NeuralNetwork(128,p=0.2)\\n'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1)\n",
    "'''\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n, p=0.2):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "         # Encoder convolucional\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),  # -> 14x14\n",
    "            nn.Dropout(p),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),  # -> 7x7\n",
    "            nn.Dropout(p),\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Bottleneck\n",
    "        self.fc_enc = nn.Linear(32*7*7, n)\n",
    "        self.fc_dec = nn.Linear(n, 32*7*7)\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32,7,7)) #de 2704 a 32x7x7\n",
    "\n",
    "        # Decoder convolucional\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 2, stride=2),  # -> 16x14x14\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 2, stride=2),   # -> 1x28x28\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_enc(x)\n",
    "        x = self.fc_dec(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "mi_red = NeuralNetwork(128,p=0.2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9uINlg69OTw"
   },
   "source": [
    "## Ejercicio 5) Entrenando el modelo\n",
    "\n",
    "**1)** Implemente, en una función, un loop de entrenamiento que recorra los batchs (lotes).\n",
    "\n",
    "**2)** Implemente, en una función, un loop de prueba o validación que recorra los batchs.\n",
    "\n",
    "**3)** Inicialize dos `DataLoader`s llamados `train_loader` y `valid_loader` que estén definidos sobre  el `train_set` (conjunto de entranmiento) y el `valid_set` (conjunto de prueba) de Fashion-MNIST, respectivamente, y que usen batchs de 100 ejemplos.\n",
    "\n",
    "**4)** Cree una función de pérdida usando el **Error Cuadrático Medio**.\n",
    "\n",
    "**5)** Cree un optimizador con un learning rate igual a $10^{-3}$.\n",
    "Pruebe con **ADAM**.\n",
    "\n",
    "**6)** Cree una instancia del modelo con dropout $p=0.2$.\n",
    "\n",
    "**7)** Especifique en que dispositivo (`device`) va a trabajar: en una **CPU** o en una **GPU**.\n",
    "\n",
    "**8)** Implemente un loop que itere sobre épocas de entrenamiento y validación, y que guarde en listas correspondientes los siguientes valores del **ECM**:\n",
    "*  promedios (incorrectos) sobre el conjunto de entrenamiento, calculado **durante** el proceso de entrenamiento sobre la época.\n",
    "*  promedios (correctos) sobre el conjunto de entrenamiento, calculados **posteriormente** al proceso de entrenamiento sobre la época.\n",
    "*  promedios (correctos) sobre el conjunto de validación, calculados **posteriormente** al proceso de entrenamiento sobre la época.\n",
    "\n",
    "**IMPORTANTE:** No olvide copiar los batchs al dispositivo de trabajo.\n",
    "\n",
    "**9)** Entrene y valide el modelo.\n",
    "\n",
    "**10)** Use las listas del inciso **8)** para graficar en función de las **épocas de entrenamiento** el **ECM** de **entrenamiento** y **validación**, respectivamente.\n",
    "Discuta y comente, cual es el número óptimo de épocas de entrenamiento?\n",
    "\n",
    "**11)** Grafique, comparativamente, algunas de las imagenes a predecir vs las imagenes predichas por el modelo entrenado.\n",
    "\n",
    "**12)** Repita para otras elecciones de los hiperparámetros tales como, el optimizador (podría ser el **SGD**), el **learning-rate**, el tamaño de los **batchs**, el **dropout**, **capas convolucionales** y **convolucionales traspuestas** de otros tamaños.\n",
    "En particular, pruebe eliminando, adecuadamente, la **capa lineal**.\n",
    "Que valores de estos hiperparámetros considera los más convenientes? Porqué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1)\n",
    "def train_loop(dataloader,model,loss_fn,optimizer):\n",
    "    model.train()\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    sum_loss = 0\n",
    "    sum_correct = 0\n",
    "    sum_samples = 0\n",
    "    for batch, (X,y) in enumerate(dataloader): \n",
    "        #enumerate devuelve una lista de tuplas (indice, valor), entonces al hacer\n",
    "        # for batch, (X,y) desestructura la tupla en indice(batch) y valor(X(imagenes), y(etiquetas))\n",
    "\n",
    "        # Copiamos las salidas y entradas al dispositivo de trabajo\n",
    "        X, y = X.to(device,non_blocking=True), y.to(device,non_blocking=True)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        batch_size = len(X)\n",
    "        # calculamos la perdida promedio del batch y lo agregamos a una suma correspondiente\n",
    "        sum_loss += loss.item() * batch_size # loss = suma de perdidas en el batch / batch_size => loss.item() * batch_size = suma de perdidas en el batch\n",
    "\n",
    "        # En este caso no tiene sentido calcular la cantidad de predicciones correctas porque es un autoencoder y no una tarea de clasificación\n",
    "        #sum_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        # actualizamos la cantidad de muestras procesadas\n",
    "        sum_samples += batch_size\n",
    "\n",
    "        #if batch % (num_batches / 10) == 0: # evaluamos en el 10% de los batches, para no saturar\n",
    "        avrg_loss = sum_loss / sum_samples\n",
    "        # precision = sum_correct / sum_samples\n",
    "        print(f\"  Batch {batch:>5d}/{num_batches:>5d} - avrg_Loss: {avrg_loss:>7f}  processed_samples: {100*sum_samples/num_samples:>5f}%\") #5d ?\n",
    "        \n",
    "    assert num_samples == sum_samples, \"Error en el conteo de muestras procesadas\"\n",
    "    avrg_loss = sum_loss / sum_samples\n",
    "    #precision = sum_correct / sum_samples\n",
    "\n",
    "    return avrg_loss #, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2)\n",
    "def valid_loop(dataloader,model,loss_fn):\n",
    "    model.eval()\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    sum_loss = 0\n",
    "    sum_correct = 0\n",
    "    sum_samples = 0\n",
    "    with torch.no_grad(): # es un context manager que desactiva el cálculo del gradiente momentáneamente, \n",
    "        #para ahorrar memoria y mejorar el rendimiento durante la evaluación del modelo.\n",
    "\n",
    "        for X,y in dataloader: #iteramos sobre los batches del dataloader, esto es posible ya que si bien dataloader no es una lista,\n",
    "            # implementa el protocolo iterable de python, por lo que se puede usar en un for, y en cada iteracion genera un batch nuevo\n",
    "\n",
    "            # Copiamos las salidas y entradas al dispositivo de trabajo\n",
    "            X, y = X.to(device,non_blocking=True), y.to(device,non_blocking=True)\n",
    "            batch_size = len(X)\n",
    "            sum_samples += batch_size\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            sum_loss += loss.item() * batch_size\n",
    "            #sum_correct += (pred.argmax(1) == y).type(tor ch.float).sum().item()\n",
    "    \n",
    "    assert num_samples == sum_samples, \"Error en el conteo de muestras procesadas\"\n",
    "    avrg_loss = sum_loss / sum_samples\n",
    "    #precision = sum_correct / sum_samples\n",
    "    print(f\"@eval_loop_avg_loss={avrg_loss:>8f}\") #, precision={100*precision:0.1f}%\")\n",
    "\n",
    "    return avrg_loss #, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3)\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True,num_workers=8, pin_memory=True,persistent_workers=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size = batch_size, shuffle = True,num_workers=8, pin_memory=True,persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.4)\n",
    "#Creamos una instancia de una funcion de perdida, en este caso error cuadratico medio\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.6)\n",
    "#valores segun ej4\n",
    "n = 128\n",
    "p = 0.2\n",
    "model = NeuralNetwork(n, p = p)\n",
    "\n",
    "#5.5)\n",
    "#definimos el optimizador, en este caso SGD\n",
    "learning_rate = 1e-3\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#5.7)\n",
    "#definimos el dispositivo de trabajo, una cpu o una gpu si esta disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#pasamos el modelo al dispositivo\n",
    "model = model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 1.354411  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 1.286679  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 1.245076  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 1.192572  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 1.145450  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 1.104783  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 1.068182  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 1.033832  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 1.002825  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.975342  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.951771  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.930135  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.910674  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.894137  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.879849  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.867505  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.856443  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.846729  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.837681  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.829849  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.822565  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.816457  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.810045  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.804650  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.800183  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.795980  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.791151  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.787251  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.783394  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.779649  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.776267  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.773399  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.770808  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.768279  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.765359  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.763255  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.760788  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.758674  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.756513  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.754550  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.752798  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.750874  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.749256  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.747536  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.746231  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.744772  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.743473  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.742216  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.740871  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.739787  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.738534  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.737544  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.736178  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.734949  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.733872  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.733134  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.731999  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.730897  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.729994  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.729254  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.728379  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.727594  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.726951  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.726311  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.725704  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.724969  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.724238  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.723505  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.722670  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.722091  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.721467  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.720778  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.720217  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.719587  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.719034  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.718541  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.718067  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.717632  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.717113  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.716687  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.716204  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.715557  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.715122  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.714662  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.714225  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.713659  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.713210  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.712729  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.712360  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.711874  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.711525  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.711077  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.710555  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.710236  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.709893  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.709531  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.709211  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.708873  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.708545  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.708179  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.707988  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.707664  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.707297  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.706963  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.706696  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.706562  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.706284  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.706020  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.705708  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.705500  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.705239  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.704895  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.704606  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.704338  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.704075  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.703930  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.703708  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.703490  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.703152  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.702863  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.702631  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.702415  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.702175  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.701843  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.701698  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.701519  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.701257  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.701136  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.700944  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.700812  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.700608  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.700414  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.700270  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.699990  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.699818  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.699599  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.699484  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.699337  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.699185  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.699006  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.698841  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.698682  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.698475  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.698300  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.698156  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.697931  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.697699  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.697617  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.697461  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.697352  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.697118  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.697012  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.696890  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.696771  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.696599  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.696494  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.696416  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.696244  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.696141  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.695980  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.695881  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.695651  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.695562  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.695500  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.695296  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.695057  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.694955  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.694803  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.694736  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.694615  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.694487  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.694375  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.694211  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.694122  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.694041  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.693987  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.693874  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.693832  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.693711  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.693649  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.693512  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.693273  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.693153  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.692950  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.692847  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.692701  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.692561  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.692443  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.692313  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.692182  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.692041  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.691951  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.691894  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.691776  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.691724  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.691638  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.691510  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.691445  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.691426  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.691338  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.691273  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.691173  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.691045  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.690908  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.690761  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.690690  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.690638  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.690556  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.690498  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.690429  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.690353  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.690318  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.690250  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.690094  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.690024  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.689984  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.689933  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.689842  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.689796  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.689748  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.689631  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.689527  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.689393  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.689358  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.689232  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.689190  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.689113  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.688995  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.688894  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.688808  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.688755  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.688666  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.688574  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.688496  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.688466  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.672381\n",
      "@eval_loop_avg_loss=0.669447\n",
      "Epoch 2/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.652957  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.661756  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.664935  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.670999  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.673085  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.672504  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.672260  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.671655  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.672672  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.672436  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.672272  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.673113  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.672964  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.673792  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.674056  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.674487  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.673790  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.673085  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.672694  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.672065  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.672275  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.671708  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.671782  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.671758  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.671860  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.671453  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.671357  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.671728  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.672132  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.672049  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.672167  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.672394  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.672425  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.672125  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.672126  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.671962  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.671855  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.671702  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.671813  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.671518  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.671377  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.671328  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.671284  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.671471  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.671516  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.671530  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.671790  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.671658  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.671725  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.671737  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.671878  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.671643  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.671572  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.671141  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.671119  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.671205  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.671191  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.671310  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.671471  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.671452  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.671468  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.671322  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.671064  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.671174  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.671180  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.671153  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.671116  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.671124  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.671070  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.671013  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.670915  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.670964  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.670957  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.671011  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.671053  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.671246  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.671102  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.671130  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.671073  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.671132  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.671049  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.671225  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.671077  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.671093  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.671153  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.671129  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.671163  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.671113  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.671034  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.671039  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.671059  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.671025  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.671072  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.670979  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.671011  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.671065  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.671005  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.670965  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.671033  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.670930  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.671039  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.671121  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.671111  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.671173  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.671054  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.671065  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.670931  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.670940  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.670851  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.670772  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.670826  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.670844  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.670931  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.671015  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.670867  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.670843  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.670862  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.670843  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.670833  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.670869  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.670856  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.670771  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.670735  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.670774  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.670750  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.670682  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.670736  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.670764  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.670805  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.670962  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.670898  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.670942  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.670922  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.670937  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.670924  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.670896  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.670914  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.670873  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.670862  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.670787  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.670803  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.670868  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.670857  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.670943  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.670862  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.670820  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.670927  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.670989  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.670996  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.670995  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.670961  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.670967  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.670932  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.670893  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.670901  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.670947  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.670851  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.670827  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.670818  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.670816  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.670803  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.670796  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.670776  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.670763  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.670761  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.670802  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.670826  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.670750  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.670809  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.670801  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.670781  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.670783  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.670801  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.670774  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.670743  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.670725  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.670788  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.670831  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.670750  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.670714  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.670664  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.670648  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.670621  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.670575  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.670669  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.670668  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.670660  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.670638  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.670599  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.670685  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.670661  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.670677  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.670657  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.670594  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.670581  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.670578  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.670586  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.670554  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.670578  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.670597  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.670604  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.670572  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.670594  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.670603  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.670604  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.670642  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.670688  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.670656  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.670652  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.670635  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.670572  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.670507  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.670475  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.670504  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.670502  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.670441  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.670431  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.670519  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.670505  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.670502  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.670412  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.670476  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.670470  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.670506  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.670532  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.670490  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.670542  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.670574  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.670528  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.670568  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.670566  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.670489  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.670485  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.670522  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.670556  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.668647\n",
      "@eval_loop_avg_loss=0.665763\n",
      "Epoch 3/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.674628  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.666975  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.661359  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.663152  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.662829  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.666127  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.665578  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.667010  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.666332  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.666579  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.666559  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.667961  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.667006  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.666004  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.666541  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.666245  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.667010  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.666915  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.667573  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.667590  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.667492  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.666667  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.666064  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.666318  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.666712  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.666908  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.666870  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.666761  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.666604  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.666319  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.666021  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.666328  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.666607  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.666903  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.666495  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.666813  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.667012  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.667340  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.667513  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.667265  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.667378  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.667544  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.667506  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.667351  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.667235  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.667431  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.667494  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.667518  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.667369  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.667268  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.667315  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.667292  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.667366  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.667327  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.667462  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.667404  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.667591  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.667597  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.667565  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.667512  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.667734  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.667754  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.667898  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.667893  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.667874  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.668048  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.668401  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.668431  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.668250  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.668237  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.668333  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.668206  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.668284  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.668352  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.668378  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.668317  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.668104  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.668018  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.667970  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.667971  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.667872  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.667853  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.667848  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.667794  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.667944  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.667719  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.667747  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.667692  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.667724  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.667738  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.667621  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.667693  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.667489  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.667424  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.667499  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.667467  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.667281  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.667219  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.667122  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.667132  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.667033  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.667046  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.667132  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.667117  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.667188  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.667209  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.667252  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.667206  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.667204  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.667094  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.666961  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.666965  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.666923  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.666758  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.666796  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.666861  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.666826  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.666728  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.666794  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.666793  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.666713  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.666667  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.666658  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.666653  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.666618  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.666614  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.666495  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.666381  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.666387  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.666272  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.666337  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.666299  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.666135  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.666039  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.665967  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.665892  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.665811  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.665851  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.665670  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.665547  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.665457  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.665324  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.665175  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.665054  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.664893  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.664866  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.664703  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.664626  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.664472  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.664292  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.664050  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.663897  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.663741  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.663563  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.663488  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.663376  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.663269  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.663144  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.662941  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.662725  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.662630  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.662469  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.662216  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.661982  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.661710  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.661459  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.661265  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.660964  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.660646  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.660492  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.660375  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.660247  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.659971  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.659823  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.659662  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.659417  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.659207  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.659000  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.658790  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.658570  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.658368  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.658186  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.657923  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.657704  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.657559  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.657293  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.657093  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.656903  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.656678  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.656511  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.656279  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.656099  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.655911  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.655754  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.655547  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.655296  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.655072  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.654772  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.654573  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.654332  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.654180  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.653979  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.653776  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.653533  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.653371  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.653189  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.652990  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.652749  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.652449  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.652274  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.652122  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.651912  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.651765  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.651606  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.651419  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.651231  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.651051  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.650904  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.650781  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.650580  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.650380  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.650157  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.649946  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.649783  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.649631  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.649439  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.649224  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.649054  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.648907  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.648716  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.648531  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.648353  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.648200  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.648050  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.648017  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.606060\n",
      "@eval_loop_avg_loss=0.603598\n",
      "Epoch 4/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.611153  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.608240  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.602996  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.605915  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.607229  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.608253  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.610305  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.608612  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.608334  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.608237  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.607847  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.607423  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.607464  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.606749  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.608125  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.607816  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.606902  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.606711  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.606517  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.605787  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.606337  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.606668  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.606821  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.605979  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.605538  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.605122  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.605310  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.605218  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.605141  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.605127  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.604785  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.604572  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.604520  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.604327  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.604072  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.604253  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.604261  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.603772  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.604068  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.604002  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.603909  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.603683  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.603521  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.603567  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.603520  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.603374  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.603411  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.603473  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.603200  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.602993  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.602815  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.602891  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.603103  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.603073  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.602939  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.602817  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.602773  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.602822  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.602885  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.603031  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.603142  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.603036  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.602639  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.602702  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.602797  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.602754  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.602846  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.603058  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.602950  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.602804  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.602848  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.602977  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.602944  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.602857  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.602808  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.602721  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.602889  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.602713  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.602428  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.602213  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.602409  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.602417  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.602572  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.602440  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.602516  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.602590  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.602568  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.602731  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.602748  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.602771  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.602695  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.602704  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.602776  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.602627  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.602512  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.602546  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.602416  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.602418  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.602406  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.602470  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.602401  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.602353  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.602324  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.602358  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.602314  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.602264  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.602482  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.602372  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.602345  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.602203  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.602236  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.602205  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.602097  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.602201  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.602130  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.602049  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.602111  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.602011  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.602002  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.601936  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.601987  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.601945  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.601828  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.601782  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.601811  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.601750  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.601809  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.601655  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.601691  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.601534  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.601560  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.601497  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.601413  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.601441  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.601417  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.601319  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.601278  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.601371  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.601236  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.601220  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.601109  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.601154  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.601011  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.601014  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.600903  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.600734  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.600678  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.600572  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.600609  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.600645  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.600620  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.600582  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.600646  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.600549  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.600427  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.600436  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.600444  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.600404  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.600469  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.600476  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.600508  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.600491  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.600427  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.600395  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.600342  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.600347  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.600429  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.600452  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.600382  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.600316  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.600255  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.600229  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.600199  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.600180  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.600133  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.600151  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.600158  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.600267  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.600230  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.600113  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.600087  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.600098  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.600097  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.599997  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.599975  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.599963  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.600022  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.600019  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.599962  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.599964  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.599926  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.599892  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.599969  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.599905  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.599837  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.599764  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.599698  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.599649  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.599603  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.599599  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.599615  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.599672  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.599670  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.599624  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.599577  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.599578  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.599557  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.599565  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.599536  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.599457  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.599394  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.599393  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.599449  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.599477  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.599453  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.599450  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.599440  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.599441  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.599495  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.599531  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.599551  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.599534  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.599583  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.599608  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.599547  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.599506  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.599518  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.599564  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.599521  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.599484  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.599469  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.599378  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.599372  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.599420  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.599409  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.594460\n",
      "@eval_loop_avg_loss=0.592072\n",
      "Epoch 5/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.595797  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.590623  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.594258  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.594806  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.595019  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.594509  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.593890  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.596922  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.597849  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.597872  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.598054  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.597816  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.597283  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.597210  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.597597  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.597911  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.596959  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.596753  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.596598  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.597279  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.596890  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.596994  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.596829  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.596620  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.596494  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.596876  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.597575  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.597418  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.597103  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.596977  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.596961  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.596937  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.596042  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.596477  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.596218  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.596568  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.596681  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.596808  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.596483  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.596520  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.596442  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.596136  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.596014  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.595796  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.596095  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.595980  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.595768  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.595580  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.595824  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.595627  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.595472  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.595241  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.595186  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.595518  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.595778  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.595824  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.595892  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.595854  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.595673  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.595460  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.595262  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.595277  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.595363  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.595228  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.595275  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.595326  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.595274  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.595138  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.595356  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.595485  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.595464  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.595541  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.595765  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.595731  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.595658  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.595643  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.595547  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.595619  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.595729  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.595813  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.595641  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.595855  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.595679  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.595767  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.595744  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.595725  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.595700  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.595702  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.595626  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.595816  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.595648  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.595789  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.595798  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.595750  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.595687  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.595699  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.595609  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.595513  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.595433  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.595432  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.595497  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.595510  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.595361  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.595395  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.595413  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.595355  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.595077  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.595153  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.594959  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.594859  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.594853  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.594873  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.594843  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.594834  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.594931  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.594912  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.594849  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.594885  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.594854  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.594857  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.594795  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.594770  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.594704  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.594820  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.594734  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.594618  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.594516  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.594507  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.594450  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.594366  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.594350  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.594403  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.594413  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.594503  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.594472  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.594395  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.594386  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.594468  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.594452  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.594484  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.594495  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.594593  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.594501  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.594525  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.594422  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.594317  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.594258  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.594219  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.594194  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.594170  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.594151  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.594204  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.594273  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.594193  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.594116  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.594130  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.594175  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.594071  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.594055  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.594031  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.593974  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.593981  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.593996  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.593997  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.593952  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.593902  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.593813  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.593845  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.593912  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.593898  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.593809  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.593863  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.593971  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.593987  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.593973  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.593920  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.593881  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.593879  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.593915  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.593919  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.593884  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.593978  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.593989  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.594029  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.594094  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.594045  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.593999  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.593934  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.593889  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.593849  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.593862  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.593940  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.593924  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.593971  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.593983  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.594012  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.594061  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.594000  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.593937  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.593973  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.593941  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.593911  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.593911  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.593924  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.593872  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.593858  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.593868  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.593835  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.593861  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.593779  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.593828  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.593878  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.593884  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.593855  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.593911  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.593868  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.593814  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.593839  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.593844  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.593787  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.593735  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.593742  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.593822  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.593804  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.593757  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.593743  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.593739  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.593717  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.593734  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.593731  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.593713  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.593780  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.593735  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.593750  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.593760  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.591141\n",
      "@eval_loop_avg_loss=0.588775\n",
      "Epoch 6/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.597016  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.598108  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.596219  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.593059  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.592984  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.594370  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.596541  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.594638  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.594083  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.594806  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.594902  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.594104  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.593718  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.594817  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.593907  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.592639  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.592517  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.592951  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.593166  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.592620  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.592349  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.593102  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.593254  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.592927  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.592065  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.592032  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.592056  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.592103  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.591933  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.591322  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.591121  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.591133  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.591376  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.591416  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.592106  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.592405  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.592612  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.592721  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.592746  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.592518  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.592197  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.592027  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.592261  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.592219  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.591996  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.592099  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.591343  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.591015  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.591307  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.591329  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.591661  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.591603  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.591691  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.591972  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.592165  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.592111  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.591919  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.591536  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.591546  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.591481  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.591446  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.591475  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.591581  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.591796  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.592056  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.592123  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.592210  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.591997  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.592026  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.592113  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.592239  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.592281  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.592094  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.592314  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.592490  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.592655  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.592841  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.592825  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.592941  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.592822  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.592983  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.592954  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.592975  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.592876  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.592831  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.592865  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.592817  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.592857  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.592746  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.592812  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.592946  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.592966  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.592857  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.592737  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.592626  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.592578  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.592575  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.592629  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.592557  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.592670  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.592732  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.592632  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.592486  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.592467  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.592320  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.592235  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.592199  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.592013  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.592029  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.592006  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.591990  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.591971  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.591878  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.591888  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.591856  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.591993  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.592072  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.592141  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.592079  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.592187  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.592101  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.592093  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.592100  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.592055  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.592017  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.592063  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.592186  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.592109  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.592163  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.592154  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.592102  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.591973  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.591886  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.592011  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.591955  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.592032  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.591958  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.592010  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.592068  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.592122  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.592012  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.592005  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.591946  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.591990  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.591910  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.591922  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.591913  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.591859  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.591867  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.591976  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.591974  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.591907  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.591852  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.591811  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.591805  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.591785  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.591727  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.591827  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.591806  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.591671  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.591667  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.591659  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.591665  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.591699  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.591619  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.591628  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.591601  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.591627  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.591599  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.591592  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.591535  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.591574  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.591573  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.591621  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.591562  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.591578  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.591532  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.591492  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.591535  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.591494  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.591463  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.591414  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.591473  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.591474  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.591535  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.591516  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.591495  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.591464  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.591412  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.591352  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.591364  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.591415  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.591448  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.591408  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.591266  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.591226  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.591275  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.591264  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.591297  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.591226  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.591139  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.591166  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.591164  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.591190  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.591225  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.591182  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.591223  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.591230  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.591238  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.591252  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.591268  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.591321  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.591383  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.591413  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.591312  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.591276  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.591228  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.591292  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.591228  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.591234  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.591277  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.591438  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.591474  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.591462  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.591420  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.591371  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.591356  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.591366  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.591281  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.591267  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.591257  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.591221  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.591185  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.591145  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.591141  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.588820\n",
      "@eval_loop_avg_loss=0.586473\n",
      "Epoch 7/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.589110  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.590097  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.595420  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.592649  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.591818  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.593562  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.593666  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.594639  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.593358  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.593065  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.594452  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.594540  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.594720  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.595168  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.595157  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.594098  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.594289  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.594106  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.593858  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.593625  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.593444  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.593174  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.592746  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.592351  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.592231  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.591941  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.591439  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.591372  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.591395  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.591062  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.591102  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.591176  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.591030  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.591392  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.591262  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.591311  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.591044  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.590883  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.590929  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.590976  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.591190  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.590996  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.591035  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.590790  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.591100  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.591057  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.591177  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.591540  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.591240  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.591042  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.591070  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.591467  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.591110  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.591093  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.591275  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.591269  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.591046  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.590976  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.591115  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.590962  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.591108  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.591281  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.591378  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.591627  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.591456  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.591539  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.591609  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.591536  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.591523  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.591450  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.591436  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.591339  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.591347  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.591231  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.591445  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.591572  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.591471  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.591414  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.591384  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.591479  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.591411  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.591346  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.591428  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.591283  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.591404  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.591393  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.591360  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.591219  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.591114  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.591105  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.591143  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.591274  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.591290  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.591057  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.590942  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.590941  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.590698  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.590629  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.590752  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.590725  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.590687  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.590698  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.590674  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.590617  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.590529  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.590500  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.590585  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.590696  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.590610  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.590621  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.590542  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.590580  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.590557  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.590399  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.590412  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.590534  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.590615  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.590661  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.590593  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.590504  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.590507  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.590547  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.590734  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.590662  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.590646  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.590625  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.590546  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.590520  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.590536  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.590444  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.590344  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.590350  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.590503  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.590608  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.590496  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.590562  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.590466  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.590300  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.590273  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.590286  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.590399  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.590371  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.590419  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.590336  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.590261  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.590299  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.590221  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.590270  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.590367  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.590306  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.590313  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.590303  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.590269  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.590229  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.590253  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.590224  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.590200  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.590213  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.590262  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.590259  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.590239  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.590253  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.590168  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.590272  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.590379  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.590454  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.590398  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.590402  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.590400  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.590373  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.590330  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.590345  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.590285  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.590157  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.590143  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.590068  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.590167  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.590111  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.590056  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.590050  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.590063  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.590010  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.589977  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.589935  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.589849  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.589760  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.589653  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.589762  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.589733  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.589745  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.589768  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.589746  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.589627  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.589617  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.589548  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.589538  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.589500  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.589450  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.589494  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.589487  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.589513  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.589494  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.589463  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.589493  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.589444  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.589461  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.589456  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.589456  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.589436  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.589402  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.589337  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.589239  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.589201  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.589178  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.589157  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.589119  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.589064  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.589125  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.589118  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.589099  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.589128  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.589232  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.589265  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.589204  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.589188  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.589167  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.589224  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.589260  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.589279  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.589301  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.589246  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.589228  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.589292  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.589236  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.589243  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.587222\n",
      "@eval_loop_avg_loss=0.584896\n",
      "Epoch 8/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.571021  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.577144  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.582146  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.585140  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.583087  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.586551  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.586552  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.585538  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.586114  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.587224  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.586637  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.585230  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.584206  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.584561  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.584705  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.585631  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.585205  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.585501  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.585912  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.585891  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.586236  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.586826  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.586871  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.586260  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.586344  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.586029  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.585797  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.586106  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.586644  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.586474  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.586283  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.586070  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.586213  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.586148  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.586231  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.587030  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.587205  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.586963  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.587114  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.587034  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.587070  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.586950  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.587142  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.587634  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.587650  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.587663  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.587981  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.587990  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.587873  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.587615  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.587831  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.587797  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.587597  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.587554  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.587744  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.587756  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.587925  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.587810  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.587825  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.587910  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.587802  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.587662  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.587611  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.587495  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.587568  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.587543  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.587704  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.587484  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.587609  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.587563  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.587766  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.587836  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.587796  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.587988  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.587915  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.587833  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.587790  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.587560  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.587723  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.587874  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.587964  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.588092  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.588139  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.588053  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.588049  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.587974  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.587893  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.587744  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.587715  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.587713  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.587608  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.587712  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.587956  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.588135  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.588219  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.588129  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.588329  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.588201  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.588256  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.588293  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.588368  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.588349  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.588303  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.588252  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.588216  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.588107  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.588116  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.588098  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.587929  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.587837  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.587841  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.587815  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.587930  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.587967  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.587982  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.587954  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.587813  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.587768  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.587832  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.587989  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.587960  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.587843  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.587771  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.587648  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.587458  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.587402  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.587521  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.587561  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.587592  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.587517  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.587477  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.587488  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.587486  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.587460  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.587479  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.587510  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.587595  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.587551  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.587521  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.587530  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.587538  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.587579  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.587650  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.587559  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.587507  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.587614  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.587674  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.587624  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.587585  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.587540  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.587569  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.587654  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.587563  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.587652  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.587770  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.587938  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.587997  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.588010  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.587875  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.587853  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.587894  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.587892  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.587879  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.587888  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.587859  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.587857  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.587878  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.587866  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.587909  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.587888  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.587866  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.587845  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.587773  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.587778  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.587708  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.587738  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.587767  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.587776  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.587798  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.587806  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.587844  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.587771  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.587827  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.587839  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.587762  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.587751  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.587706  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.587767  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.587886  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.587909  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.587935  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.588042  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.587996  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.588094  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.588129  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.588016  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.588052  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.588059  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.588132  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.588034  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.588031  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.588079  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.588204  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.588240  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.588236  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.588168  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.588196  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.588215  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.588227  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.588202  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.588241  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.588209  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.588160  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.588201  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.588234  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.588180  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.588192  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.588148  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.588074  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.588116  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.588134  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.588055  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.588060  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.588006  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.587968  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.587965  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.587962  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.587937  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.587899  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.587882  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.587854  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.587878  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.587888  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.587956  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.587952  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.586194\n",
      "@eval_loop_avg_loss=0.583879\n",
      "Epoch 9/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.583918  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.583338  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.582028  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.582931  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.584243  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.584259  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.584890  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.585364  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.586334  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.586527  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.586034  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.585793  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.585855  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.585688  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.585966  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.586101  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.585931  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.586964  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.587226  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.586711  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.587536  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.586970  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.587156  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.587576  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.588130  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.588536  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.588830  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.588512  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.588342  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.588262  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.588540  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.589289  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.589058  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.589126  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.589376  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.589446  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.589233  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.589123  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.589037  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.588565  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.588470  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.588577  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.588729  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.588656  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.588346  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.588278  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.588064  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.588217  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.588240  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.588086  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.588087  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.587967  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.587988  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.587807  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.587912  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.587927  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.587847  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.587910  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.587824  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.587446  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.587312  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.587413  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.587489  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.587463  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.587474  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.587582  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.587668  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.587726  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.587712  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.587496  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.587510  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.587852  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.587776  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.587819  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.587747  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.587727  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.587688  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.587589  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.587450  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.587304  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.587347  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.587287  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.587221  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.586930  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.586924  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.586953  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.586802  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.586936  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.586884  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.586821  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.586788  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.586986  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.586883  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.586867  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.586858  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.586844  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.586920  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.586775  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.586747  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.586581  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.586605  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.586549  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.586570  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.586619  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.586504  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.586397  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.586386  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.586549  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.586584  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.586635  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.586788  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.586930  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.586922  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.586939  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.586923  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.586900  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.586945  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.586940  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.586962  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.587061  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.587136  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.587153  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.586989  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.587055  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.587054  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.587061  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.587024  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.587003  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.586942  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.586979  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.586991  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.586972  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.586918  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.586935  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.586961  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.586991  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.586988  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.587008  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.587076  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.587046  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.587145  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.587263  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.587285  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.587233  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.587306  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.587355  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.587389  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.587368  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.587363  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.587352  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.587336  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.587398  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.587404  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.587337  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.587369  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.587265  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.587235  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.587201  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.587131  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.587120  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.587131  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.587116  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.587170  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.587187  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.587140  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.587214  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.587253  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.587273  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.587262  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.587239  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.587207  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.587249  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.587231  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.587195  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.587233  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.587185  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.587090  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.587140  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.587159  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.587092  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.587069  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.587015  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.587049  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.587071  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.587111  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.587129  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.587145  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.587215  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.587180  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.587116  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.587067  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.587088  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.587033  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.587037  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.587001  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.586976  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.586999  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.586960  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.586987  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.586994  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.587002  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.587075  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.587031  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.586990  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.586960  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.586921  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.586943  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.587035  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.587068  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.587105  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.587074  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.587118  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.587083  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.587022  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.586998  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.587003  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.586992  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.586991  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.587003  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.587029  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.587069  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.587110  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.587106  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.587120  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.587103  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.587120  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.587088  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.587061  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.587013  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.587062  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.587073  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.587048  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.587033  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.587076  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.587053  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.585313\n",
      "@eval_loop_avg_loss=0.583009\n",
      "Epoch 10/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.581242  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.580529  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.576933  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.576062  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.577305  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.580465  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.581226  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.581408  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.582043  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.583084  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.583354  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.584295  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.583800  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.585425  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.585028  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.585588  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.585727  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.585568  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.584777  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.585156  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.584903  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.585191  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.585815  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.585582  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.585427  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.585533  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.585014  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.584977  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.585477  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.585873  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.585783  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.586071  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.586327  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.586662  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.586798  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.587403  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.587665  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.587675  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.587701  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.587726  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.587761  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.587816  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.587618  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.587504  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.587386  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.587241  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.587079  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.587243  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.587420  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.587392  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.587520  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.587525  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.587302  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.587160  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.587070  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.587217  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.587265  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.587320  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.587258  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.587386  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.587227  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.587191  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.587139  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.587123  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.587098  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.586883  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.586965  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.586751  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.586676  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.586714  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.586656  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.586615  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.586714  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.586726  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.586854  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.586887  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.586895  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.586874  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.586818  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.586908  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.586906  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.586963  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.586882  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.586827  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.587093  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.587163  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.587286  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.587447  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.587397  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.587341  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.587412  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.587433  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.587237  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.587361  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.587323  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.587303  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.587329  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.587402  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.587380  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.587326  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.587285  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.587260  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.587284  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.587265  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.587238  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.587159  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.587219  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.587147  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.587185  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.587233  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.587224  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.587164  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.587225  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.587322  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.587471  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.587570  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.587504  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.587576  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.587530  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.587425  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.587455  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.587469  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.587517  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.587451  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.587481  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.587518  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.587545  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.587566  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.587555  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.587539  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.587502  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.587392  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.587420  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.587431  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.587467  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.587418  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.587376  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.587383  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.587448  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.587535  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.587569  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.587490  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.587462  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.587519  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.587486  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.587559  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.587513  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.587560  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.587612  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.587524  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.587542  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.587540  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.587526  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.587478  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.587360  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.587379  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.587336  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.587379  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.587275  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.587306  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.587303  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.587258  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.587269  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.587268  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.587301  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.587353  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.587317  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.587351  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.587308  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.587347  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.587260  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.587260  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.587246  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.587272  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.587253  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.587162  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.587285  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.587234  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.587220  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.587281  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.587287  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.587289  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.587262  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.587293  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.587234  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.587231  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.587217  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.587199  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.587188  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.587136  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.587102  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.587148  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.587154  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.587121  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.587084  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.587035  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.586927  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.586918  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.586919  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.586851  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.586847  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.586812  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.586751  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.586748  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.586700  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.586732  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.586711  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.586725  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.586740  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.586666  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.586645  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.586649  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.586662  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.586618  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.586649  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.586650  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.586689  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.586755  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.586783  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.586750  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.586686  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.586690  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.586688  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.586689  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.586687  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.586648  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.586557  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.586535  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.586528  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.586479  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.586502  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.586392  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.586382  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.586347  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.586340  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.584637\n",
      "@eval_loop_avg_loss=0.582350\n",
      "Epoch 11/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.598251  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.595969  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.597047  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.597767  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.594750  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.594131  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.592636  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.590574  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.589162  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.589688  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.589871  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.588610  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.588585  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.588057  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.587830  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.587968  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.587816  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.587424  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.586332  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.586659  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.587284  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.587200  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.586805  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.587126  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.586747  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.586682  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.586649  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.587079  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.586905  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.586855  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.586595  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.586676  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.586618  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.586539  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.586558  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.586391  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.586591  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.586465  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.586209  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.586391  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.586504  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.586488  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.586189  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.586135  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.586043  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.585960  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.585908  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.586004  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.586283  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.586537  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.586849  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.587149  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.587206  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.587413  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.587124  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.587248  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.587242  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.587231  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.587151  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.586946  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.586804  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.586733  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.586983  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.586993  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.587150  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.587059  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.586886  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.587144  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.587063  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.587086  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.587050  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.586865  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.586731  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.586815  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.586673  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.586637  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.586584  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.586563  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.586720  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.586835  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.586788  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.586833  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.586766  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.586888  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.586773  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.586910  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.586786  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.586782  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.586619  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.586595  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.586613  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.586621  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.586588  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.586561  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.586649  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.586612  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.586554  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.586445  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.586433  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.586355  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.586437  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.586424  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.586469  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.586554  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.586467  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.586635  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.586669  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.586630  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.586663  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.586434  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.586444  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.586381  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.586373  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.586470  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.586479  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.586582  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.586543  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.586509  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.586421  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.586528  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.586489  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.586501  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.586515  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.586537  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.586562  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.586567  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.586550  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.586403  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.586420  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.586458  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.586425  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.586430  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.586365  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.586391  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.586387  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.586347  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.586336  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.586242  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.586183  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.586215  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.586199  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.586179  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.586220  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.586140  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.586109  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.586178  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.586295  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.586342  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.586353  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.586339  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.586362  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.586291  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.586361  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.586326  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.586318  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.586285  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.586236  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.586299  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.586308  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.586286  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.586229  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.586249  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.586225  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.586174  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.586174  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.586100  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.586092  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.586074  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.586081  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.586084  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.586020  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.586084  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.586092  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.586166  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.586140  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.586102  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.586143  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.586149  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.586176  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.586198  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.586203  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.586166  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.586185  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.586190  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.586201  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.586209  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.586128  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.586186  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.586204  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.586228  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.586191  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.586149  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.586139  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.586091  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.586047  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.586050  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.586075  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.586091  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.586068  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.586063  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.586031  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.586041  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.586071  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.586013  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.586011  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.585954  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.585917  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.585933  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.585933  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.585906  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.585871  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.585898  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.585841  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.585999  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.585945  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.585914  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.585954  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.585950  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.585920  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.585830  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.585849  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.585860  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.585885  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.585851  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.585889  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.585799  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.585789  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.585824  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.585804  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.585755  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.585701  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.585703  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.585731  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.585786  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.585778  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.584153\n",
      "@eval_loop_avg_loss=0.581876\n",
      "Epoch 12/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.603005  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.600695  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.595275  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.593981  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.592316  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.590851  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.588527  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.588699  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.589803  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.590413  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.590896  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.589747  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.589116  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.587603  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.586930  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.586706  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.587020  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.586572  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.586061  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.585891  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.585488  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.585076  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.585821  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.585794  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.586141  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.585811  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.585918  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.586455  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.586449  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.586973  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.587028  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.586821  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.586133  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.586615  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.586549  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.586051  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.586052  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.585874  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.585438  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.585237  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.585447  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.585451  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.585551  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.585393  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.585286  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.585594  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.585278  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.585336  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.585296  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.585500  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.585832  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.585954  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.586016  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.585878  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.585815  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.586111  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.586320  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.586407  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.586235  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.585907  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.585915  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.585724  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.585673  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.585813  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.585689  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.585786  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.585772  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.585816  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.585812  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.585763  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.585638  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.585606  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.585658  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.585704  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.585615  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.585538  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.585506  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.585505  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.585448  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.585438  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.585515  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.585422  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.585616  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.585483  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.585595  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.585600  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.585681  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.585832  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.585887  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.585767  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.585915  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.585787  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.585828  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.585754  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.585564  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.585514  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.585475  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.585583  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.585554  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.585498  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.585497  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.585382  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.585193  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.585233  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.585081  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.584960  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.584942  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.584985  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.585213  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.585237  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.585223  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.585305  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.585216  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.585250  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.585153  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.585220  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.585169  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.585246  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.585329  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.585190  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.585184  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.585125  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.585161  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.585159  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.585080  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.585157  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.585136  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.585248  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.585302  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.585251  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.585208  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.585263  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.585258  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.585329  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.585257  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.585308  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.585318  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.585319  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.585173  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.585203  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.585099  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.585155  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.585178  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.585174  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.585199  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.585204  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.585296  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.585267  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.585239  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.585304  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.585276  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.585243  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.585208  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.585112  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.585102  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.585164  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.585189  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.585272  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.585250  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.585275  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.585249  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.585232  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.585135  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.585110  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.585225  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.585246  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.585290  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.585292  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.585262  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.585285  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.585269  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.585295  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.585267  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.585323  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.585243  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.585246  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.585306  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.585199  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.585188  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.585181  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.585162  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.585202  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.585227  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.585264  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.585337  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.585317  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.585399  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.585363  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.585349  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.585364  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.585340  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.585307  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.585285  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.585291  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.585334  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.585279  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.585224  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.585242  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.585181  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.585163  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.585123  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.585132  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.585150  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.585150  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.585204  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.585222  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.585219  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.585235  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.585288  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.585305  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.585179  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.585201  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.585134  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.585145  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.585087  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.585130  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.585208  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.585272  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.585212  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.585204  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.585255  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.585294  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.585341  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.585364  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.585401  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.585414  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.585383  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.585383  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.585349  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.585333  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.585322  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.585281  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.585263  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.585336  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.585318  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.583676\n",
      "@eval_loop_avg_loss=0.581412\n",
      "Epoch 13/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.576526  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.584834  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.584112  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.587957  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.588293  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.588444  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.587540  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.587900  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.589192  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.589034  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.589308  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.589440  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.588662  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.589356  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.588999  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.587901  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.587637  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.587550  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.587618  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.587465  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.586894  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.587116  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.587081  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.586887  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.586739  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.586755  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.587047  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.587073  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.587270  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.587173  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.587704  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.587547  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.587999  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.587964  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.588228  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.587835  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.587451  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.587126  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.587313  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.587109  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.587064  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.587123  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.586945  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.587009  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.587331  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.587075  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.587086  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.587034  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.587082  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.587169  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.587001  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.587008  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.587253  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.587072  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.587050  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.586920  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.586956  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.587041  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.586984  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.586848  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.586609  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.586320  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.586476  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.586572  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.586867  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.586735  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.586867  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.586786  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.586771  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.586606  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.586322  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.586170  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.586059  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.586237  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.586110  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.586154  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.586471  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.586360  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.586388  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.586328  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.586378  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.586523  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.586418  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.586410  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.586491  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.586400  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.586246  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.586274  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.586232  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.586260  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.586065  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.585940  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.585906  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.585902  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.585807  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.585883  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.585882  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.585886  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.585871  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.585846  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.585625  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.585558  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.585616  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.585590  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.585626  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.585585  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.585613  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.585608  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.585477  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.585345  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.585254  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.585181  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.585143  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.585069  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.585096  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.585013  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.585151  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.585239  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.585177  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.585134  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.585198  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.585181  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.585195  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.585205  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.585209  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.585249  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.585237  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.585200  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.585177  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.585021  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.585124  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.585121  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.585146  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.585152  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.585206  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.585257  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.585251  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.585161  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.585142  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.585136  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.585182  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.585242  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.585219  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.585069  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.585016  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.585004  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.584979  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.584994  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.584996  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.584934  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.584972  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.585045  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.585081  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.585086  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.585072  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.585074  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.585022  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.584906  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.584953  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.584897  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.584894  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.584871  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.584777  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.584771  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.584811  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.584835  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.584804  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.584708  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.584696  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.584630  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.584598  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.584592  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.584616  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.584606  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.584569  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.584565  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.584483  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.584523  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.584587  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.584589  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.584585  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.584578  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.584557  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.584628  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.584660  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.584644  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.584702  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.584671  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.584693  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.584708  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.584717  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.584723  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.584823  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.584835  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.584871  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.584862  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.584842  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.584827  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.584858  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.584973  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.585000  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.584935  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.584923  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.584859  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.584818  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.584782  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.584809  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.584801  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.584793  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.584763  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.584750  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.584728  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.584710  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.584711  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.584733  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.584824  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.584845  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.584780  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.584852  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.584824  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.584827  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.584826  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.584816  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.584819  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.584753  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.584720  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.584760  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.584757  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.584714  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.584749  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.584773  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.584831  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.584882  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.584911  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.584923  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.583382\n",
      "@eval_loop_avg_loss=0.581125\n",
      "Epoch 14/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.596179  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.590657  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.581198  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.587823  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.585280  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.583963  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.584842  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.583654  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.583888  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.583192  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.584164  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.585578  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.588193  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.588429  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.587893  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.587282  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.587647  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.586181  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.585668  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.585451  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.584895  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.584854  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.585223  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.584250  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.584537  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.583810  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.583316  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.583613  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.583319  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.583471  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.583189  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.583243  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.583587  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.583235  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.583439  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.583000  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.583493  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.583716  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.584087  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.584166  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.583898  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.583845  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.583785  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.583577  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.583658  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.583724  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.584246  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.584161  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.584699  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.584494  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.584364  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.584224  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.584021  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.583819  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.584088  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.584082  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.584253  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.584221  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.584230  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.584443  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.584515  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.584510  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.584460  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.584420  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.584360  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.584156  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.584116  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.584328  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.584243  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.584317  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.584443  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.584318  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.584474  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.584442  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.584545  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.584651  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.584638  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.584490  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.584478  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.584421  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.584412  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.584288  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.584278  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.584250  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.584245  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.584225  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.584254  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.584191  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.584131  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.584126  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.583956  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.583829  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.583764  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.583871  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.583838  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.583894  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.583801  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.583948  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.583903  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.584013  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.584016  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.584085  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.584188  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.584279  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.584263  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.584241  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.584225  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.584225  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.584231  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.584275  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.584193  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.584186  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.584195  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.584201  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.584262  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.584305  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.584367  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.584426  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.584305  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.584222  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.584310  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.584383  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.584450  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.584524  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.584579  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.584630  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.584615  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.584608  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.584549  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.584528  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.584564  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.584631  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.584649  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.584654  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.584658  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.584624  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.584537  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.584476  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.584565  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.584584  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.584584  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.584514  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.584489  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.584434  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.584508  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.584676  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.584754  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.584753  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.584693  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.584771  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.584847  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.584819  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.584756  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.584725  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.584709  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.584660  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.584646  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.584691  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.584750  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.584615  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.584648  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.584600  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.584639  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.584635  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.584593  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.584598  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.584570  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.584542  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.584583  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.584551  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.584489  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.584490  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.584466  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.584372  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.584375  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.584387  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.584401  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.584463  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.584524  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.584475  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.584475  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.584426  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.584458  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.584474  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.584475  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.584493  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.584518  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.584461  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.584333  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.584333  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.584330  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.584385  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.584497  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.584466  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.584426  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.584414  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.584450  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.584444  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.584459  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.584439  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.584469  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.584547  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.584469  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.584489  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.584476  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.584523  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.584481  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.584505  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.584535  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.584524  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.584507  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.584552  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.584537  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.584522  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.584552  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.584611  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.584626  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.584667  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.584557  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.584500  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.584545  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.584538  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.584568  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.584538  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.584498  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.584401  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.584371  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.584346  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.584347  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.584455  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.584478  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.584540  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.584541  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.584590  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.584611  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.583083\n",
      "@eval_loop_avg_loss=0.580840\n",
      "Epoch 15/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.583336  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.588889  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.589979  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.585697  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.587100  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.584466  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.583492  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.582363  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.581419  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.582108  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.583466  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.582481  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.582921  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.583149  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.583106  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.583334  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.582917  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.583575  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.584065  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.584200  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.583903  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.583298  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.582880  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.582914  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.582689  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.582654  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.583046  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.583263  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.582962  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.582684  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.582651  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.582791  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.583289  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.583177  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.583500  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.583530  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.583782  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.583816  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.583408  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.583408  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.583322  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.583598  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.583613  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.583691  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.583730  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.583626  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.583820  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.583645  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.583863  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.583891  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.583963  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.583949  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.583846  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.583844  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.583818  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.584131  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.584253  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.584192  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.584175  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.584269  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.584284  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.584000  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.584126  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.584035  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.583918  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.583977  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.583818  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.583939  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.583853  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.583937  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.583981  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.583978  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.583996  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.583977  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.584044  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.584092  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.584133  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.583985  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.584030  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.584247  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.584178  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.584248  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.584355  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.584407  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.584422  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.584479  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.584518  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.584617  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.584725  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.584659  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.584742  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.584889  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.584815  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.584757  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.584725  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.584796  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.584806  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.584750  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.584825  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.584740  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.584658  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.584590  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.584649  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.584635  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.584767  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.584705  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.584584  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.584676  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.584659  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.584548  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.584489  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.584559  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.584344  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.584413  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.584425  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.584441  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.584408  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.584302  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.584280  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.584363  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.584371  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.584418  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.584412  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.584312  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.584305  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.584311  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.584369  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.584290  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.584318  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.584260  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.584212  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.584308  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.584224  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.584219  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.584200  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.584164  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.584185  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.584302  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.584401  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.584295  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.584367  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.584351  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.584358  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.584441  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.584382  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.584369  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.584340  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.584343  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.584406  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.584561  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.584524  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.584545  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.584519  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.584513  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.584543  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.584490  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.584522  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.584670  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.584673  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.584690  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.584687  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.584669  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.584593  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.584643  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.584572  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.584623  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.584566  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.584613  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.584649  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.584616  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.584642  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.584695  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.584639  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.584555  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.584519  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.584483  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.584452  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.584467  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.584553  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.584439  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.584458  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.584539  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.584515  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.584568  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.584567  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.584561  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.584582  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.584570  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.584559  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.584534  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.584515  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.584518  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.584431  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.584439  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.584415  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.584420  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.584413  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.584500  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.584557  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.584569  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.584494  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.584549  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.584634  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.584698  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.584730  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.584688  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.584699  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.584727  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.584607  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.584527  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.584471  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.584414  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.584444  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.584367  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.584434  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.584506  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.584474  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.584450  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.584487  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.584456  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.584422  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.584472  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.584538  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.584566  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.584537  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.584493  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.584439  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.584447  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.584387  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.584352  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.584392  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.584413  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.584295  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.584308  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.584317  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.582753\n",
      "@eval_loop_avg_loss=0.580522\n",
      "Epoch 16/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.592311  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.584128  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.585579  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.585181  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.582970  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.583366  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.583666  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.582490  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.580584  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.580834  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.580695  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.580604  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.581788  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.581726  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.583281  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.583872  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.584252  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.584971  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.584455  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.585480  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.585660  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.585788  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.585317  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.585209  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.584960  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.585386  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.585182  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.584817  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.584653  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.584694  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.584233  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.584515  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.584845  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.584823  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.584620  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.584227  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.584383  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.583954  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.583959  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.584029  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.583899  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.583742  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.583421  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.583400  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.583558  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.583561  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.583628  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.583794  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.583924  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.583866  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.583870  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.583909  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.584003  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.583924  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.583682  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.583379  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.583499  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.583811  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.583957  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.583728  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.583779  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.583781  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.583950  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.583756  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.583640  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.583704  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.583464  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.583447  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.583200  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.583059  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.582946  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.583011  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.582830  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.582943  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.583225  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.583203  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.583283  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.583299  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.583376  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.583321  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.583193  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.583292  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.583434  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.583659  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.583823  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.583905  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.583902  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.583714  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.583433  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.583560  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.583438  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.583425  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.583503  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.583575  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.583466  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.583205  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.583144  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.583187  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.583191  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.583206  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.583045  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.583008  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.582991  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.583083  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.583154  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.583230  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.583065  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.583173  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.583178  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.583201  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.583210  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.583095  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.583029  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.583116  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.583105  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.583117  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.583167  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.583218  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.583264  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.583315  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.583423  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.583490  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.583462  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.583500  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.583395  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.583439  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.583411  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.583391  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.583566  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.583570  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.583614  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.583683  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.583694  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.583842  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.583858  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.583778  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.583742  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.583691  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.583728  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.583649  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.583557  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.583506  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.583470  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.583475  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.583458  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.583469  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.583475  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.583462  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.583517  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.583603  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.583562  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.583710  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.583713  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.583668  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.583698  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.583732  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.583826  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.583805  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.583788  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.583903  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.583833  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.583855  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.583919  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.583932  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.583821  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.583848  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.583835  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.583791  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.583894  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.583803  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.583796  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.583833  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.583815  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.583849  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.583898  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.583881  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.583926  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.583948  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.583979  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.583992  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.584032  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.584048  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.584050  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.583962  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.583866  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.583902  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.583997  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.583925  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.583934  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.583966  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.583941  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.583924  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.583972  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.584020  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.584004  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.584010  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.584067  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.584025  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.583978  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.583948  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.584029  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.584053  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.584095  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.584129  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.584120  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.584094  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.584032  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.583974  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.583994  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.584038  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.584078  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.584044  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.584042  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.584075  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.584064  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.584060  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.584097  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.584075  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.584046  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.584062  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.583979  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.584026  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.583966  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.584047  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.584058  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.584081  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.584135  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.584105  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.584104  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.584082  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.584031  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.583973  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.584017  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.584019  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.584051  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.582512\n",
      "@eval_loop_avg_loss=0.580286\n",
      "Epoch 17/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.585334  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.580483  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.585239  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.587333  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.587818  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.586335  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.587149  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.588585  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.588146  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.587463  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.588073  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.587692  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.586411  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.586893  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.586655  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.586269  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.587088  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.586578  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.585917  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.585321  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.585271  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.585472  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.585129  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.585465  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.585275  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.585304  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.585153  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.585366  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.585631  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.585642  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.586024  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.585908  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.585482  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.585116  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.584911  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.584433  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.584243  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.584011  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.584192  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.584030  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.583928  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.583964  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.583806  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.583566  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.583351  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.583019  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.583169  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.583230  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.583293  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.583492  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.584016  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.583930  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.583775  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.583622  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.583906  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.584007  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.584223  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.584205  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.583968  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.583789  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.583538  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.583741  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.583305  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.583351  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.583273  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.583092  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.583332  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.583323  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.583212  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.583075  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.583015  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.583042  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.583304  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.583568  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.583612  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.583559  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.583460  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.583643  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.583718  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.583957  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.584065  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.584109  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.584115  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.584122  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.584206  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.584177  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.584170  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.584094  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.584038  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.584160  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.584216  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.584028  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.584177  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.584283  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.584338  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.584241  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.584353  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.584283  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.584299  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.584240  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.584164  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.584190  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.584117  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.584070  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.584061  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.583964  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.583907  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.583980  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.583977  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.584020  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.584015  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.583987  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.584022  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.583904  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.583797  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.583787  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.583897  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.583973  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.583990  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.584006  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.583988  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.583854  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.583835  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.583834  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.583880  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.583948  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.583925  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.583867  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.583871  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.583685  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.583696  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.583688  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.583702  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.583770  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.583826  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.583838  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.583878  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.583838  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.583806  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.583788  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.583837  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.583743  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.583701  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.583768  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.583702  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.583757  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.583711  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.583704  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.583719  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.583794  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.583778  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.583798  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.583700  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.583708  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.583781  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.583660  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.583727  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.583649  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.583630  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.583584  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.583662  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.583652  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.583620  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.583648  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.583614  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.583663  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.583709  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.583716  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.583742  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.583662  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.583668  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.583709  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.583699  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.583773  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.583795  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.583836  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.583846  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.583758  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.583801  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.583795  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.583760  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.583800  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.583746  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.583775  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.583795  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.583714  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.583618  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.583648  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.583587  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.583608  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.583606  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.583530  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.583614  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.583681  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.583608  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.583573  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.583628  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.583599  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.583582  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.583568  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.583580  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.583580  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.583618  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.583567  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.583588  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.583617  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.583555  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.583530  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.583542  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.583537  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.583493  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.583594  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.583623  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.583587  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.583618  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.583633  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.583666  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.583662  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.583688  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.583680  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.583656  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.583658  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.583698  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.583750  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.583823  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.583690  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.583635  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.583578  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.583593  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.583645  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.583661  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.583632  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.583683  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.583793  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.583813  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.582378\n",
      "@eval_loop_avg_loss=0.580158\n",
      "Epoch 18/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.574524  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.575630  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.577696  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.580075  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.582462  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.583159  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.583803  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.584257  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.583243  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.584607  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.584368  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.582758  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.582504  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.582396  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.582379  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.582801  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.583851  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.583273  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.583981  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.584709  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.584863  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.584203  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.583857  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.583614  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.583465  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.583077  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.582857  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.583088  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.582851  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.582257  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.582334  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.582266  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.581791  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.581808  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.582591  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.582661  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.582766  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.582786  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.582610  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.583185  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.582293  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.582417  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.582768  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.582844  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.582969  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.583047  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.583310  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.583484  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.583483  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.583483  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.583563  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.583528  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.583430  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.583553  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.583329  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.583488  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.583517  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.583380  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.583073  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.583077  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.582804  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.582678  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.582854  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.582903  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.582823  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.582726  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.582668  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.582844  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.582585  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.582573  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.582677  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.582890  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.582950  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.583008  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.583047  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.583182  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.582989  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.583094  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.583314  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.583304  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.583294  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.583216  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.583298  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.583413  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.583317  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.583326  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.583440  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.583460  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.583356  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.583281  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.583516  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.583512  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.583534  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.583498  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.583453  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.583443  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.583384  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.583315  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.583293  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.583299  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.583338  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.583455  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.583495  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.583558  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.583580  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.583592  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.583594  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.583689  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.583823  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.583775  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.583703  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.583672  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.583559  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.583689  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.583735  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.583658  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.583619  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.583714  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.583687  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.583705  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.583738  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.583571  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.583486  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.583485  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.583396  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.583427  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.583482  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.583589  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.583549  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.583565  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.583684  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.583749  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.583726  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.583669  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.583678  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.583701  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.583703  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.583622  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.583670  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.583579  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.583626  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.583635  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.583713  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.583828  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.583795  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.583772  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.583776  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.583796  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.583853  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.583933  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.583979  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.583995  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.583979  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.584025  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.584192  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.584177  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.584145  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.584106  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.584122  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.584133  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.584142  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.584115  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.584083  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.584114  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.584116  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.584060  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.584125  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.584095  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.584050  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.584100  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.584077  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.584016  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.583983  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.584021  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.584023  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.583951  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.583935  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.583991  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.583946  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.584093  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.584099  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.584074  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.584058  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.584081  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.584152  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.584124  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.584171  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.584058  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.584053  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.584145  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.584118  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.584058  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.584053  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.584062  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.584071  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.584063  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.583933  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.583934  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.583889  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.583795  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.583788  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.583753  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.583811  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.583815  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.583781  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.583727  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.583730  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.583787  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.583844  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.583774  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.583766  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.583721  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.583696  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.583678  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.583612  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.583620  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.583596  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.583567  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.583554  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.583552  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.583590  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.583547  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.583524  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.583515  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.583508  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.583561  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.583538  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.583595  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.583554  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.583536  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.583564  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.583615  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.583594  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.583638  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.583624  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.582085\n",
      "@eval_loop_avg_loss=0.579876\n",
      "Epoch 19/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.572617  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.576639  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.580228  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.578353  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.579626  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.582437  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.581844  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.584111  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.583849  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.583658  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.584752  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.584112  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.584298  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.584271  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.584285  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.584863  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.586343  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.586530  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.586283  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.585972  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.585824  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.585401  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.584882  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.584896  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.585025  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.585621  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.585696  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.585450  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.585300  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.585719  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.585732  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.585953  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.585655  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.585211  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.585089  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.584702  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.584346  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.584254  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.584411  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.584345  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.584428  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.584270  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.584430  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.584339  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.584271  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.584387  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.584401  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.584288  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.584241  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.584055  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.584084  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.584140  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.584058  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.584080  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.584099  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.584087  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.584275  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.584086  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.584245  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.584330  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.584519  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.584576  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.584538  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.584551  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.584179  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.584024  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.583959  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.583910  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.583976  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.583954  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.583850  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.583868  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.583682  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.583854  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.583765  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.583732  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.583971  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.584098  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.583968  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.583859  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.583568  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.583582  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.583458  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.583382  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.583452  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.583458  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.583405  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.583418  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.583430  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.583361  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.583250  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.583300  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.583225  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.583200  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.583229  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.583225  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.583270  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.583373  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.583278  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.583302  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.583224  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.583264  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.583381  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.583485  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.583739  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.583687  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.583743  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.583566  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.583476  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.583524  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.583556  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.583630  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.583614  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.583510  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.583504  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.583405  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.583435  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.583429  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.583553  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.583740  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.583675  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.583646  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.583697  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.583720  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.583821  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.583721  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.583668  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.583668  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.583542  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.583552  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.583571  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.583568  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.583547  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.583500  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.583642  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.583606  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.583624  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.583621  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.583539  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.583572  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.583657  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.583606  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.583511  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.583465  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.583602  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.583636  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.583675  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.583759  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.583642  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.583590  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.583673  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.583737  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.583752  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.583639  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.583684  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.583609  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.583571  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.583474  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.583568  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.583622  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.583580  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.583598  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.583685  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.583712  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.583725  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.583691  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.583712  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.583667  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.583687  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.583603  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.583632  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.583740  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.583873  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.583830  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.583902  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.583926  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.583936  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.583870  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.583890  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.583824  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.583716  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.583593  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.583605  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.583617  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.583630  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.583593  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.583536  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.583534  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.583531  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.583524  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.583553  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.583511  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.583468  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.583482  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.583448  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.583447  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.583521  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.583499  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.583465  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.583500  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.583522  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.583643  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.583589  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.583602  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.583584  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.583537  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.583559  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.583607  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.583534  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.583482  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.583485  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.583454  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.583396  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.583444  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.583438  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.583405  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.583371  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.583382  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.583376  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.583409  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.583386  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.583447  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.583409  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.583407  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.583410  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.583407  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.583358  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.583405  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.583367  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.583379  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.583389  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.583393  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.583440  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.583439  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.583427  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581844\n",
      "@eval_loop_avg_loss=0.579637\n",
      "Epoch 20/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.575778  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.576231  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.581846  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.582280  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.582599  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.584388  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.583583  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.584199  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.585874  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.584860  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.584775  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.584621  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.585136  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.585331  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.584538  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.584636  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.584176  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.584416  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.583403  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.583488  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.583662  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.583350  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.583860  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.583360  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.583670  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.583659  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.583323  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.582781  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.582847  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.583263  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.583126  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.583718  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.583504  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.583843  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.584152  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.584177  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.583870  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.583755  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.583765  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.583561  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.583556  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.583415  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.583402  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.582972  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.583104  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.583347  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.583572  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.583299  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.583287  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.583444  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.583486  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.583406  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.583435  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.583376  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.583237  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.583195  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.583220  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.583146  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.583220  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.583425  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.583445  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.583469  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.583305  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.583357  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.583249  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.583178  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.583142  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.583059  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.583111  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.583242  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.583473  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.583444  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.583479  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.583338  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.583213  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.583444  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.583727  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.583655  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.583586  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.583535  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.583613  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.583526  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.583519  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.583561  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.583667  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.583489  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.583539  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.583519  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.583475  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.583512  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.583463  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.583575  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.583612  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.583462  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.583580  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.583589  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.583673  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.583721  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.583659  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.583493  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.583583  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.583521  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.583566  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.583584  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.583527  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.583400  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.583345  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.583360  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.583390  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.583330  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.583321  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.583301  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.583244  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.583139  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.583026  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.583053  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.583103  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.583059  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.583153  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.583180  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.583168  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.583196  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.583282  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.583186  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.583193  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.583236  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.583336  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.583313  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.583370  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.583377  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.583378  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.583443  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.583282  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.583267  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.583341  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.583330  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.583316  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.583345  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.583413  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.583468  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.583491  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.583485  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.583382  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.583428  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.583404  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.583344  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.583323  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.583263  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.583267  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.583253  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.583169  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.583144  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.583097  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.583134  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.583146  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.583113  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.583074  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.583131  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.583139  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.583087  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.583094  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.583016  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.583054  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.583076  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.583004  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.583056  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.583070  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.583166  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.583154  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.583413  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.583326  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.583360  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.583341  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.583288  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.583309  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.583309  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.583315  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.583376  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.583361  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.583388  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.583452  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.583513  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.583474  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.583461  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.583486  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.583419  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.583446  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.583456  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.583495  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.583442  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.583461  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.583526  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.583585  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.583632  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.583552  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.583557  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.583482  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.583490  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.583515  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.583519  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.583420  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.583410  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.583420  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.583425  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.583344  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.583343  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.583339  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.583346  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.583363  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.583305  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.583264  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.583270  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.583255  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.583292  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.583325  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.583267  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.583277  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.583337  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.583349  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.583381  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.583382  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.583283  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.583248  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.583247  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.583213  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.583247  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.583292  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.583180  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.583200  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.583193  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.583300  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.583264  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.583238  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.583213  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.583230  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581744\n",
      "@eval_loop_avg_loss=0.579542\n",
      "Epoch 21/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.602428  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.595048  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.589160  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.589563  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.583982  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.584832  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.584233  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.585666  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.584785  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.584602  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.585017  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.586454  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.586239  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.585928  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.585045  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.585083  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.584595  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.584695  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.584538  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.584479  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.584577  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.584166  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.584319  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.584291  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.583403  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.583142  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.583412  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.583277  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.583699  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.583852  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.583854  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.584105  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.584122  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.583953  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.583881  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.583544  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.583494  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.583453  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.583464  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.583440  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.583880  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.583727  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.583583  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.583753  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.583834  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.584024  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.583553  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.583442  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.583209  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.583041  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.583135  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.583594  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.583573  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.583516  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.583715  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.583698  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.583573  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.583526  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.583466  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.583622  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.583362  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.583328  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.583764  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.583570  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.583601  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.583707  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.583768  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.583840  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.583814  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.583852  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.583560  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.583710  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.583777  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.583857  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.583703  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.583732  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.583569  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.583666  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.583512  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.583462  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.583634  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.583684  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.583866  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.583915  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.584032  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.584097  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.584227  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.584282  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.584332  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.584329  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.584366  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.584444  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.584276  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.584264  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.584168  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.584181  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.584021  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.584031  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.584118  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.584143  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.584063  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.583931  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.583815  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.583714  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.583789  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.583887  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.583811  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.583610  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.583702  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.583854  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.583656  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.583562  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.583631  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.583592  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.583682  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.583722  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.583820  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.583759  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.583656  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.583618  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.583553  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.583682  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.583693  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.583539  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.583612  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.583565  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.583573  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.583545  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.583643  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.583580  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.583600  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.583550  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.583577  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.583481  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.583557  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.583448  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.583457  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.583347  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.583294  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.583270  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.583241  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.583197  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.583182  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.583153  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.583241  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.583144  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.583066  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.583126  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.583075  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.583057  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.583081  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.583126  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.583127  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.583125  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.583176  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.583149  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.583093  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.583015  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.583066  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.583018  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.582997  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.582889  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.582969  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.582984  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.583017  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.582960  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.582978  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.582989  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.582900  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.582825  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.582829  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.582834  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.582872  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.582967  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.582927  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.582871  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.582885  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.582936  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.582896  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.582838  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.582807  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.582724  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.582736  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.582690  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.582723  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.582703  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.582638  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.582682  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.582690  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.582746  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.582694  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.582639  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.582742  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.582839  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.582875  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.582881  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.582862  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.582869  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.582858  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.582917  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.582893  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.582914  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.582917  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.582889  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.583008  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.583038  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.583093  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.583123  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.583132  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.583130  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.583039  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.583091  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.583099  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.583164  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.583119  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.583124  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.583154  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.583165  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.583165  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.583157  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.583125  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.583169  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.583190  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.583220  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.583223  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.583226  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.583176  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.583191  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.583186  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.583197  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.583180  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.583102  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.583049  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.583090  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.583087  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581586\n",
      "@eval_loop_avg_loss=0.579404\n",
      "Epoch 22/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.569956  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.575874  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.580032  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.576530  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.579450  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.581199  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.580682  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.580276  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.581023  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.580895  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.580421  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.579415  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.579731  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.579769  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.580038  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.580847  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.580184  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.579771  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.580815  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.580306  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.580254  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.580350  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.580432  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.580525  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.580829  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.581563  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.581329  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.581532  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.582138  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.582058  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.581770  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.581740  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.581704  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.582059  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.582026  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.582180  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.581996  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.582042  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.582460  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.582769  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.582954  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.582869  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.582760  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.582746  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.582678  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.582855  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.583160  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.582869  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.582863  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.582670  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.582388  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.582387  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.582640  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.582951  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.582948  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.582891  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.582922  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.582666  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.582428  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.582412  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.582424  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.582194  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.582298  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.582405  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.582433  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.582373  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.582478  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.582533  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.582526  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.582626  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.582490  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.582503  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.582493  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.582387  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.582463  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.582481  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.582611  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.582586  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.582665  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.582696  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.582730  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.582769  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.582738  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.582786  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.582813  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.582759  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.582716  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.582553  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.582618  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.582599  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.582403  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.582349  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.582348  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.582658  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.582577  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.582661  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.582448  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.582495  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.582398  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.582644  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.582612  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.582600  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.582460  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.582464  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.582458  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.582577  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.582523  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.582425  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.582309  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.582377  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.582362  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.582329  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.582345  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.582421  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.582619  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.582614  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.582704  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.582801  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.582743  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.582633  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.582553  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.582567  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.582572  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.582566  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.582529  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.582441  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.582380  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.582341  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.582393  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.582330  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.582436  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.582476  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.582448  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.582508  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.582529  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.582508  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.582590  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.582630  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.582727  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.582795  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.582952  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.582916  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.582906  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.582934  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.582957  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.582870  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.582924  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.582883  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.582857  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.582864  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.582890  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.582902  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.582896  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.582902  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.582799  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.582922  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.582873  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.582914  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.582999  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.582958  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.582839  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.582846  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.582819  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.582782  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.582692  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.582657  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.582636  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.582644  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.582683  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.582635  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.582652  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.582712  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.582727  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.582838  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.582791  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.582806  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.582723  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.582791  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.582792  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.582823  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.582854  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.582879  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.582898  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.582868  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.582919  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.582923  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.582892  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.582890  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.582824  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.582816  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.582779  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.582782  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.582777  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.582783  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.582761  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.582784  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.582717  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.582732  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.582746  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.582730  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.582810  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.582758  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.582830  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.582812  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.582820  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.582784  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.582853  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.582883  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.582936  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.582944  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.582919  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.582934  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.582898  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.582930  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.582967  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.582936  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.582923  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.582892  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.582917  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.582961  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.582946  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.582940  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.582934  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.582890  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.582830  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.582819  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.582847  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.582815  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.582824  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.582884  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.582873  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.582898  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.582972  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.582990  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.582985  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581489\n",
      "@eval_loop_avg_loss=0.579314\n",
      "Epoch 23/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.585022  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.581772  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.581095  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.581976  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.581592  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.582143  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.581569  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.581665  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.582340  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.582099  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.582023  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.582042  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.582244  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.581456  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.581888  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.581496  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.580914  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.581541  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.581298  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.581558  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.582093  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.582910  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.583188  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.583125  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.583601  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.583575  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.584115  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.583772  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.583855  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.583863  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.583540  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.583210  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.582822  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.582842  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.582605  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.582357  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.582518  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.582621  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.582706  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.582711  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.582515  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.582148  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.582313  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.582417  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.582497  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.582631  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.582686  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.582481  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.582649  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.582585  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.582506  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.582426  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.582706  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.582999  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.583149  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.583125  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.583272  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.583198  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.583130  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.583233  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.583136  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.583245  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.583327  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.583492  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.583563  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.583570  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.583930  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.583858  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.583857  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.583841  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.583760  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.583652  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.583684  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.583543  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.583448  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.583442  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.583440  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.583263  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.583222  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.583293  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.583253  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.583243  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.583264  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.583306  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.583294  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.583398  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.583458  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.583297  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.583316  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.583372  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.583530  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.583570  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.583707  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.583631  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.583493  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.583517  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.583497  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.583513  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.583562  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.583568  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.583514  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.583502  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.583529  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.583427  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.583611  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.583506  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.583500  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.583478  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.583484  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.583524  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.583524  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.583516  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.583576  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.583458  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.583430  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.583477  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.583551  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.583497  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.583616  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.583631  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.583639  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.583627  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.583578  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.583607  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.583457  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.583510  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.583640  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.583571  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.583512  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.583464  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.583341  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.583342  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.583217  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.583280  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.583313  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.583349  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.583281  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.583333  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.583250  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.583235  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.583316  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.583250  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.583177  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.583272  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.583281  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.583331  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.583362  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.583366  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.583510  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.583403  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.583383  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.583210  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.583201  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.583210  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.583238  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.583191  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.583180  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.583178  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.583098  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.583024  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.583033  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.582942  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.582902  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.582865  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.582775  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.582803  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.582823  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.582860  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.582812  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.582817  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.582829  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.582759  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.582728  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.582711  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.582734  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.582793  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.582781  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.582843  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.582796  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.582726  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.582750  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.582732  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.582778  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.582766  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.582754  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.582752  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.582696  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.582810  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.582870  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.582895  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.582864  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.582943  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.582848  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.582890  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.582853  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.582868  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.582858  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.582909  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.582913  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.582876  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.582854  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.582848  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.582820  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.582865  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.582825  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.582776  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.582797  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.582821  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.582845  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.582899  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.582898  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.582793  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.582823  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.582831  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.582822  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.582831  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.582786  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.582851  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.582896  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.582895  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.582854  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.582835  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.582903  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.582906  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.582850  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.582878  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.582849  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.582856  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.582823  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.582848  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.582826  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.582804  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.582848  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.582822  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.582827  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581316\n",
      "@eval_loop_avg_loss=0.579143\n",
      "Epoch 24/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.576743  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.588170  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.585291  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.582962  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.582608  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.585294  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.586438  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.584152  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.585705  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.584732  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.584723  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.584143  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.584445  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.584412  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.583920  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.583793  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.583136  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.583216  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.583882  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.585124  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.585151  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.584974  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.584951  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.584696  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.585136  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.584409  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.584619  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.584625  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.584532  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.584812  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.584488  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.584159  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.584302  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.584337  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.584272  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.584280  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.584143  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.583722  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.583685  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.583348  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.583779  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.584129  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.584019  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.583940  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.583805  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.583721  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.583815  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.583797  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.583550  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.583531  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.583622  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.583799  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.584103  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.584191  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.584520  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.584263  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.584540  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.584428  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.584417  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.584243  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.584262  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.584191  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.584302  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.584214  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.584288  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.584254  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.584308  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.584259  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.584237  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.584154  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.584041  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.584062  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.583997  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.584060  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.584058  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.584076  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.584118  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.584165  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.583943  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.583921  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.583862  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.583795  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.583852  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.583865  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.583840  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.583795  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.583868  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.583700  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.583856  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.583763  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.583864  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.583739  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.583765  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.583840  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.583742  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.583762  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.583728  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.583804  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.583585  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.583689  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.583770  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.583626  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.583703  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.583720  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.583616  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.583681  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.583818  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.583760  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.583638  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.583606  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.583639  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.583565  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.583510  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.583481  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.583397  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.583366  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.583301  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.583183  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.583289  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.583184  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.583323  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.583218  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.583224  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.583311  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.583380  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.583324  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.583378  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.583409  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.583336  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.583248  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.583311  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.583261  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.583336  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.583399  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.583523  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.583401  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.583406  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.583439  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.583393  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.583198  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.583131  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.583218  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.583173  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.583158  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.583177  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.583261  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.583273  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.583298  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.583370  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.583332  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.583315  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.583328  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.583296  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.583315  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.583282  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.583322  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.583213  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.583165  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.583194  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.583162  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.583222  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.583243  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.583274  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.583251  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.583307  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.583365  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.583459  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.583432  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.583445  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.583372  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.583389  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.583324  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.583272  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.583222  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.583227  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.583183  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.583154  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.583111  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.583140  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.583115  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.583190  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.583189  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.583194  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.583176  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.583198  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.583258  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.583261  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.583183  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.583175  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.583098  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.583042  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.583023  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.583125  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.583100  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.583093  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.583112  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.583158  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.583073  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.582953  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.582923  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.582906  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.582883  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.582827  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.582814  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.582780  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.582788  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.582717  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.582659  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.582623  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.582631  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.582717  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.582739  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.582778  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.582747  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.582754  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.582743  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.582712  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.582647  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.582616  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.582570  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.582579  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.582561  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.582594  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.582607  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.582573  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.582571  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.582589  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.582628  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.582618  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.582657  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.582694  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.582742  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.582681  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.582653  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.582688  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581204\n",
      "@eval_loop_avg_loss=0.579051\n",
      "Epoch 25/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.595516  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.579409  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.583215  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.585174  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.585214  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.583557  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.581618  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.581744  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.581096  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.581701  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.582114  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.581015  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.581591  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.581640  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.581995  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.581590  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.581512  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.581279  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.580979  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.580208  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.580906  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.580793  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.580801  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.581117  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.581084  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.581276  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.582012  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.581881  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.581839  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.581279  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.580979  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.581261  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.580864  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.581011  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.581109  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.580989  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.580881  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.581189  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.581590  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.582024  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.581892  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.582319  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.582137  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.582155  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.582124  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.582193  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.582072  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.582205  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.581994  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.582121  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.582358  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.582405  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.582264  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.582361  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.582395  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.582424  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.582633  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.582854  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.582797  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.582827  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.582986  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.582805  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.582801  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.582707  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.582788  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.582860  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.582641  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.582851  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.582728  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.582974  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.582919  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.582947  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.582759  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.582806  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.582916  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.582716  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.582762  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.582763  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.582681  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.582628  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.582570  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.582632  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.582627  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.582437  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.582391  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.582325  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.582427  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.582482  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.582414  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.582525  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.582627  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.582462  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.582525  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.582584  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.582606  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.582580  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.582469  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.582348  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.582292  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.582277  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.582148  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.582202  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.582123  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.582164  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.582153  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.582321  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.582316  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.582354  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.582346  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.582162  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.582189  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.582099  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.582033  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.582112  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.582228  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.582177  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.582198  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.582232  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.582328  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.582318  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.582362  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.582457  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.582519  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.582431  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.582437  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.582437  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.582519  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.582416  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.582340  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.582441  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.582436  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.582457  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.582489  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.582383  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.582380  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.582377  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.582299  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.582314  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.582211  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.582073  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.582012  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.582087  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.582002  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.582070  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.582045  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.582202  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.582245  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.582322  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.582279  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.582296  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.582278  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.582238  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.582192  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.582143  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.582142  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.582226  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.582173  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.582208  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.582237  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.582306  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.582343  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.582269  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.582386  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.582316  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.582361  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.582318  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.582344  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.582352  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.582448  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.582407  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.582427  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.582464  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.582493  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.582497  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.582560  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.582556  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.582594  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.582620  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.582643  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.582685  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.582738  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.582769  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.582810  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.582779  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.582771  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.582817  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.582849  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.582889  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.582876  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.582824  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.582833  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.582899  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.582951  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.582983  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.582952  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.582910  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.582820  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.582852  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.582854  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.582873  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.582820  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.582767  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.582694  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.582677  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.582682  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.582618  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.582598  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.582677  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.582607  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.582583  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.582588  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.582550  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.582521  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.582620  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.582655  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.582684  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.582727  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.582687  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.582702  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.582728  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.582711  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.582678  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.582643  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.582640  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.582618  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.582631  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.582663  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.582655  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.582634  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.582642  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.582704  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.582690  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.582651  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.582604  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.582596  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581129\n",
      "@eval_loop_avg_loss=0.578990\n",
      "Epoch 26/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.589756  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.577424  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.579887  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.579691  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.577702  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.582524  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.583997  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.583327  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.581926  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.581810  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.582775  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.582492  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.582679  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.583089  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.582648  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.582925  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.582920  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.582405  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.581405  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.581623  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.581738  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.582423  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.581861  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.582249  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.582846  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.582991  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.583656  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.583652  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.583743  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.583400  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.583339  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.582764  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.582831  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.582628  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.583201  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.583322  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.583200  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.582990  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.583030  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.583148  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.583248  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.583247  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.583175  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.583361  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.583400  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.584010  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.583819  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.583933  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.583851  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.583823  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.583634  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.583738  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.583858  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.583598  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.583524  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.583518  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.583677  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.583605  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.583729  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.583796  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.583505  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.583395  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.583372  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.583170  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.583013  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.582992  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.582608  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.582584  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.582823  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.582567  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.582503  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.582708  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.582570  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.582655  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.582530  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.582551  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.582515  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.582599  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.582690  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.582619  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.582754  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.582671  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.582595  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.582614  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.582552  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.582648  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.582875  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.582798  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.582748  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.582709  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.582824  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.582737  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.582817  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.582999  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.582967  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.582986  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.582864  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.582953  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.583038  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.582993  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.583001  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.582995  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.582945  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.583123  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.583107  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.583065  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.582886  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.582734  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.582776  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.582718  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.582760  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.582748  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.582837  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.582801  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.582861  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.582798  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.582844  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.582751  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.582828  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.582853  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.582942  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.582951  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.582793  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.582776  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.582860  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.582947  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.582913  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.582967  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.582854  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.582790  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.582689  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.582691  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.582684  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.582608  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.582566  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.582574  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.582516  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.582650  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.582608  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.582593  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.582569  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.582646  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.582620  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.582593  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.582515  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.582654  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.582652  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.582700  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.582627  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.582650  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.582557  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.582521  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.582607  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.582701  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.582768  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.582830  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.582865  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.582896  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.582958  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.582891  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.582835  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.582803  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.582832  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.582696  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.582715  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.582740  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.582656  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.582712  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.582696  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.582783  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.582832  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.582845  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.582796  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.582771  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.582767  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.582676  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.582701  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.582639  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.582671  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.582685  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.582700  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.582737  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.582813  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.582817  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.582703  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.582671  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.582603  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.582636  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.582782  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.582727  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.582725  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.582662  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.582655  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.582629  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.582621  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.582665  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.582617  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.582592  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.582644  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.582629  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.582641  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.582704  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.582679  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.582702  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.582767  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.582758  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.582752  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.582761  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.582769  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.582662  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.582652  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.582665  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.582600  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.582585  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.582530  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.582536  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.582511  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.582579  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.582563  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.582563  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.582592  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.582602  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.582605  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.582531  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.582543  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.582520  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.582524  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.582572  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.582524  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.582497  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.582520  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.582502  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.582473  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.582508  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.582478  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580916\n",
      "@eval_loop_avg_loss=0.578774\n",
      "Epoch 27/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.570749  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.582128  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.581017  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.579395  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.578032  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.578763  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.578198  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.579437  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.581170  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.581529  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.582130  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.581923  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.581274  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.581806  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.582465  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.582471  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.582717  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.582422  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.582754  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.583239  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.582647  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.583157  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.583009  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.582623  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.582750  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.583051  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.582245  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.581871  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.582032  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.582147  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.581920  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.581898  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.582211  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.582261  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.582264  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.582184  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.582298  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.582186  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.581865  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.582102  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.582155  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.582172  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.582098  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.582046  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.582192  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.582548  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.582185  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.582189  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.581966  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.581879  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.581835  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.581886  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.581803  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.581597  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.581586  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.581781  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.581767  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.581776  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.581381  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.581301  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.581235  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.581237  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.581156  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.581326  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.581481  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.581462  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.581236  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.581427  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.581352  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.581345  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.581352  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.581149  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.581283  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.581251  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.581295  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.581294  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.581375  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.581294  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.581329  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.581474  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.581657  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.581649  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.581632  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.581805  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.581896  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.581586  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.581443  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.581489  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.581648  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.581777  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.581787  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.581703  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.581687  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.581755  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.581702  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.581714  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.581653  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.581692  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.581519  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.581572  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.581519  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.581491  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.581540  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.581565  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.581559  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.581684  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.581625  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.581781  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.581763  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.581719  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.581720  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.581750  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.581835  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.581705  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.581692  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.581719  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.581830  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.581935  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.582094  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.582151  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.582116  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.581946  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.581996  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.582142  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.582272  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.582223  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.582315  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.582277  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.582177  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.582153  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.582149  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.582155  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.582212  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.582158  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.582153  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.582153  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.582193  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.582240  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.582247  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.582199  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.582236  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.582256  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.582287  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.582309  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.582291  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.582331  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.582288  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.582291  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.582309  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.582330  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.582297  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.582340  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.582410  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.582341  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.582310  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.582275  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.582348  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.582337  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.582313  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.582294  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.582355  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.582412  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.582256  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.582158  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.582162  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.582105  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.582117  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.582154  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.582134  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.582193  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.582206  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.582251  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.582217  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.582231  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.582369  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.582418  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.582383  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.582315  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.582291  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.582280  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.582258  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.582245  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.582337  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.582379  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.582336  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.582305  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.582273  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.582226  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.582246  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.582290  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.582272  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.582334  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.582375  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.582387  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.582474  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.582384  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.582434  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.582416  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.582424  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.582367  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.582381  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.582350  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.582341  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.582279  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.582323  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.582292  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.582295  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.582274  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.582313  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.582267  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.582202  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.582161  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.582156  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.582258  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.582220  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.582321  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.582323  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.582290  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.582275  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.582250  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.582249  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.582268  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.582192  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.582299  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.582277  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.582209  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.582217  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.582242  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.582241  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.582289  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.582291  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.582369  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.582362  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.582376  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.582359  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580862\n",
      "@eval_loop_avg_loss=0.578744\n",
      "Epoch 28/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.579362  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.585872  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.580854  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.582304  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.583088  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.582784  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.583992  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.583537  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.583637  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.583232  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.583402  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.584424  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.584661  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.585375  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.584695  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.584337  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.584135  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.583654  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.583941  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.583725  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.583556  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.583374  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.583272  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.583395  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.583059  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.583589  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.583615  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.583517  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.583784  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.583894  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.584115  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.584123  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.584437  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.584639  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.584537  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.584162  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.584046  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.583877  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.583663  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.583578  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.583405  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.583474  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.583295  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.583475  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.583224  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.583607  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.583652  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.583604  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.583672  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.583669  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.583929  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.583749  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.583660  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.583717  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.583403  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.583416  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.583486  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.583587  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.583531  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.583468  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.583471  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.583420  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.583493  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.583710  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.583652  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.583682  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.583579  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.583479  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.583322  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.583508  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.583460  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.583457  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.583474  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.583366  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.583259  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.583128  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.583027  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.583200  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.583280  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.583214  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.583061  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.583213  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.583412  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.583303  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.583209  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.583212  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.583210  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.583187  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.583299  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.583157  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.582935  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.582809  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.582883  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.582796  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.582646  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.582631  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.582444  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.582457  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.582540  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.582533  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.582358  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.582406  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.582331  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.582220  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.582286  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.582354  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.582339  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.582215  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.582292  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.582370  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.582257  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.582328  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.582316  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.582267  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.582304  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.582377  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.582325  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.582224  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.582268  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.582377  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.582288  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.582127  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.582332  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.582273  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.582214  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.582158  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.582115  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.582189  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.582173  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.582090  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.581935  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.581892  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.581999  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.582030  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.582070  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.582120  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.582163  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.582223  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.582218  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.582252  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.582162  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.582198  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.582286  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.582271  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.582330  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.582280  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.582155  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.582118  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.582089  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.582031  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.581948  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.581898  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.581916  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.581897  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.581906  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.581939  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.582024  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.582033  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.582020  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.581948  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.582011  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.582067  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.582139  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.582162  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.582214  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.582165  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.582150  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.582131  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.582185  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.582138  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.582104  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.582170  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.582188  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.582285  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.582250  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.582258  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.582259  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.582224  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.582195  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.582242  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.582245  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.582344  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.582430  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.582509  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.582496  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.582450  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.582374  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.582288  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.582302  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.582310  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.582338  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.582388  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.582360  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.582422  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.582472  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.582356  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.582385  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.582357  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.582377  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.582374  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.582390  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.582428  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.582425  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.582466  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.582440  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.582532  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.582488  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.582487  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.582483  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.582513  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.582525  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.582484  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.582459  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.582461  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.582498  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.582516  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.582505  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.582493  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.582510  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.582466  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.582408  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.582389  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.582402  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.582424  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.582472  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.582484  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.582453  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.582392  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.582362  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.582349  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.582381  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.582362  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.582297  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.582283  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.582277  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580698\n",
      "@eval_loop_avg_loss=0.578578\n",
      "Epoch 29/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.593403  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.577958  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.573263  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.573779  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.574431  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.573631  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.577790  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.578417  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.577977  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.578890  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.578770  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.577880  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.578446  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.579624  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.579414  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.578767  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.579420  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.580212  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.580451  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.579734  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.579353  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.579945  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.580087  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.580744  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.580442  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.580383  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.580640  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.581146  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.581288  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.581265  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.581126  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.581247  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.581218  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.581841  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.581869  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.581792  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.582143  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.582014  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.581675  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.581857  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.581955  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.581995  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.581894  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.581808  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.581753  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.581390  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.581523  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.581558  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.581732  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.581614  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.581716  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.581583  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.581867  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.581629  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.581653  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.581652  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.581625  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.581766  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.581413  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.581607  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.581634  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.581919  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.582049  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.581953  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.581925  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.582043  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.582198  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.582055  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.581982  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.581834  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.582144  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.582363  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.582285  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.582430  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.582438  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.582572  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.582629  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.582543  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.582417  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.582316  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.582271  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.582038  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.582086  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.582114  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.582343  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.582413  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.582452  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.582315  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.582420  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.582457  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.582522  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.582469  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.582313  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.582397  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.582497  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.582669  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.582549  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.582616  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.582709  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.582663  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.582686  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.582768  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.582786  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.582727  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.582789  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.582725  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.582712  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.582601  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.582639  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.582670  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.582881  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.582861  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.582819  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.582858  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.582833  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.582653  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.582572  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.582660  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.582709  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.582719  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.582697  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.582692  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.582700  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.582773  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.582770  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.582722  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.582656  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.582601  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.582501  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.582512  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.582467  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.582539  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.582663  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.582791  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.582812  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.582785  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.582716  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.582671  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.582599  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.582524  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.582512  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.582503  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.582636  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.582647  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.582739  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.582806  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.582829  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.582907  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.582848  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.582722  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.582715  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.582621  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.582622  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.582676  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.582655  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.582598  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.582504  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.582608  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.582576  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.582680  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.582746  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.582704  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.582681  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.582649  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.582717  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.582678  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.582648  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.582615  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.582544  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.582611  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.582625  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.582639  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.582672  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.582703  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.582737  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.582647  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.582688  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.582644  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.582588  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.582562  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.582519  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.582560  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.582542  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.582520  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.582582  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.582614  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.582661  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.582673  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.582637  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.582623  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.582546  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.582508  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.582564  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.582549  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.582461  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.582407  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.582408  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.582462  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.582374  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.582320  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.582348  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.582330  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.582344  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.582366  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.582417  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.582437  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.582390  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.582391  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.582370  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.582361  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.582375  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.582320  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.582199  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.582240  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.582253  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.582267  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.582340  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.582340  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.582338  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.582292  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.582327  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.582348  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.582365  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.582258  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.582280  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.582276  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.582157  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.582088  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.582161  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.582106  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.582151  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.582173  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.582158  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.582155  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.582178  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580749\n",
      "@eval_loop_avg_loss=0.578632\n",
      "Epoch 30/30:\n",
      "-------------------------------\n",
      "  Batch     0/  235 - avrg_Loss: 0.573254  processed_samples: 0.426667%\n",
      "  Batch     1/  235 - avrg_Loss: 0.588409  processed_samples: 0.853333%\n",
      "  Batch     2/  235 - avrg_Loss: 0.583528  processed_samples: 1.280000%\n",
      "  Batch     3/  235 - avrg_Loss: 0.584596  processed_samples: 1.706667%\n",
      "  Batch     4/  235 - avrg_Loss: 0.586316  processed_samples: 2.133333%\n",
      "  Batch     5/  235 - avrg_Loss: 0.586356  processed_samples: 2.560000%\n",
      "  Batch     6/  235 - avrg_Loss: 0.585210  processed_samples: 2.986667%\n",
      "  Batch     7/  235 - avrg_Loss: 0.584213  processed_samples: 3.413333%\n",
      "  Batch     8/  235 - avrg_Loss: 0.583840  processed_samples: 3.840000%\n",
      "  Batch     9/  235 - avrg_Loss: 0.583754  processed_samples: 4.266667%\n",
      "  Batch    10/  235 - avrg_Loss: 0.583162  processed_samples: 4.693333%\n",
      "  Batch    11/  235 - avrg_Loss: 0.582063  processed_samples: 5.120000%\n",
      "  Batch    12/  235 - avrg_Loss: 0.582090  processed_samples: 5.546667%\n",
      "  Batch    13/  235 - avrg_Loss: 0.582025  processed_samples: 5.973333%\n",
      "  Batch    14/  235 - avrg_Loss: 0.581521  processed_samples: 6.400000%\n",
      "  Batch    15/  235 - avrg_Loss: 0.581769  processed_samples: 6.826667%\n",
      "  Batch    16/  235 - avrg_Loss: 0.581685  processed_samples: 7.253333%\n",
      "  Batch    17/  235 - avrg_Loss: 0.581657  processed_samples: 7.680000%\n",
      "  Batch    18/  235 - avrg_Loss: 0.581458  processed_samples: 8.106667%\n",
      "  Batch    19/  235 - avrg_Loss: 0.581666  processed_samples: 8.533333%\n",
      "  Batch    20/  235 - avrg_Loss: 0.581361  processed_samples: 8.960000%\n",
      "  Batch    21/  235 - avrg_Loss: 0.581465  processed_samples: 9.386667%\n",
      "  Batch    22/  235 - avrg_Loss: 0.581252  processed_samples: 9.813333%\n",
      "  Batch    23/  235 - avrg_Loss: 0.581275  processed_samples: 10.240000%\n",
      "  Batch    24/  235 - avrg_Loss: 0.581286  processed_samples: 10.666667%\n",
      "  Batch    25/  235 - avrg_Loss: 0.580753  processed_samples: 11.093333%\n",
      "  Batch    26/  235 - avrg_Loss: 0.581053  processed_samples: 11.520000%\n",
      "  Batch    27/  235 - avrg_Loss: 0.581025  processed_samples: 11.946667%\n",
      "  Batch    28/  235 - avrg_Loss: 0.581030  processed_samples: 12.373333%\n",
      "  Batch    29/  235 - avrg_Loss: 0.580815  processed_samples: 12.800000%\n",
      "  Batch    30/  235 - avrg_Loss: 0.580817  processed_samples: 13.226667%\n",
      "  Batch    31/  235 - avrg_Loss: 0.580763  processed_samples: 13.653333%\n",
      "  Batch    32/  235 - avrg_Loss: 0.580493  processed_samples: 14.080000%\n",
      "  Batch    33/  235 - avrg_Loss: 0.580543  processed_samples: 14.506667%\n",
      "  Batch    34/  235 - avrg_Loss: 0.580103  processed_samples: 14.933333%\n",
      "  Batch    35/  235 - avrg_Loss: 0.579845  processed_samples: 15.360000%\n",
      "  Batch    36/  235 - avrg_Loss: 0.580297  processed_samples: 15.786667%\n",
      "  Batch    37/  235 - avrg_Loss: 0.579966  processed_samples: 16.213333%\n",
      "  Batch    38/  235 - avrg_Loss: 0.580157  processed_samples: 16.640000%\n",
      "  Batch    39/  235 - avrg_Loss: 0.580346  processed_samples: 17.066667%\n",
      "  Batch    40/  235 - avrg_Loss: 0.580413  processed_samples: 17.493333%\n",
      "  Batch    41/  235 - avrg_Loss: 0.580340  processed_samples: 17.920000%\n",
      "  Batch    42/  235 - avrg_Loss: 0.580264  processed_samples: 18.346667%\n",
      "  Batch    43/  235 - avrg_Loss: 0.580641  processed_samples: 18.773333%\n",
      "  Batch    44/  235 - avrg_Loss: 0.580567  processed_samples: 19.200000%\n",
      "  Batch    45/  235 - avrg_Loss: 0.580696  processed_samples: 19.626667%\n",
      "  Batch    46/  235 - avrg_Loss: 0.580567  processed_samples: 20.053333%\n",
      "  Batch    47/  235 - avrg_Loss: 0.580386  processed_samples: 20.480000%\n",
      "  Batch    48/  235 - avrg_Loss: 0.580214  processed_samples: 20.906667%\n",
      "  Batch    49/  235 - avrg_Loss: 0.580188  processed_samples: 21.333333%\n",
      "  Batch    50/  235 - avrg_Loss: 0.580363  processed_samples: 21.760000%\n",
      "  Batch    51/  235 - avrg_Loss: 0.580682  processed_samples: 22.186667%\n",
      "  Batch    52/  235 - avrg_Loss: 0.580489  processed_samples: 22.613333%\n",
      "  Batch    53/  235 - avrg_Loss: 0.580708  processed_samples: 23.040000%\n",
      "  Batch    54/  235 - avrg_Loss: 0.580866  processed_samples: 23.466667%\n",
      "  Batch    55/  235 - avrg_Loss: 0.580909  processed_samples: 23.893333%\n",
      "  Batch    56/  235 - avrg_Loss: 0.580905  processed_samples: 24.320000%\n",
      "  Batch    57/  235 - avrg_Loss: 0.580991  processed_samples: 24.746667%\n",
      "  Batch    58/  235 - avrg_Loss: 0.581122  processed_samples: 25.173333%\n",
      "  Batch    59/  235 - avrg_Loss: 0.581282  processed_samples: 25.600000%\n",
      "  Batch    60/  235 - avrg_Loss: 0.581382  processed_samples: 26.026667%\n",
      "  Batch    61/  235 - avrg_Loss: 0.581505  processed_samples: 26.453333%\n",
      "  Batch    62/  235 - avrg_Loss: 0.581548  processed_samples: 26.880000%\n",
      "  Batch    63/  235 - avrg_Loss: 0.581555  processed_samples: 27.306667%\n",
      "  Batch    64/  235 - avrg_Loss: 0.581556  processed_samples: 27.733333%\n",
      "  Batch    65/  235 - avrg_Loss: 0.581537  processed_samples: 28.160000%\n",
      "  Batch    66/  235 - avrg_Loss: 0.581602  processed_samples: 28.586667%\n",
      "  Batch    67/  235 - avrg_Loss: 0.581592  processed_samples: 29.013333%\n",
      "  Batch    68/  235 - avrg_Loss: 0.581629  processed_samples: 29.440000%\n",
      "  Batch    69/  235 - avrg_Loss: 0.581655  processed_samples: 29.866667%\n",
      "  Batch    70/  235 - avrg_Loss: 0.581502  processed_samples: 30.293333%\n",
      "  Batch    71/  235 - avrg_Loss: 0.581539  processed_samples: 30.720000%\n",
      "  Batch    72/  235 - avrg_Loss: 0.581588  processed_samples: 31.146667%\n",
      "  Batch    73/  235 - avrg_Loss: 0.581508  processed_samples: 31.573333%\n",
      "  Batch    74/  235 - avrg_Loss: 0.581557  processed_samples: 32.000000%\n",
      "  Batch    75/  235 - avrg_Loss: 0.581652  processed_samples: 32.426667%\n",
      "  Batch    76/  235 - avrg_Loss: 0.581701  processed_samples: 32.853333%\n",
      "  Batch    77/  235 - avrg_Loss: 0.581716  processed_samples: 33.280000%\n",
      "  Batch    78/  235 - avrg_Loss: 0.581782  processed_samples: 33.706667%\n",
      "  Batch    79/  235 - avrg_Loss: 0.581748  processed_samples: 34.133333%\n",
      "  Batch    80/  235 - avrg_Loss: 0.581678  processed_samples: 34.560000%\n",
      "  Batch    81/  235 - avrg_Loss: 0.581797  processed_samples: 34.986667%\n",
      "  Batch    82/  235 - avrg_Loss: 0.581927  processed_samples: 35.413333%\n",
      "  Batch    83/  235 - avrg_Loss: 0.582054  processed_samples: 35.840000%\n",
      "  Batch    84/  235 - avrg_Loss: 0.582094  processed_samples: 36.266667%\n",
      "  Batch    85/  235 - avrg_Loss: 0.582080  processed_samples: 36.693333%\n",
      "  Batch    86/  235 - avrg_Loss: 0.582113  processed_samples: 37.120000%\n",
      "  Batch    87/  235 - avrg_Loss: 0.582149  processed_samples: 37.546667%\n",
      "  Batch    88/  235 - avrg_Loss: 0.582177  processed_samples: 37.973333%\n",
      "  Batch    89/  235 - avrg_Loss: 0.582373  processed_samples: 38.400000%\n",
      "  Batch    90/  235 - avrg_Loss: 0.582313  processed_samples: 38.826667%\n",
      "  Batch    91/  235 - avrg_Loss: 0.582261  processed_samples: 39.253333%\n",
      "  Batch    92/  235 - avrg_Loss: 0.582313  processed_samples: 39.680000%\n",
      "  Batch    93/  235 - avrg_Loss: 0.582371  processed_samples: 40.106667%\n",
      "  Batch    94/  235 - avrg_Loss: 0.582319  processed_samples: 40.533333%\n",
      "  Batch    95/  235 - avrg_Loss: 0.582326  processed_samples: 40.960000%\n",
      "  Batch    96/  235 - avrg_Loss: 0.582290  processed_samples: 41.386667%\n",
      "  Batch    97/  235 - avrg_Loss: 0.582194  processed_samples: 41.813333%\n",
      "  Batch    98/  235 - avrg_Loss: 0.582032  processed_samples: 42.240000%\n",
      "  Batch    99/  235 - avrg_Loss: 0.582080  processed_samples: 42.666667%\n",
      "  Batch   100/  235 - avrg_Loss: 0.582219  processed_samples: 43.093333%\n",
      "  Batch   101/  235 - avrg_Loss: 0.582323  processed_samples: 43.520000%\n",
      "  Batch   102/  235 - avrg_Loss: 0.582309  processed_samples: 43.946667%\n",
      "  Batch   103/  235 - avrg_Loss: 0.582274  processed_samples: 44.373333%\n",
      "  Batch   104/  235 - avrg_Loss: 0.582294  processed_samples: 44.800000%\n",
      "  Batch   105/  235 - avrg_Loss: 0.582362  processed_samples: 45.226667%\n",
      "  Batch   106/  235 - avrg_Loss: 0.582302  processed_samples: 45.653333%\n",
      "  Batch   107/  235 - avrg_Loss: 0.582336  processed_samples: 46.080000%\n",
      "  Batch   108/  235 - avrg_Loss: 0.582363  processed_samples: 46.506667%\n",
      "  Batch   109/  235 - avrg_Loss: 0.582281  processed_samples: 46.933333%\n",
      "  Batch   110/  235 - avrg_Loss: 0.582188  processed_samples: 47.360000%\n",
      "  Batch   111/  235 - avrg_Loss: 0.582160  processed_samples: 47.786667%\n",
      "  Batch   112/  235 - avrg_Loss: 0.582025  processed_samples: 48.213333%\n",
      "  Batch   113/  235 - avrg_Loss: 0.582155  processed_samples: 48.640000%\n",
      "  Batch   114/  235 - avrg_Loss: 0.582088  processed_samples: 49.066667%\n",
      "  Batch   115/  235 - avrg_Loss: 0.582088  processed_samples: 49.493333%\n",
      "  Batch   116/  235 - avrg_Loss: 0.582065  processed_samples: 49.920000%\n",
      "  Batch   117/  235 - avrg_Loss: 0.581998  processed_samples: 50.346667%\n",
      "  Batch   118/  235 - avrg_Loss: 0.581956  processed_samples: 50.773333%\n",
      "  Batch   119/  235 - avrg_Loss: 0.581909  processed_samples: 51.200000%\n",
      "  Batch   120/  235 - avrg_Loss: 0.581926  processed_samples: 51.626667%\n",
      "  Batch   121/  235 - avrg_Loss: 0.581871  processed_samples: 52.053333%\n",
      "  Batch   122/  235 - avrg_Loss: 0.581923  processed_samples: 52.480000%\n",
      "  Batch   123/  235 - avrg_Loss: 0.581834  processed_samples: 52.906667%\n",
      "  Batch   124/  235 - avrg_Loss: 0.581809  processed_samples: 53.333333%\n",
      "  Batch   125/  235 - avrg_Loss: 0.581826  processed_samples: 53.760000%\n",
      "  Batch   126/  235 - avrg_Loss: 0.581848  processed_samples: 54.186667%\n",
      "  Batch   127/  235 - avrg_Loss: 0.581858  processed_samples: 54.613333%\n",
      "  Batch   128/  235 - avrg_Loss: 0.581826  processed_samples: 55.040000%\n",
      "  Batch   129/  235 - avrg_Loss: 0.581828  processed_samples: 55.466667%\n",
      "  Batch   130/  235 - avrg_Loss: 0.581816  processed_samples: 55.893333%\n",
      "  Batch   131/  235 - avrg_Loss: 0.581813  processed_samples: 56.320000%\n",
      "  Batch   132/  235 - avrg_Loss: 0.581822  processed_samples: 56.746667%\n",
      "  Batch   133/  235 - avrg_Loss: 0.581748  processed_samples: 57.173333%\n",
      "  Batch   134/  235 - avrg_Loss: 0.581764  processed_samples: 57.600000%\n",
      "  Batch   135/  235 - avrg_Loss: 0.581718  processed_samples: 58.026667%\n",
      "  Batch   136/  235 - avrg_Loss: 0.581705  processed_samples: 58.453333%\n",
      "  Batch   137/  235 - avrg_Loss: 0.581760  processed_samples: 58.880000%\n",
      "  Batch   138/  235 - avrg_Loss: 0.581742  processed_samples: 59.306667%\n",
      "  Batch   139/  235 - avrg_Loss: 0.581827  processed_samples: 59.733333%\n",
      "  Batch   140/  235 - avrg_Loss: 0.581802  processed_samples: 60.160000%\n",
      "  Batch   141/  235 - avrg_Loss: 0.581672  processed_samples: 60.586667%\n",
      "  Batch   142/  235 - avrg_Loss: 0.581697  processed_samples: 61.013333%\n",
      "  Batch   143/  235 - avrg_Loss: 0.581686  processed_samples: 61.440000%\n",
      "  Batch   144/  235 - avrg_Loss: 0.581745  processed_samples: 61.866667%\n",
      "  Batch   145/  235 - avrg_Loss: 0.581802  processed_samples: 62.293333%\n",
      "  Batch   146/  235 - avrg_Loss: 0.581865  processed_samples: 62.720000%\n",
      "  Batch   147/  235 - avrg_Loss: 0.581859  processed_samples: 63.146667%\n",
      "  Batch   148/  235 - avrg_Loss: 0.581909  processed_samples: 63.573333%\n",
      "  Batch   149/  235 - avrg_Loss: 0.581915  processed_samples: 64.000000%\n",
      "  Batch   150/  235 - avrg_Loss: 0.581956  processed_samples: 64.426667%\n",
      "  Batch   151/  235 - avrg_Loss: 0.581924  processed_samples: 64.853333%\n",
      "  Batch   152/  235 - avrg_Loss: 0.581976  processed_samples: 65.280000%\n",
      "  Batch   153/  235 - avrg_Loss: 0.581861  processed_samples: 65.706667%\n",
      "  Batch   154/  235 - avrg_Loss: 0.581853  processed_samples: 66.133333%\n",
      "  Batch   155/  235 - avrg_Loss: 0.581755  processed_samples: 66.560000%\n",
      "  Batch   156/  235 - avrg_Loss: 0.581838  processed_samples: 66.986667%\n",
      "  Batch   157/  235 - avrg_Loss: 0.581887  processed_samples: 67.413333%\n",
      "  Batch   158/  235 - avrg_Loss: 0.581890  processed_samples: 67.840000%\n",
      "  Batch   159/  235 - avrg_Loss: 0.581864  processed_samples: 68.266667%\n",
      "  Batch   160/  235 - avrg_Loss: 0.581998  processed_samples: 68.693333%\n",
      "  Batch   161/  235 - avrg_Loss: 0.582009  processed_samples: 69.120000%\n",
      "  Batch   162/  235 - avrg_Loss: 0.581963  processed_samples: 69.546667%\n",
      "  Batch   163/  235 - avrg_Loss: 0.581912  processed_samples: 69.973333%\n",
      "  Batch   164/  235 - avrg_Loss: 0.581784  processed_samples: 70.400000%\n",
      "  Batch   165/  235 - avrg_Loss: 0.581859  processed_samples: 70.826667%\n",
      "  Batch   166/  235 - avrg_Loss: 0.581858  processed_samples: 71.253333%\n",
      "  Batch   167/  235 - avrg_Loss: 0.581817  processed_samples: 71.680000%\n",
      "  Batch   168/  235 - avrg_Loss: 0.581757  processed_samples: 72.106667%\n",
      "  Batch   169/  235 - avrg_Loss: 0.581693  processed_samples: 72.533333%\n",
      "  Batch   170/  235 - avrg_Loss: 0.581651  processed_samples: 72.960000%\n",
      "  Batch   171/  235 - avrg_Loss: 0.581723  processed_samples: 73.386667%\n",
      "  Batch   172/  235 - avrg_Loss: 0.581747  processed_samples: 73.813333%\n",
      "  Batch   173/  235 - avrg_Loss: 0.581771  processed_samples: 74.240000%\n",
      "  Batch   174/  235 - avrg_Loss: 0.581748  processed_samples: 74.666667%\n",
      "  Batch   175/  235 - avrg_Loss: 0.581772  processed_samples: 75.093333%\n",
      "  Batch   176/  235 - avrg_Loss: 0.581774  processed_samples: 75.520000%\n",
      "  Batch   177/  235 - avrg_Loss: 0.581743  processed_samples: 75.946667%\n",
      "  Batch   178/  235 - avrg_Loss: 0.581783  processed_samples: 76.373333%\n",
      "  Batch   179/  235 - avrg_Loss: 0.581766  processed_samples: 76.800000%\n",
      "  Batch   180/  235 - avrg_Loss: 0.581778  processed_samples: 77.226667%\n",
      "  Batch   181/  235 - avrg_Loss: 0.581907  processed_samples: 77.653333%\n",
      "  Batch   182/  235 - avrg_Loss: 0.581946  processed_samples: 78.080000%\n",
      "  Batch   183/  235 - avrg_Loss: 0.581946  processed_samples: 78.506667%\n",
      "  Batch   184/  235 - avrg_Loss: 0.581907  processed_samples: 78.933333%\n",
      "  Batch   185/  235 - avrg_Loss: 0.581884  processed_samples: 79.360000%\n",
      "  Batch   186/  235 - avrg_Loss: 0.581926  processed_samples: 79.786667%\n",
      "  Batch   187/  235 - avrg_Loss: 0.581892  processed_samples: 80.213333%\n",
      "  Batch   188/  235 - avrg_Loss: 0.581955  processed_samples: 80.640000%\n",
      "  Batch   189/  235 - avrg_Loss: 0.581928  processed_samples: 81.066667%\n",
      "  Batch   190/  235 - avrg_Loss: 0.581915  processed_samples: 81.493333%\n",
      "  Batch   191/  235 - avrg_Loss: 0.581898  processed_samples: 81.920000%\n",
      "  Batch   192/  235 - avrg_Loss: 0.581857  processed_samples: 82.346667%\n",
      "  Batch   193/  235 - avrg_Loss: 0.581770  processed_samples: 82.773333%\n",
      "  Batch   194/  235 - avrg_Loss: 0.581737  processed_samples: 83.200000%\n",
      "  Batch   195/  235 - avrg_Loss: 0.581684  processed_samples: 83.626667%\n",
      "  Batch   196/  235 - avrg_Loss: 0.581667  processed_samples: 84.053333%\n",
      "  Batch   197/  235 - avrg_Loss: 0.581630  processed_samples: 84.480000%\n",
      "  Batch   198/  235 - avrg_Loss: 0.581631  processed_samples: 84.906667%\n",
      "  Batch   199/  235 - avrg_Loss: 0.581596  processed_samples: 85.333333%\n",
      "  Batch   200/  235 - avrg_Loss: 0.581605  processed_samples: 85.760000%\n",
      "  Batch   201/  235 - avrg_Loss: 0.581655  processed_samples: 86.186667%\n",
      "  Batch   202/  235 - avrg_Loss: 0.581594  processed_samples: 86.613333%\n",
      "  Batch   203/  235 - avrg_Loss: 0.581611  processed_samples: 87.040000%\n",
      "  Batch   204/  235 - avrg_Loss: 0.581637  processed_samples: 87.466667%\n",
      "  Batch   205/  235 - avrg_Loss: 0.581676  processed_samples: 87.893333%\n",
      "  Batch   206/  235 - avrg_Loss: 0.581684  processed_samples: 88.320000%\n",
      "  Batch   207/  235 - avrg_Loss: 0.581792  processed_samples: 88.746667%\n",
      "  Batch   208/  235 - avrg_Loss: 0.581801  processed_samples: 89.173333%\n",
      "  Batch   209/  235 - avrg_Loss: 0.581760  processed_samples: 89.600000%\n",
      "  Batch   210/  235 - avrg_Loss: 0.581738  processed_samples: 90.026667%\n",
      "  Batch   211/  235 - avrg_Loss: 0.581710  processed_samples: 90.453333%\n",
      "  Batch   212/  235 - avrg_Loss: 0.581756  processed_samples: 90.880000%\n",
      "  Batch   213/  235 - avrg_Loss: 0.581766  processed_samples: 91.306667%\n",
      "  Batch   214/  235 - avrg_Loss: 0.581823  processed_samples: 91.733333%\n",
      "  Batch   215/  235 - avrg_Loss: 0.581830  processed_samples: 92.160000%\n",
      "  Batch   216/  235 - avrg_Loss: 0.581923  processed_samples: 92.586667%\n",
      "  Batch   217/  235 - avrg_Loss: 0.581952  processed_samples: 93.013333%\n",
      "  Batch   218/  235 - avrg_Loss: 0.582004  processed_samples: 93.440000%\n",
      "  Batch   219/  235 - avrg_Loss: 0.581993  processed_samples: 93.866667%\n",
      "  Batch   220/  235 - avrg_Loss: 0.581939  processed_samples: 94.293333%\n",
      "  Batch   221/  235 - avrg_Loss: 0.581974  processed_samples: 94.720000%\n",
      "  Batch   222/  235 - avrg_Loss: 0.581990  processed_samples: 95.146667%\n",
      "  Batch   223/  235 - avrg_Loss: 0.582028  processed_samples: 95.573333%\n",
      "  Batch   224/  235 - avrg_Loss: 0.582034  processed_samples: 96.000000%\n",
      "  Batch   225/  235 - avrg_Loss: 0.582062  processed_samples: 96.426667%\n",
      "  Batch   226/  235 - avrg_Loss: 0.582074  processed_samples: 96.853333%\n",
      "  Batch   227/  235 - avrg_Loss: 0.582074  processed_samples: 97.280000%\n",
      "  Batch   228/  235 - avrg_Loss: 0.582014  processed_samples: 97.706667%\n",
      "  Batch   229/  235 - avrg_Loss: 0.582039  processed_samples: 98.133333%\n",
      "  Batch   230/  235 - avrg_Loss: 0.582044  processed_samples: 98.560000%\n",
      "  Batch   231/  235 - avrg_Loss: 0.582067  processed_samples: 98.986667%\n",
      "  Batch   232/  235 - avrg_Loss: 0.582056  processed_samples: 99.413333%\n",
      "  Batch   233/  235 - avrg_Loss: 0.582068  processed_samples: 99.840000%\n",
      "  Batch   234/  235 - avrg_Loss: 0.582071  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580578\n",
      "@eval_loop_avg_loss=0.578473\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "#5.8) y 5.9)\n",
    "num_epochs = 30\n",
    "list_train_avg_loss_incorrecta = []\n",
    "list_train_avg_loss = []\n",
    "list_valid_avg_loss = []\n",
    "list_train_precisiom_incorrecta = []\n",
    "list_train_precision = []\n",
    "list_valid_precision = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\\n-------------------------------\")\n",
    "    train_avg_loss_incorrecta = train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    train_avg_loss = valid_loop(train_loader, model, loss_fn)\n",
    "    valid_avg_loss = valid_loop(valid_loader, model, loss_fn)\n",
    "\n",
    "    list_train_avg_loss_incorrecta.append(train_avg_loss_incorrecta)\n",
    "\n",
    "    list_train_avg_loss.append(train_avg_loss)\n",
    "    list_valid_avg_loss.append(valid_avg_loss)\n",
    "\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado como: model_20251209_180825.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#cargamos el modelo guardado\\nmodel = NeuralNetwork(128, 0.2)\\nnombre = \"./TP_FINAL/CASO0/caso0.pth\"\\nmodel.load_state_dict(torch.load(nombre))\\nmodel = model.to(device)\\nmodel.eval()\\n'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"model_{timestamp}.pth\"\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'list_train_avg_loss_incorrecta': list_train_avg_loss_incorrecta,\n",
    "    'list_train_avg_loss': list_train_avg_loss,\n",
    "    'list_valid_avg_loss': list_valid_avg_loss\n",
    "    }, filename)\n",
    "print(\"Guardado como:\", filename)\n",
    "'''\n",
    "#cargamos el modelo guardado\n",
    "model = NeuralNetwork(128, 0.2)\n",
    "nombre = \"./TP_FINAL/CASO0/caso0.pth\"\n",
    "model.load_state_dict(torch.load(nombre))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# probando la red entrenada con un ejemplito\n",
    "numero_img = 0\n",
    "imgs_before = []\n",
    "imgs_after = []\n",
    "for i in range(5):  # Cambiamos el rango para probar varias imágenes\n",
    "    dataiter = iter(valid_loader)\n",
    "    images, labels = next(dataiter)\n",
    "\n",
    "    img = images[numero_img]  # Agregar dimensión de batch\n",
    "    imgs_before.append(img.cpu().squeeze())\n",
    "    # Pasar la imagen por el modelo\n",
    "    with torch.no_grad():\n",
    "        img = img.to(device)\n",
    "        output = model(img.unsqueeze(0))  # Agregar dimensión de batch\n",
    "        imgs_after.append(output.cpu().squeeze())\n",
    "\n",
    "#comparacion imagen original vs reconstruida\n",
    "#imagen:\n",
    "figure = plt.figure()\n",
    "#ajustamos el tamaño de la figura\n",
    "figure.set_size_inches(10, 5)  # Ajusta el tamaño de la figura\n",
    "cols,rows = 5,2\n",
    "#graficamos arriba las 5 figuras originales y abajo las 5 reconstruidas\n",
    "for i in range(len(imgs_before)):\n",
    "    figure.add_subplot(rows,cols,i+1)\n",
    "    plt.imshow(imgs_before[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "for i in range(len(imgs_after)):\n",
    "    figure.add_subplot(rows,cols,i+1+5)  # Agregamos las imágenes reconstruidas en la segunda fila\n",
    "    plt.imshow(imgs_after[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nplt.xlabel(\"Epoch\")\\nplt.ylabel(\"Precision\")\\nplt.plot(range(1,len(list_train_precisiom_incorrecta)+1),  list_train_precisiom_incorrecta, label=\"Train Precision Incorrecta\",linestyle=\\'-\\', c=\\'red\\')\\nplt.plot(range(1,len(list_train_precision)+1),  list_train_precision, label=\"Train Precision\",linestyle=\\'-\\', c=\\'green\\')\\nplt.plot(range(1,len(list_valid_precision)+1), list_valid_precision, label=\"Valid Precision\",linestyle=\\'--\\', c=\\'blue\\')\\nplt.legend()\\n#plt.title(\"\")\\nplt.show() '"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.10)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.plot(range(1,len(list_train_avg_loss_incorrecta)+1), list_train_avg_loss_incorrecta, label=\"Train Loss Incorrecta\",linestyle='-', c='red')\n",
    "plt.plot(range(1,len(list_train_avg_loss)+1), list_train_avg_loss, label=\"Train Loss\",linestyle='-.', c='green')\n",
    "plt.plot(range(1,len(list_valid_avg_loss)+1), list_valid_avg_loss, label=\"Valid Loss\",linestyle='--', c='blue')\n",
    "plt.legend()\n",
    "#plt.title(\"\")\n",
    "plt.show()\n",
    "'''\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.plot(range(1,len(list_train_precisiom_incorrecta)+1),  list_train_precisiom_incorrecta, label=\"Train Precision Incorrecta\",linestyle='-', c='red')\n",
    "plt.plot(range(1,len(list_train_precision)+1),  list_train_precision, label=\"Train Precision\",linestyle='-', c='green')\n",
    "plt.plot(range(1,len(list_valid_precision)+1), list_valid_precision, label=\"Valid Precision\",linestyle='--', c='blue')\n",
    "plt.legend()\n",
    "#plt.title(\"\")\n",
    "plt.show() '''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
