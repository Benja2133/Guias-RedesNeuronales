{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRYEofSD0xoF"
   },
   "source": [
    "# PyTorch: Autoencoder convolucional Fashion-MNIST\n",
    "\n",
    "## Refs.\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "\n",
    "* https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "* https://github.com/pranay414/Fashion-MNIST-Pytorch/blob/master/fashion_mnist.ipynb\n",
    "\n",
    "## **Ejercicio 1)** Importando librerías\n",
    "\n",
    "**0)** De ser necesario, **instale PyTorch** escribiendo\n",
    "\n",
    "    !pip3 install torch torchvision torchaudio torchviz\n",
    "\n",
    "**1)** Importe las librerías estandard de Python: `os`, `datetime`, `collections` y `pickle`.\n",
    "\n",
    "**2)** Importe las siguientes librerías third party de Python: `matplotlib.pyplot`, `numpy`, `scipy`, `sklearn`, `pandas`, `dill` y `json`.\n",
    "\n",
    "**3)** Importe las librerias necesarias de **PyTorch**: `torch` y `torchvision`.\n",
    "\n",
    "**4)** Importe la librería: `google.colab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multiprocessing\n",
    "#multiprocessing.set_start_method(\"spawn\", force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jg3VSqHCGSub",
    "outputId": "45f624ae-5aa6-49e2-9116-c43b311bf3f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /home/benjamin/.local/lib/python3.10/site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in /home/benjamin/.local/lib/python3.10/site-packages (0.22.1+cu118)\n",
      "Requirement already satisfied: torchaudio in /home/benjamin/.local/lib/python3.10/site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (10.3.0.86)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: networkx in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: filelock in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.8.86)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.11.3.6)\n",
      "Requirement already satisfied: fsspec in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/benjamin/.local/lib/python3.10/site-packages (from torch) (11.8.87)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/lib/python3/dist-packages (from triton==3.3.1->torch) (59.6.0)\n",
      "Requirement already satisfied: numpy in /home/benjamin/.local/lib/python3.10/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/benjamin/.local/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/benjamin/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# 1.0)\n",
    "#!pip3 install torch torchvision torchaudio torchviz\n",
    "# ¡Instalación con Pip apuntando directamente a la versión 11.8!\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "I8N3D_nU1_oT"
   },
   "outputs": [],
   "source": [
    "# 1.1)\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "QsfFvPYhkCGl"
   },
   "outputs": [],
   "source": [
    "# 1.2)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg as linalg\n",
    "#import sklearn as skl\n",
    "import pandas as pd\n",
    "#import dill\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Uot5sVNnkCNa"
   },
   "outputs": [],
   "source": [
    "# 1.3\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "#from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rVCiYt-1kCUi"
   },
   "outputs": [],
   "source": [
    "# 1.4)\n",
    "#import google.colab\n",
    "#from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "oUFvWw_kr7Bt",
    "outputId": "44d01453-6867-4827-cae1-5091bb2bf694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcaGEHAd10sb"
   },
   "source": [
    "## **Ejercicio 2)**\n",
    "\n",
    "Bajando y Jugando con el dataset **Fashion-MNIST**.\n",
    "\n",
    "**1)** Baje y transforme los conjuntos de entrenamiento y testeo de FashionMNIST.\n",
    "\n",
    "**2)** Grafique un mosaico de 3x3 imagenes de FashionMNIST, cada una titulada con su respectiva clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUoQ9bnwaZ7O",
    "outputId": "ad7eff68-8c23-4f71-eb71-2f1179f4e38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# 2.1)\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data\n",
    "train_set_orig = datasets.FashionMNIST('MNIST_data/', download = True, train = True,  transform = transform)\n",
    "valid_set_orig = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)\n",
    "\n",
    "\n",
    "print(len(train_set_orig))  # 60000\n",
    "print(len(valid_set_orig))        # 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "-wJdl9mKx5EC",
    "outputId": "ea41b46d-7034-43df-f087-bb7c1803b254"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2.2)\n",
    "figure = plt.figure()\n",
    "cols,rows = 3,3\n",
    "for i in range(1,cols*rows+1):\n",
    "    j = torch.randint(len(train_set_orig),size=(1,)).item() # Los números aleatorios tambien se pueden generar desde pytorch. Util para trabajar en la GPU.\n",
    "    image,label = train_set_orig[j]\n",
    "    figure.add_subplot(rows,cols,i)\n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")  \n",
    "    #plt.title(labels_names[label])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OWYnfxWz8RS"
   },
   "source": [
    "## Ejercicio 3) Creando un `DataSet` personalizado.\n",
    "\n",
    "**1)** Con el fin de implementar un autoencoder, cree una clase derivada de la clase `DataSet` (llámela, por ejemplo `CustomDataset`) que, en vez de retornal el label asociado a cada imagen de `FashionMNIST`, retorne la imagen misma.\n",
    "\n",
    "**2)** Utilice dicha clase para transformar los conjuntos de entrenamiento y testeo de `FashionMNIST` pensados para clasificación, a correspondientes conjuntos pensados para entrenar un autoencoder.\n",
    "Para ello, defina una clase `CustomDataset` que deriva de la clase `Dataset`, cuyo método `__getitem__(self,i)` retorne el pair `input,output` donde tanto `input` cómo `output` son iguales a la $i$-ésima imagen del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "sPjO1_Av1f87"
   },
   "outputs": [],
   "source": [
    "# 3.1)\n",
    "# Creamos una subclase de la clase Dataset que nos sirva para generar lotes de ejemplos que puedan usarse para entrenar un autoencoder\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset=dataset\n",
    "    # Redefinimos el método .__len__()\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    # Redefinimos el método .__getitem__()\n",
    "    def __getitem__(self,i):\n",
    "        image,label=self.dataset[i]\n",
    "        input  = image\n",
    "        output = image #torch.flatten(image) # retornamos la imagen como salida\n",
    "        return input,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "EbMUnqwU19gL"
   },
   "outputs": [],
   "source": [
    "# 3.2)\n",
    "# Convertimos FashionMNIST Dataset a CustomDataset\n",
    "train_set = CustomDataset(train_set_orig)\n",
    "valid_set = CustomDataset(valid_set_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKpx5sTuPJdk"
   },
   "source": [
    "## Ejercicio 4) Red Neuronal Autoencoder Convolucional\n",
    "\n",
    "**1)** Defina y cree una red neuronal *autoencoder convolucional* constituida por las siguientes capas:\n",
    "\n",
    "\n",
    "1. Capa convolucional 2D (encoder) compuesta por:\n",
    "\n",
    "  * Una capa `Conv2d` (ver [documentación](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)) que mapea una entrada con $1$ canal y dimensiones $(28,28)$ a una salida con $16$ canales y dimensiones $(26,26)$.\n",
    "    Utilice un kernel de dimensiones $(3,3)$ y el resto de los parámetros en sus valores por defecto.\n",
    "  * Una capa `ReLU`.\n",
    "  * Una capa `MaxPool2d` con un kernel de dimensiones $(2,2)$, de modo que la salida resultante tenga dimensiones $(16,13,13)$.\n",
    "  * Una capa `Dropout` con probabilidad $p$.\n",
    "\n",
    "2. Capa lineal (cuello de botella o “bottleneck”) compuesta por:\n",
    "\n",
    "  * Una capa `Flatten` que transforma una entrada de dimensiones $(16,13,13)$ en un vector de dimensión $16\\times 13\\times 13 = 2704$.\n",
    "  * Una capa `Linear` que mapea el vector de dimensión $2704$ a un vector de dimensión $n$ (donde $n$ es un número mucho menor, por ejemplo $n=128$, representando la *codificación comprimida* o *latente*).\n",
    "  * Una capa `ReLU`.\n",
    "  * Una capa `Linear` que mapea de nuevo el vector de dimensión $n$ al espacio original de dimensión $2704$.\n",
    "  * Una capa `ReLU`.\n",
    "\n",
    "3. Capa convolucional 2D transpuesta (decoder) compuesta por:\n",
    "\n",
    "  * Una capa `Unflatten` que mapea el vector de dimensión $2704$ a una representación de $16$ canales con dimensiones $(13,13)$.\n",
    "  * Una capa `ConvTranspose2d` (ver [documentación](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html)) que mapea $16$ canales de dimensiones $(13,13)$ a $1$ canal de dimensiones $(28,28)$. Utilice un kernel de dimensiones $(6,6)$, un stride de $(2,2)$, y un padding de $(1,1)$.\n",
    "  * Una capa `Sigmoid`, para asegurar que las salidas se encuentren en el rango $[0,1]$ (asumiendo que las imágenes originales también fueron normalizadas en dicho rango).\n",
    "\n",
    "**2)** Grafique, a modo de comparación, algunas imágenes de entrada y sus correspondientes reconstrucciones obtenidas con el modelo **sin entrenar** y con una probabilidad de *dropout* $p=0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "qSJqCozXCEq1"
   },
   "outputs": [],
   "source": [
    "# 4.1)\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,n,p=0.2):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        #capa0 : convolucional 2D\n",
    "        self.conv0 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)  #De 28x28x1 a 26x26x16. Son 16 filtros convolucionales. Cada filtro extrae una característica diferente. \n",
    "        #Si aca usamos padding=1, la salida sería 28x28x16 pues mantenemos las dimensiones espaciales debido a que el padding lo que hace es agregar una capa de ceros alrededor de la imagen.\n",
    "        # Y si aca usamos stride=2, la salida sería 13x13x16, pues reducimos las dimensiones espaciales a la mitad. Ya que stride=2 significa que el filtro se mueve de a 2 pixeles en cada paso con lo cual se reduce la resolución espacial.\n",
    "        # Si el tamaño del kernel aumentara a 5, la salida sería 24x24x16, pues el tamaño del kernel afecta las dimensiones espaciales de la salida.\n",
    "        self.relu = nn.ReLU() \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #Reducción de dimensionalidad: de 26x26 a 13x13, canales siguen siendo 16. \n",
    "        self.dropout = nn.Dropout(p) \n",
    "\n",
    "        #capa 1 : bottleneck\n",
    "        self.flatten = nn.Flatten()#start_dim=(16,13,13)) #De 16x13x13 a 2704\n",
    "        self.fc2_0 = nn.Linear(16*13*13,n)  #de 2704 a n, codificación \n",
    "        #relu\n",
    "        self.fc2_1 = nn.Linear(n,16*13*13)  #de n a 2704, decodificación\n",
    "        #relu\n",
    "\n",
    "        #capa 2\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(16,13,13)) #de 2704 a 16x13x13\n",
    "        self.convtr2 = nn.ConvTranspose2d(in_channels=16, out_channels=1, kernel_size=6,stride= 2, padding=1)  #de 16x13x13 a 28x28x1, son 28 porque usamos stride=2, que duplica las dimensiones espaciales.\n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "    \n",
    "    def forward(self,x):\n",
    "        #capa0\n",
    "        x = self.conv0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        #capa1\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc2_0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2_1(x)\n",
    "        x = self.relu(x)\n",
    "        #capa2\n",
    "        x = self.unflatten(x)\n",
    "        x = self.convtr2(x)\n",
    "        x = self.sigmoid(x)\n",
    "                    \n",
    "        return x\n",
    "\n",
    "mi_red = NeuralNetwork(128,p=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9uINlg69OTw"
   },
   "source": [
    "## Ejercicio 5) Entrenando el modelo\n",
    "\n",
    "**1)** Implemente, en una función, un loop de entrenamiento que recorra los batchs (lotes).\n",
    "\n",
    "**2)** Implemente, en una función, un loop de prueba o validación que recorra los batchs.\n",
    "\n",
    "**3)** Inicialize dos `DataLoader`s llamados `train_loader` y `valid_loader` que estén definidos sobre  el `train_set` (conjunto de entranmiento) y el `valid_set` (conjunto de prueba) de Fashion-MNIST, respectivamente, y que usen batchs de 100 ejemplos.\n",
    "\n",
    "**4)** Cree una función de pérdida usando el **Error Cuadrático Medio**.\n",
    "\n",
    "**5)** Cree un optimizador con un learning rate igual a $10^{-3}$.\n",
    "Pruebe con **ADAM**.\n",
    "\n",
    "**6)** Cree una instancia del modelo con dropout $p=0.2$.\n",
    "\n",
    "**7)** Especifique en que dispositivo (`device`) va a trabajar: en una **CPU** o en una **GPU**.\n",
    "\n",
    "**8)** Implemente un loop que itere sobre épocas de entrenamiento y validación, y que guarde en listas correspondientes los siguientes valores del **ECM**:\n",
    "*  promedios (incorrectos) sobre el conjunto de entrenamiento, calculado **durante** el proceso de entrenamiento sobre la época.\n",
    "*  promedios (correctos) sobre el conjunto de entrenamiento, calculados **posteriormente** al proceso de entrenamiento sobre la época.\n",
    "*  promedios (correctos) sobre el conjunto de validación, calculados **posteriormente** al proceso de entrenamiento sobre la época.\n",
    "\n",
    "**IMPORTANTE:** No olvide copiar los batchs al dispositivo de trabajo.\n",
    "\n",
    "**9)** Entrene y valide el modelo.\n",
    "\n",
    "**10)** Use las listas del inciso **8)** para graficar en función de las **épocas de entrenamiento** el **ECM** de **entrenamiento** y **validación**, respectivamente.\n",
    "Discuta y comente, cual es el número óptimo de épocas de entrenamiento?\n",
    "\n",
    "**11)** Grafique, comparativamente, algunas de las imagenes a predecir vs las imagenes predichas por el modelo entrenado.\n",
    "\n",
    "**12)** Repita para otras elecciones de los hiperparámetros tales como, el optimizador (podría ser el **SGD**), el **learning-rate**, el tamaño de los **batchs**, el **dropout**, **capas convolucionales** y **convolucionales traspuestas** de otros tamaños.\n",
    "En particular, pruebe eliminando, adecuadamente, la **capa lineal**.\n",
    "Que valores de estos hiperparámetros considera los más convenientes? Porqué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "hyuXv-0x29Xw"
   },
   "outputs": [],
   "source": [
    "# 5.1)\n",
    "def train_loop(dataloader,model,loss_fn,optimizer):\n",
    "    model.train()\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    sum_loss = 0\n",
    "    sum_correct = 0\n",
    "    sum_samples = 0\n",
    "    for batch, (X,y) in enumerate(dataloader): \n",
    "        #enumerate devuelve una lista de tuplas (indice, valor), entonces al hacer\n",
    "        # for batch, (X,y) desestructura la tupla en indice(batch) y valor(X(imagenes), y(etiquetas))\n",
    "\n",
    "        # Copiamos las salidas y entradas al dispositivo de trabajo\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        batch_size = len(X)\n",
    "        # calculamos la perdida promedio del batch y lo agregamos a una suma correspondiente\n",
    "        sum_loss += loss.item() * batch_size # loss = suma de perdidas en el batch / batch_size => loss.item() * batch_size = suma de perdidas en el batch\n",
    "\n",
    "        # En este caso no tiene sentido calcular la cantidad de predicciones correctas porque es un autoencoder y no una tarea de clasificación\n",
    "        #sum_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        # actualizamos la cantidad de muestras procesadas\n",
    "        sum_samples += batch_size\n",
    "\n",
    "        #if batch % (num_batches / 10) == 0: # evaluamos en el 10% de los batches, para no saturar\n",
    "        avrg_loss = sum_loss / sum_samples\n",
    "        # precision = sum_correct / sum_samples\n",
    "        print(f\"  Batch {batch:>5d}/{num_batches:>5d} - avrg_Loss: {avrg_loss:>7f}  processed_samples: {100*sum_samples/num_samples:>5f}%\") #5d ?\n",
    "        \n",
    "    assert num_samples == sum_samples, \"Error en el conteo de muestras procesadas\"\n",
    "    avrg_loss = sum_loss / sum_samples\n",
    "    #precision = sum_correct / sum_samples\n",
    "\n",
    "    return avrg_loss #, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2)\n",
    "def valid_loop(dataloader,model,loss_fn):\n",
    "    model.eval()\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    sum_loss = 0\n",
    "    sum_correct = 0\n",
    "    sum_samples = 0\n",
    "    with torch.no_grad(): # es un context manager que desactiva el cálculo del gradiente momentáneamente, \n",
    "        #para ahorrar memoria y mejorar el rendimiento durante la evaluación del modelo.\n",
    "\n",
    "        for X,y in dataloader: #iteramos sobre los batches del dataloader, esto es posible ya que si bien dataloader no es una lista,\n",
    "            # implementa el protocolo iterable de python, por lo que se puede usar en un for, y en cada iteracion genera un batch nuevo\n",
    "\n",
    "            # Copiamos las salidas y entradas al dispositivo de trabajo\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            batch_size = len(X)\n",
    "            sum_samples += batch_size\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            sum_loss += loss.item() * batch_size\n",
    "            #sum_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    assert num_samples == sum_samples, \"Error en el conteo de muestras procesadas\"\n",
    "    avrg_loss = sum_loss / sum_samples\n",
    "    #precision = sum_correct / sum_samples\n",
    "    print(f\"@eval_loop_avg_loss={avrg_loss:>8f}\") #, precision={100*precision:0.1f}%\")\n",
    "\n",
    "    return avrg_loss #, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3)\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True,num_workers=8, pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size = batch_size, shuffle = True,num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.4)\n",
    "#Creamos una instancia de una funcion de perdida, en este caso error cuadratico medio\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.6)\n",
    "#valores segun ej4\n",
    "n = 128\n",
    "p = 0.2\n",
    "model = NeuralNetwork(n, p = p)\n",
    "\n",
    "#5.5)\n",
    "#definimos el optimizador, en este caso SGD\n",
    "learning_rate = 1e-3\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#5.7)\n",
    "#definimos el dispositivo de trabajo, una cpu o una gpu si esta disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#pasamos el modelo al dispositivo\n",
    "model = model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 1.392717  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 1.379994  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 1.367504  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 1.327966  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 1.289367  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 1.256989  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 1.222493  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 1.189563  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 1.153316  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 1.119422  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 1.090040  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 1.062676  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 1.037789  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 1.016466  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.997414  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.979431  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.964252  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.950358  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.938741  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.927391  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.917217  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.907432  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.899260  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.890131  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.883090  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.876010  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.869007  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.862645  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.856902  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.850491  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.845075  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.840482  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.835938  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.832306  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.827937  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.824051  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.820657  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.817606  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.814440  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.812008  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.808766  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.805993  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.803456  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.800678  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.798106  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.796145  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.794222  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.791817  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.790627  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.788697  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.786986  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.785124  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.783562  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.782143  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.780550  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.778595  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.776832  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.775629  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.774227  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.772701  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.771163  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.770261  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.769221  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.768409  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.767458  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.766130  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.765043  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.763801  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.762769  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.761824  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.760836  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.760120  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.759065  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.758137  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.757139  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.756299  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.755524  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.754735  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.753879  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.752938  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.752149  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.751424  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.750726  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.749868  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.749117  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.748367  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.747465  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.746512  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.746043  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.745271  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.744386  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.743973  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.743321  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.742694  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.742131  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.741612  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.741272  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.740845  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.740270  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.739876  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.739418  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.738838  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.738308  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.737799  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.737531  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.736970  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.736565  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.736027  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.735514  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.735203  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.734615  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.734241  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.733663  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.733158  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.732865  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.732673  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.732511  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.732136  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.731987  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.731589  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.731360  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.730978  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.730678  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.730292  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.729870  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.729463  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.729055  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.728662  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.728125  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.727743  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.727483  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.727274  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.726876  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.726803  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.726568  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.726327  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.726114  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.725886  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.725709  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.725411  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.725125  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.724876  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.724587  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.724220  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.723908  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.723704  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.723447  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.722988  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.722652  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.722307  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.722060  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.721781  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.721452  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.721308  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.721088  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.720806  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.720495  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.720375  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.720129  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.719910  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.719692  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.719506  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.719367  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.719109  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.718874  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.718711  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.718547  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.718298  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.718071  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.717900  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.717719  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.717404  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.717174  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.716941  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.716712  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.716513  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.716223  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.716116  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.715877  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.715766  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.715561  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.715345  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.715073  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.714874  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.714684  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.714413  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.714324  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.714247  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.714098  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.713815  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.713656  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.713557  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.713374  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.713195  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.713004  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.712767  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.712729  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.712511  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.712289  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.712191  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.711978  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.711836  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.711752  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.711702  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.711588  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.711463  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.711414  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.711299  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.711144  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.710937  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.710782  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.710685  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.710505  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.710372  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.710291  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.710277  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.710084  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.710007  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.710007  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.709853  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.709698  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.709535  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.709410  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.709215  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.709018  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.708839  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.708725  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.708754  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.708669  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.708584  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.708516  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.708404  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.708322  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.708131  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.708126  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.708086  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.708002  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.707986  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.707881  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.707828  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.707761  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.707703  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.707712  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.707587  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.707564  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.707412  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.707310  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.707268  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.707021  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.707014  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.707002  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.706955  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.706895  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.706810  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.706642  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.706498  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.706430  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.706373  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.706219  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.706164  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.706105  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.705997  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.705943  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.705880  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.705785  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.705777  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.705693  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.705681  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.705718  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.705648  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.705552  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.705466  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.705364  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.705271  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.705202  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.705162  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.705053  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.704984  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.704865  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.704778  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.704730  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.704651  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.704632  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.704485  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.704500  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.704431  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.704324  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.704224  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.703997  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.703942  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.703909  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.703832  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.703787  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.703797  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.703759  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.703643  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.703586  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.703535  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.703450  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.703402  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.703376  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.703367  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.703311  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.703274  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.703190  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.703133  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.703122  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.703024  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.703021  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.702958  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.702935  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.702861  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.702828  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.702744  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.702659  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.702592  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.702556  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.702459  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.702406  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.702307  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.702253  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.702204  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.702197  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.702120  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.701953  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.701871  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.701819  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.701828  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.701784  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.701686  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.701643  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.701565  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.701561  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.701510  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.701467  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.701439  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.701387  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.701370  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.701346  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.701322  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.701227  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.701205  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.701109  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.701068  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.701004  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.700961  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.700915  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.700883  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.700874  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.700831  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.700851  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.700805  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.700861  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.700816  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.700794  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.700782  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.700792  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.700753  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.700730  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.700700  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.700679  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.700640  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.700607  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.700534  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.700493  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.700492  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.700434  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.700435  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.700354  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.700319  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.700300  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.700259  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.700187  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.700133  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.700050  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.700078  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.700123  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.700068  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.700050  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.699972  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.699967  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.699956  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.699901  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.699874  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.699819  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.699788  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.699772  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.699747  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.699731  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.699646  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.699588  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.699562  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.699517  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.699486  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.699424  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.699390  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.699364  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.699331  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.699308  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.699314  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.699303  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.699236  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.699182  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.699156  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.699124  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.699048  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.699064  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.699004  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.698925  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.698883  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.698829  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.698769  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.698741  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.698720  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.698666  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.698651  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.698614  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.698539  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.698494  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.698447  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.698448  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.698407  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.698349  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.698331  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.698306  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.698278  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.698253  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.698286  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.698207  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.698137  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.698106  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.698043  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.698033  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.698030  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.697997  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.697890  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.697873  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.697819  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.697789  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.697774  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.697792  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.697770  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.697708  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.697687  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.697629  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.697634  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.697599  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.697609  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.697559  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.697527  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.697523  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.697464  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.697433  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.697387  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.697384  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.697355  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.697342  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.697305  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.697320  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.697286  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.697248  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.697229  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.697190  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.697199  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.697194  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.697151  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.697158  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.697098  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.697075  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.697090  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.697130  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.697103  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.697052  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.697045  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.697042  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.696966  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.696937  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.696883  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.696869  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.696844  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.696837  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.696770  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.696747  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.696746  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.696716  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.696677  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.696642  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.696668  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.696636  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.696610  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.696590  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.696566  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.696503  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.696453  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.696444  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.696409  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.696388  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.696372  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.696365  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.696310  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.696265  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.696211  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.696181  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.696131  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.696149  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.696125  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.696075  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.696084  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.696073  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.696034  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.696030  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.695980  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.695966  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.695963  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.695979  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.695944  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.695911  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.695835  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.695806  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.695793  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.695739  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.695699  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.695654  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.695652  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.695621  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.695623  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.695584  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.695570  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.695524  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.695505  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.695496  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.695519  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.695510  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.695460  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.695412  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.695380  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.695330  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.695300  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.695284  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.695260  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.695222  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.695195  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.695174  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.695164  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.695108  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.695110  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.695133  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.695135  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.695119  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.695113  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.695112  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.695090  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.695066  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.695059  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.695045  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.695093  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.695078  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.695065  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.695046  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.695023  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.695004  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.694976  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.694977  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.694949  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.694939  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.694911  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.694851  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.694838  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.694822  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.694776  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.694753  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.694721  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.694685  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.694667  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.694644  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.694629  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.694601  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.694598  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.694625  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.694623  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.694575  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.694563  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.694539  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.694518  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.694504  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.694497  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.694463  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.694458  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.694421  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.694441  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.694412  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.694439  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.694413  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.694450  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.694423  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.694397  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.694409  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.694402  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.694377  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.694408  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.685231\n",
      "@eval_loop_avg_loss=0.682265\n",
      "Epoch 2/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.679320  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.678511  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.678478  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.680723  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.679015  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.676551  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.679719  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.681064  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.683894  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.685557  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.687001  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.686897  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.686597  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.685448  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.684761  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.683522  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.683910  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.684315  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.683320  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.682733  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.683968  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.684438  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.684497  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.684425  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.684823  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.684828  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.685457  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.684974  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.684865  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.684575  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.684939  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.685012  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.685011  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.685537  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.685432  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.685561  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.685675  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.685763  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.685776  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.685679  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.685489  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.685590  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.685589  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.685827  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.685871  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.686104  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.686244  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.686531  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.686479  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.686663  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.686474  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.686632  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.686494  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.686739  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.686507  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.686738  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.687033  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.687066  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.686932  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.686845  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.686754  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.686664  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.686692  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.686722  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.686690  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.686597  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.686895  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.686979  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.686998  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.686926  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.687209  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.687251  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.687209  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.687441  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.687537  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.687553  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.687341  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.687292  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.687524  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.687387  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.687322  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.687253  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.687412  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.687383  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.687539  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.687395  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.687427  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.687602  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.687578  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.687576  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.687587  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.687551  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.687542  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.687527  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.687598  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.687580  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.687697  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.687461  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.687503  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.687558  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.687734  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.687704  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.687928  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.687779  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.687588  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.687614  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.687379  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.687492  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.687254  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.687369  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.687378  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.687303  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.687336  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.687356  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.687221  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.687183  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.687354  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.687156  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.687250  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.687149  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.687184  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.687169  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.687420  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.687399  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.687405  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.687495  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.687775  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.687553  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.687635  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.687593  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.687486  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.687421  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.687548  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.687408  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.687326  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.687351  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.687545  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.687419  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.687294  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.687187  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.687151  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.687142  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.687186  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.687155  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.686970  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.686875  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.686706  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.686695  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.686693  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.686751  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.686664  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.686543  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.686494  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.686509  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.686505  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.686506  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.686349  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.686405  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.686282  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.686271  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.686299  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.686305  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.686319  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.686434  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.686400  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.686162  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.686213  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.686168  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.686066  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.686188  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.686154  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.686113  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.686182  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.686038  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.686097  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.686260  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.686329  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.686339  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.686315  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.686246  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.686357  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.686335  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.686312  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.686256  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.686250  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.686263  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.686264  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.686195  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.686113  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.686075  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.686023  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.686002  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.686065  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.685960  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.686012  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.686027  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.685932  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.685933  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.685880  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.685919  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.685913  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.685928  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.686005  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.686058  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.686056  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.686025  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.686057  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.685965  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.685926  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.685971  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.685972  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.685941  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.685996  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.685979  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.686032  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.685993  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.685888  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.685813  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.685847  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.685849  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.685922  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.685948  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.685950  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.685918  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.685923  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.685990  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.685987  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.686013  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.686021  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.686052  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.685959  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.685979  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.685955  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.685930  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.685979  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.685928  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.685911  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.685871  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.685842  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.685998  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.685938  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.685971  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.685945  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.685957  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.685955  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.685942  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.685978  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.685916  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.685910  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.685941  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.685934  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.685834  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.685773  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.685689  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.685759  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.685720  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.685729  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.685777  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.685828  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.685887  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.685992  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.685987  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.685981  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.685985  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.685961  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.685917  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.685955  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.686019  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.686065  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.686092  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.686078  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.686071  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.686041  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.686038  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.686041  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.686115  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.686027  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.685941  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.685925  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.685867  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.685871  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.685840  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.685891  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.685975  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.685929  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.686032  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.686091  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.686082  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.686067  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.686045  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.686013  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.686052  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.686082  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.686098  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.686068  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.686009  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.685999  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.685966  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.686009  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.686063  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.686023  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.686046  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.686040  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.686032  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.686022  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.686032  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.686113  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.686069  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.686008  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.685926  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.685963  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.685917  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.685877  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.685904  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.685848  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.685754  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.685722  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.685716  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.685683  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.685684  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.685656  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.685636  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.685606  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.685614  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.685650  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.685645  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.685686  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.685702  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.685711  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.685759  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.685786  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.685787  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.685780  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.685672  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.685783  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.685820  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.685797  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.685750  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.685760  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.685837  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.685787  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.685715  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.685708  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.685726  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.685629  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.685611  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.685631  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.685604  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.685610  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.685689  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.685687  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.685685  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.685666  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.685662  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.685639  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.685560  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.685595  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.685559  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.685611  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.685598  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.685597  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.685570  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.685531  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.685486  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.685389  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.685394  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.685438  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.685464  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.685458  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.685385  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.685355  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.685296  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.685255  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.685237  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.685167  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.685145  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.685220  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.685236  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.685203  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.685141  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.685114  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.685053  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.685048  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.685015  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.685027  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.684990  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.684976  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.684974  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.685006  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.685038  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.685086  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.685122  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.685149  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.685101  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.685123  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.685104  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.685116  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.685141  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.685138  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.685131  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.685109  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.685073  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.685075  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.685047  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.685057  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.685081  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.685043  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.685008  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.685035  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.684997  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.684969  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.685026  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.685033  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.685050  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.685010  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.684995  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.685016  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.685071  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.685064  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.685041  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.685042  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.685065  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.685055  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.685043  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.685021  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.685032  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.685061  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.685036  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.685030  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.685015  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.684960  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.684951  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.684938  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.684924  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.684912  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.684903  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.684902  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.684928  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.684900  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.684855  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.684882  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.684875  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.684884  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.684892  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.684890  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.684893  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.684928  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.684927  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.684937  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.684971  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.684926  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.684912  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.684922  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.684932  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.684940  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.684947  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.684994  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.685044  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.685036  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.685015  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.685000  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.685027  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.685073  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.685033  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.685026  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.685070  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.685028  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.685057  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.685075  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.685060  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.685059  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.685046  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.685059  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.685066  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.685087  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.685050  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.685058  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.685049  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.684964  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.685008  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.684990  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.685003  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.685035  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.685022  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.685042  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.685044  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.685045  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.685046  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.685024  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.684979  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.684880  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.684857  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.684866  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.684896  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.684902  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.684916  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.684924  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.684961  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.684949  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.684948  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.684919  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.684928  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.684902  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.684934  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.684938  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.684939  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.684911  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.684876  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.684927  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.684882  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.684912  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.684901  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.684909  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.684884  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.684912  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.684891  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.684894  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.684881  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.684903  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.684884  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.684871  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.684904  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.684925  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.684976  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.684973  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.684938  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.684929  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.684905  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.684900  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.684920  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.684924  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.684918  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.684931  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.684941  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.684952  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.684927  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.684857  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.684830  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.684800  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.684804  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.684819  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.684830  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.684870  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.684858  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.684885  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.684912  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.684899  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.684886  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.684916  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.684931  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.684960  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.684974  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.684977  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.684989  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.685011  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.684983  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.684967  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.684960  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.684986  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.684993  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.684994  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.684987  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.685004  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.684994  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.685025  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.685046  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.685066  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.685035  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.685030  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.685054  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.685060  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.685036  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.685006  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.684994  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.685005  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.685004  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.684971  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.684990  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.684974  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.684985  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.685001  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.684998  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.685014  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.685040  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.685068  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.685091  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.685118  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.685145  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.685137  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.685138  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.685111  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.685086  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.685079  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.685109  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.685098  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.685109  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.685122  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.685132  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.685133  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.685138  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.684981\n",
      "@eval_loop_avg_loss=0.682017\n",
      "Epoch 3/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.674496  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.676602  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.677211  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.678712  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.684083  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.685785  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.686703  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.686851  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.687392  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.688203  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.689156  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.689067  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.688341  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.688187  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.687637  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.688031  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.686880  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.686008  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.686289  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.687824  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.687367  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.687452  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.687409  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.687253  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.687262  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.688341  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.688176  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.688735  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.688848  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.688123  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.687904  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.688416  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.688062  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.687648  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.688084  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.688212  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.688128  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.687867  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.687520  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.687016  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.686294  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.685737  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.685662  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.685523  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.685087  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.685148  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.685086  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.685165  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.684914  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.684895  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.685159  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.685245  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.685554  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.685328  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.685741  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.685914  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.686205  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.686382  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.686558  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.686312  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.686240  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.685544  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.686022  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.686026  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.686211  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.686537  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.686273  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.685933  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.686000  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.685917  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.685937  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.686060  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.685994  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.686095  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.685971  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.685895  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.685729  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.685805  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.685875  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.685740  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.685755  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.685518  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.685353  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.685195  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.685347  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.685530  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.685545  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.685544  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.685516  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.685507  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.685544  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.685545  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.685555  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.685575  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.685380  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.685318  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.685284  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.685133  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.685013  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.684994  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.684977  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.684989  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.684881  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.684905  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.684853  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.684951  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.684921  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.685119  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.685105  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.684987  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.684997  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.685134  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.685002  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.685002  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.685025  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.684984  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.684959  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.684769  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.684791  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.684660  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.684635  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.684689  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.684681  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.684799  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.684747  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.684702  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.684551  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.684341  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.684496  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.684462  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.684416  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.684536  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.684641  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.684533  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.684312  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.684307  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.684341  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.684485  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.684530  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.684494  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.684459  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.684561  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.684555  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.684558  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.684574  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.684508  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.684601  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.684524  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.684605  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.684587  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.684753  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.684698  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.684666  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.684634  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.684639  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.684569  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.684599  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.684669  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.684486  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.684488  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.684552  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.684684  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.684783  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.684854  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.684806  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.684793  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.684815  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.684772  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.684660  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.684708  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.684614  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.684581  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.684561  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.684561  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.684637  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.684693  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.684569  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.684640  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.684675  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.684744  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.684716  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.684798  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.684829  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.684821  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.684826  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.684817  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.684795  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.684755  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.684803  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.684748  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.684733  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.684801  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.684834  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.684842  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.684736  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.684707  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.684747  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.684711  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.684716  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.684753  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.684719  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.684743  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.684642  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.684635  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.684516  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.684575  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.684515  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.684440  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.684391  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.684318  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.684325  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.684354  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.684381  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.684348  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.684420  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.684367  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.684314  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.684492  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.684517  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.684450  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.684434  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.684370  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.684332  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.684297  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.684273  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.684179  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.684190  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.684232  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.684306  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.684356  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.684335  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.684258  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.684229  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.684249  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.684169  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.684236  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.684311  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.684338  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.684406  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.684394  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.684372  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.684248  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.684335  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.684454  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.684509  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.684481  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.684475  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.684431  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.684393  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.684461  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.684556  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.684602  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.684570  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.684556  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.684627  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.684523  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.684568  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.684546  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.684553  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.684549  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.684531  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.684581  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.684593  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.684618  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.684574  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.684598  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.684619  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.684642  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.684644  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.684610  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.684585  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.684557  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.684591  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.684649  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.684624  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.684515  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.684445  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.684469  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.684473  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.684413  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.684387  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.684407  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.684392  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.684325  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.684325  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.684320  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.684387  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.684372  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.684335  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.684389  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.684462  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.684453  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.684497  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.684555  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.684637  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.684583  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.684514  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.684446  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.684499  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.684498  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.684565  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.684482  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.684470  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.684406  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.684387  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.684368  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.684371  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.684317  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.684344  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.684307  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.684260  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.684304  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.684321  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.684287  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.684377  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.684373  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.684399  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.684404  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.684395  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.684364  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.684392  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.684379  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.684510  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.684460  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.684517  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.684527  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.684542  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.684520  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.684519  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.684479  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.684439  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.684420  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.684472  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.684473  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.684531  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.684461  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.684499  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.684430  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.684406  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.684417  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.684504  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.684542  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.684570  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.684608  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.684578  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.684592  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.684528  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.684540  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.684526  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.684508  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.684541  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.684536  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.684559  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.684613  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.684675  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.684656  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.684649  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.684694  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.684687  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.684663  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.684660  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.684714  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.684749  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.684728  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.684771  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.684772  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.684788  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.684745  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.684738  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.684704  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.684711  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.684709  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.684704  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.684725  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.684726  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.684693  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.684759  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.684773  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.684770  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.684818  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.684832  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.684867  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.684854  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.684807  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.684813  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.684813  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.684804  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.684800  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.684819  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.684807  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.684816  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.684848  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.684809  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.684851  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.684846  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.684865  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.684850  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.684844  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.684841  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.684853  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.684813  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.684814  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.684875  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.684875  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.684830  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.684843  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.684818  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.684861  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.684802  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.684827  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.684812  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.684800  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.684779  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.684754  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.684721  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.684751  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.684740  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.684769  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.684805  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.684776  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.684813  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.684801  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.684794  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.684831  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.684819  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.684805  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.684808  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.684790  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.684827  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.684831  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.684886  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.684807  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.684815  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.684782  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.684736  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.684717  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.684705  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.684735  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.684718  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.684761  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.684766  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.684820  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.684853  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.684817  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.684828  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.684859  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.684880  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.684913  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.684904  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.684859  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.684808  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.684738  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.684745  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.684749  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.684752  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.684695  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.684706  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.684724  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.684724  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.684738  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.684739  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.684727  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.684728  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.684759  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.684749  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.684764  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.684765  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.684758  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.684752  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.684768  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.684762  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.684756  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.684770  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.684769  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.684722  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.684745  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.684806  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.684788  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.684740  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.684769  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.684733  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.684781  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.684780  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.684711  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.684674  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.684642  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.684647  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.684660  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.684675  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.684673  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.684641  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.684632  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.684699  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.684709  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.684686  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.684665  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.684687  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.684702  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.684685  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.684695  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.684674  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.684676  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.684685  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.684658  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.684656  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.684649  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.684628  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.684617  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.684605  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.684616  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.684615  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.684608  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.684573  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.684551  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.684528  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.684542  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.684534  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.684519  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.684553  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.684559  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.684583  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.684572  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.684547  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.684554  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.684578  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.684604  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.684549  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.684528  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.684521  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.684500  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.684499  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.684529  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.684556  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.684592  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.684566  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.684548  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.684489  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.684512  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.684481  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.684501  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.684475  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.684484  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.684495  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.684479  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.684501  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.684487  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.684497  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.684467  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.684450  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.684452  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.684447  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.684425  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.684400  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.684392  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.684357  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.684365  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.684360  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.684396  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.684386  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.684391  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.684410  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.684429  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.684416  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.684434  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.684456  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.684474  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.684464  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.684444  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.684412  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.684404  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.684420  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.684413  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.684407  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.684369  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.684398  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.684426  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.684447  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.684478  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.684486  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.684499  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.684510  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.684472  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.684486  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.684487  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.684495  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.684480  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.684477  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.684481  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.684496  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.684491  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.684489  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.684494  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.684491  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.684496  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.684476  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.684493  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.684493  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.684510  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.684494  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.684507  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.683807\n",
      "@eval_loop_avg_loss=0.680845\n",
      "Epoch 4/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.699272  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.692259  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.690678  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.686814  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.685738  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.684377  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.682226  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.682889  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.680922  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.677387  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.678421  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.678116  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.679664  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.681507  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.681858  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.681523  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.680945  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.680508  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.680664  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.681798  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.682046  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.682425  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.682391  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.682135  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.682251  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.682434  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.683209  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.682698  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.682838  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.682898  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.682898  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.682715  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.682983  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.683168  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.683473  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.683700  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.683645  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.683675  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.683949  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.683754  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.684107  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.683672  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.683867  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.684359  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.684137  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.683876  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.683769  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.683658  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.683295  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.683140  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.682747  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.682768  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.682702  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.682521  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.682808  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.682905  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.682670  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.682632  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.682982  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.683052  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.683117  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.683318  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.683378  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.683298  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.683137  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.682933  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.682813  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.682921  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.682800  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.682639  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.682550  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.682412  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.682686  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.682574  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.682576  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.682389  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.682362  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.682262  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.682400  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.682461  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.682378  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.682305  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.682606  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.682650  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.682625  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.682632  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.682398  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.682413  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.682448  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.682467  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.682252  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.682123  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.682369  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.682389  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.682317  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.682624  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.682541  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.682448  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.682469  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.682403  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.682378  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.682313  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.682249  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.682026  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.681952  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.681701  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.681805  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.681917  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.681899  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.681987  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.681969  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.681979  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.682094  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.682041  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.681929  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.681858  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.681537  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.681312  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.681439  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.681444  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.681449  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.681375  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.681174  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.681199  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.681024  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.680981  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.681070  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.681101  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.681036  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.681004  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.681010  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.681089  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.681067  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.681109  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.681045  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.680990  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.680934  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.680725  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.680799  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.680830  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.680706  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.680700  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.680511  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.680518  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.680488  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.680420  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.680523  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.680638  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.680597  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.680612  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.680452  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.680436  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.680428  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.680300  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.680079  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.680010  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.679991  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.680021  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.679924  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.679810  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.679683  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.679716  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.679784  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.679723  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.679529  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.679623  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.679566  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.679546  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.679486  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.679306  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.679369  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.679238  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.679191  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.679174  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.679270  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.679250  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.679216  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.679300  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.679312  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.679178  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.679082  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.679175  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.679104  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.679050  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.679032  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.678995  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.679057  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.679018  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.678896  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.678872  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.678669  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.678550  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.678450  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.678323  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.678158  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.678185  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.678030  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.678013  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.677989  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.677715  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.677658  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.677410  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.677285  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.677061  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.676935  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.676816  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.676750  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.676560  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.676399  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.676379  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.676236  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.676123  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.676044  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.675895  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.675671  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.675377  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.675151  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.675002  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.674883  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.674766  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.674523  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.674249  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.674060  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.673758  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.673476  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.673321  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.673180  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.673025  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.672765  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.672545  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.672305  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.672082  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.671815  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.671656  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.671486  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.671301  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.671131  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.670934  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.670769  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.670571  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.670405  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.670111  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.669969  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.669661  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.669464  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.669216  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.669040  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.668945  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.668794  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.668501  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.668275  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.668152  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.667910  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.667734  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.667502  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.667159  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.666969  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.666806  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.666625  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.666425  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.666208  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.665967  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.665764  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.665496  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.665349  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.665101  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.664899  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.664744  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.664495  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.664168  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.663940  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.663768  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.663656  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.663467  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.663261  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.662999  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.662843  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.662620  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.662457  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.662328  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.662119  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.661942  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.661668  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.661426  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.661228  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.661108  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.660884  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.660681  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.660589  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.660403  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.660144  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.659963  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.659762  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.659522  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.659378  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.659220  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.659103  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.658871  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.658592  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.658360  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.658225  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.658133  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.657950  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.657722  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.657523  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.657379  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.657248  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.657155  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.657009  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.656788  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.656600  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.656407  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.656277  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.656099  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.655909  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.655690  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.655482  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.655320  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.655173  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.655112  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.654946  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.654756  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.654656  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.654531  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.654332  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.654147  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.653995  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.653814  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.653779  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.653665  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.653488  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.653420  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.653241  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.653035  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.652862  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.652673  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.652573  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.652381  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.652181  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.651965  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.651834  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.651651  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.651499  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.651335  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.651162  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.651035  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.650884  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.650709  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.650605  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.650478  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.650305  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.650160  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.650035  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.649893  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.649703  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.649520  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.649390  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.649213  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.649055  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.648961  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.648854  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.648669  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.648459  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.648347  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.648245  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.648081  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.647963  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.647833  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.647720  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.647529  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.647361  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.647150  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.646929  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.646812  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.646671  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.646573  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.646395  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.646322  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.646197  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.646085  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.645990  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.645941  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.645827  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.645721  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.645579  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.645428  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.645309  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.645200  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.645052  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.644899  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.644794  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.644633  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.644575  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.644447  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.644328  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.644164  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.644039  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.643994  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.643869  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.643807  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.643669  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.643568  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.643504  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.643295  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.643170  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.642996  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.642838  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.642748  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.642639  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.642607  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.642523  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.642364  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.642223  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.642137  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.642052  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.641918  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.641791  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.641642  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.641504  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.641435  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.641387  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.641301  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.641203  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.641086  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.641012  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.640927  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.640893  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.640747  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.640621  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.640541  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.640458  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.640374  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.640275  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.640191  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.640072  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.639999  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.639966  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.639781  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.639663  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.639644  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.639582  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.639523  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.639369  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.639197  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.639140  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.639042  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.638978  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.638900  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.638819  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.638730  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.638603  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.638502  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.638393  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.638322  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.638239  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.638130  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.638053  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.637947  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.637866  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.637818  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.637703  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.637571  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.637451  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.637379  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.637327  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.637251  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.637076  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.636967  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.636910  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.636818  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.636720  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.636597  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.636480  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.636402  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.636324  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.636243  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.636165  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.636101  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.636036  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.635930  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.635920  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.635880  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.635767  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.635655  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.635546  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.635473  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.635407  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.635348  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.635330  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.635294  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.635231  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.635131  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.635023  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.634954  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.634878  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.634778  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.634692  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.634629  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.634571  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.634499  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.634432  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.634322  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.634292  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.634225  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.634129  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.634043  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.633927  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.633835  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.633743  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.633688  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.633658  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.633603  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.633533  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.633451  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.633355  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.633281  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.633215  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.633162  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.633124  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.633062  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.632977  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.632884  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.632852  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.632764  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.632687  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.632695  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.632672  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.632654  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.632553  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.632472  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.632348  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.632236  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.632215  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.632093  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.632043  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.631972  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.631890  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.631810  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.631752  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.631721  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.631649  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.631576  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.631510  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.631461  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.631398  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.631337  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.631250  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.631221  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.631126  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.631059  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.631004  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.630909  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.630841  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.630774  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.630688  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.630663  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.630631  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.630569  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.630501  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.630472  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.630436  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.630410  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.630343  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.630281  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.630232  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.630193  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.630096  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.630063  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.630046  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.630017  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.629965  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.629903  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.629868  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.629837  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.629754  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.629710  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.629686  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.629650  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.629592  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.629527  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.629450  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.629314  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.629266  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.629218  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.629136  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.629093  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.629037  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.629012  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.628990  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.628916  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.628865  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.628803  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.628746  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.628754  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.628672  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.628603  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.628512  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.628455  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.628406  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.628341  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.594816\n",
      "@eval_loop_avg_loss=0.592448\n",
      "Epoch 5/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.609976  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.602501  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.601952  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.598276  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.601163  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.598688  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.598666  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.599097  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.597459  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.596507  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.596862  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.597272  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.596436  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.597089  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.599116  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.599336  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.599374  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.598474  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.599956  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.600235  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.600766  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.599704  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.598083  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.598159  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.598120  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.597777  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.598685  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.597779  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.597897  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.597515  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.598260  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.598233  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.597643  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.597625  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.597511  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.597418  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.597570  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.597196  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.597334  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.597425  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.597371  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.597499  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.597217  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.596932  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.596877  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.597309  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.596824  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.597063  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.597263  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.597606  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.597920  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.597697  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.598287  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.598550  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.598707  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.598830  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.598123  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.597853  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.597768  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.597791  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.597516  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.597524  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.597012  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.596879  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.596502  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.596508  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.596614  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.596626  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.596779  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.596741  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.596743  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.596519  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.596882  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.596861  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.596793  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.596495  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.596448  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.596401  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.596526  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.596578  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.596673  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.596627  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.596434  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.596321  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.596409  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.596278  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.596109  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.595991  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.595823  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.595715  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.595606  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.595434  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.595626  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.595487  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.595447  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.595432  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.595439  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.595696  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.595555  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.595257  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.595150  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.595268  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.595140  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.595116  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.594966  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.594824  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.594856  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.594679  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.594763  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.594672  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.594539  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.594529  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.594466  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.594501  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.594623  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.594595  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.594739  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.594586  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.594393  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.594512  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.594324  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.594264  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.594117  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.594129  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.594104  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.594122  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.594198  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.594226  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.594250  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.594246  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.594165  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.594183  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.594346  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.594254  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.594425  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.594516  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.594576  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.594536  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.594528  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.594389  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.594481  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.594322  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.594297  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.594275  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.594403  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.594509  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.594410  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.594453  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.594517  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.594408  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.594311  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.594370  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.594173  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.594171  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.594254  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.594255  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.594131  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.594183  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.594215  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.594157  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.594126  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.594020  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.593982  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.593959  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.594004  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.593900  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.593971  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.594020  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.594108  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.594168  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.594150  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.594201  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.594129  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.593999  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.593869  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.593805  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.593797  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.593789  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.593845  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.593847  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.593876  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.593727  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.593773  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.593829  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.593863  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.593881  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.594027  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.594033  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.593954  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.594026  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.594014  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.594037  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.594069  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.594179  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.594197  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.594169  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.594082  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.594106  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.594086  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.594132  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.594001  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.594047  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.594035  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.593989  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.593866  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.593793  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.593868  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.593951  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.593955  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.593895  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.593965  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.593984  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.593981  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.593909  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.593934  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.593915  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.593984  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.593886  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.593824  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.593810  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.593754  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.593743  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.593643  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.593585  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.593587  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.593648  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.593810  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.593767  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.593719  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.593713  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.593804  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.593774  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.593818  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.593784  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.593889  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.593941  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.594000  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.593985  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.594079  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.593942  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.593896  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.593869  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.593771  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.593779  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.593841  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.593840  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.593825  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.593745  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.593734  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.593685  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.593704  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.593625  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.593627  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.593547  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.593492  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.593422  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.593407  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.593425  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.593471  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.593501  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.593566  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.593556  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.593568  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.593583  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.593601  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.593715  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.593730  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.593769  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.593837  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.593818  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.593847  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.593876  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.593829  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.593906  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.593885  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.593892  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.593853  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.593835  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.593835  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.593821  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.593814  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.593839  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.593731  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.593724  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.593729  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.593682  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.593600  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.593644  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.593597  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.593614  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.593628  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.593640  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.593572  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.593604  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.593557  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.593537  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.593524  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.593543  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.593513  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.593447  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.593470  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.593553  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.593526  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.593467  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.593506  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.593509  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.593489  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.593623  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.593668  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.593659  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.593618  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.593666  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.593616  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.593558  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.593531  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.593509  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.593506  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.593520  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.593474  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.593466  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.593459  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.593403  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.593362  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.593391  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.593377  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.593417  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.593482  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.593483  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.593466  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.593485  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.593445  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.593514  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.593520  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.593474  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.593416  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.593517  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.593519  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.593442  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.593492  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.593482  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.593590  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.593545  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.593559  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.593531  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.593550  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.593534  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.593512  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.593452  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.593447  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.593445  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.593557  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.593555  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.593575  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.593598  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.593613  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.593662  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.593708  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.593697  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.593675  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.593681  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.593721  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.593719  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.593722  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.593745  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.593643  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.593667  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.593645  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.593624  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.593561  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.593548  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.593550  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.593598  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.593597  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.593582  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.593649  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.593635  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.593639  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.593670  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.593672  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.593652  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.593640  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.593596  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.593569  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.593552  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.593536  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.593528  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.593546  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.593601  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.593612  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.593655  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.593704  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.593764  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.593718  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.593703  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.593733  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.593724  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.593725  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.593676  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.593688  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.593629  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.593718  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.593723  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.593682  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.593686  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.593649  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.593602  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.593613  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.593626  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.593652  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.593642  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.593683  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.593704  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.593696  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.593708  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.593759  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.593737  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.593749  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.593721  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.593725  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.593695  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.593696  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.593741  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.593781  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.593827  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.593841  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.593796  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.593838  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.593803  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.593833  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.593789  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.593757  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.593793  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.593826  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.593843  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.593837  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.593803  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.593774  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.593703  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.593704  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.593681  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.593679  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.593676  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.593674  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.593670  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.593636  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.593616  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.593633  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.593627  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.593582  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.593541  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.593560  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.593508  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.593553  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.593590  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.593553  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.593549  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.593558  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.593541  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.593514  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.593534  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.593524  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.593505  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.593547  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.593502  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.593496  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.593509  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.593494  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.593499  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.593475  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.593475  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.593475  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.593446  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.593462  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.593458  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.593456  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.593443  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.593417  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.593420  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.593424  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.593478  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.593467  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.593420  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.593437  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.593442  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.593378  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.593361  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.593338  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.593333  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.593342  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.593274  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.593250  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.593228  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.593196  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.593186  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.593164  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.593139  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.593145  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.593192  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.593202  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.593214  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.593226  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.593213  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.593213  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.593123  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.593096  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.593050  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.593046  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.593023  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.592980  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.592961  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.592952  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.592958  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.592952  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.592916  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.592872  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.592865  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.592863  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.592842  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.592803  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.592810  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.592838  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.592847  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.592846  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.592849  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.592897  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.592917  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.592948  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.592942  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.592880  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.592897  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.592890  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.592867  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.592825  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.592839  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.592876  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.592891  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.592905  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.592926  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.592908  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.592932  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.592951  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.592945  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.592931  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.592948  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.592889  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.592904  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.592928  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.592913  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.592895  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.592910  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.592893  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.592884  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.592897  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.592882  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.592886  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.592875  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.592925  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.592915  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.592873  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.592861  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.592885  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.592920  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.592901  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.592891  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.592895  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.592867  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.592864  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.592853  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.592842  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.592833  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.592872  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.592858  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.592862  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.592873  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.592918  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.592894  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.592898  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.592891  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.592889  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.592862  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.592834  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.592839  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.592800  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.592829  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.592821  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.592814  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.592831  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.592807  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.592810  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.592814  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.592838  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.592856  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.592866  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.592823  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.592804  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.592834  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.592800  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.592762  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.592766  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.592782  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.590013\n",
      "@eval_loop_avg_loss=0.587711\n",
      "Epoch 6/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.594429  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.593572  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.598422  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.602081  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.603349  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.606056  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.605413  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.601979  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.601885  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.599545  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.597382  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.597514  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.597103  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.595874  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.595199  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.595659  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.596468  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.596190  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.596365  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.595844  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.595471  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.595167  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.594507  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.594220  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.593636  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.593641  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.592892  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.593618  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.593591  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.593293  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.593416  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.593106  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.593037  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.593136  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.593752  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.593765  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.593555  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.593714  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.594018  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.594736  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.594349  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.594191  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.593344  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.593326  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.593476  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.593693  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.593418  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.592894  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.592519  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.592476  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.592375  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.592287  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.592464  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.592632  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.592449  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.592096  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.592018  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.592377  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.592260  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.592404  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.592339  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.592464  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.592435  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.592361  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.592277  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.592139  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.592079  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.591676  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.591282  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.591058  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.591299  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.591157  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.590994  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.590808  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.590586  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.590559  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.590721  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.590848  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.591026  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.591091  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.590925  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.590744  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.590797  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.590895  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.590929  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.590653  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.590860  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.591062  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.591032  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.590930  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.590841  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.591090  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.591054  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.591117  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.590906  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.590780  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.590646  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.590584  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.590453  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.590367  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.590199  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.590191  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.589991  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.589969  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.589988  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.589779  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.589668  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.589864  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.590118  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.590177  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.589914  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.590098  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.590148  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.589979  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.589933  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.589954  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.590167  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.589935  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.589950  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.590232  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.590191  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.590006  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.590027  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.589861  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.589742  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.589757  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.589744  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.589783  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.589615  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.589667  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.589536  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.589555  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.589453  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.589398  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.589391  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.589527  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.589633  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.589624  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.589689  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.589763  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.589718  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.589713  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.589527  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.589532  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.589419  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.589384  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.589518  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.589444  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.589420  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.589434  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.589683  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.589623  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.589481  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.589532  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.589568  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.589515  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.589561  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.589524  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.589472  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.589417  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.589392  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.589401  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.589420  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.589343  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.589454  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.589339  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.589285  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.589274  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.589242  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.589180  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.588998  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.589076  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.589000  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.588958  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.588893  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.588834  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.588821  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.588811  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.588750  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.588726  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.588804  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.588771  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.588763  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.588767  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.588950  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.588858  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.588868  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.588795  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.588874  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.588810  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.588818  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.588864  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.588888  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.588949  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.589005  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.589059  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.589063  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.589067  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.589140  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.589101  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.589103  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.589083  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.589176  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.589118  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.589109  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.589050  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.589069  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.589054  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.589073  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.589041  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.589091  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.589007  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.589104  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.589149  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.589284  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.589275  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.589332  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.589276  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.589315  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.589361  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.589508  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.589502  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.589466  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.589359  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.589343  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.589342  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.589362  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.589374  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.589346  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.589329  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.589453  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.589495  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.589449  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.589434  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.589274  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.589235  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.589264  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.589355  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.589348  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.589447  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.589545  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.589618  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.589763  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.589835  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.589908  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.589860  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.589827  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.589708  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.589527  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.589469  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.589439  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.589413  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.589515  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.589468  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.589483  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.589454  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.589429  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.589499  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.589445  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.589566  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.589459  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.589458  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.589434  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.589405  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.589410  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.589412  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.589435  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.589417  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.589429  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.589467  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.589359  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.589338  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.589369  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.589384  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.589365  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.589418  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.589426  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.589400  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.589343  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.589360  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.589365  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.589414  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.589477  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.589473  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.589459  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.589445  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.589434  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.589559  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.589554  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.589590  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.589615  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.589591  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.589548  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.589542  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.589525  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.589532  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.589512  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.589480  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.589486  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.589448  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.589485  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.589498  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.589472  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.589432  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.589407  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.589428  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.589393  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.589436  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.589456  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.589420  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.589396  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.589480  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.589518  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.589511  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.589487  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.589452  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.589462  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.589513  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.589583  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.589614  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.589613  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.589587  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.589626  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.589633  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.589629  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.589627  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.589603  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.589608  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.589617  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.589674  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.589620  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.589583  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.589621  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.589611  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.589567  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.589569  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.589543  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.589588  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.589563  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.589540  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.589583  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.589561  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.589539  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.589499  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.589555  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.589626  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.589689  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.589697  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.589718  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.589713  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.589689  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.589707  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.589711  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.589629  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.589635  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.589680  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.589663  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.589618  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.589594  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.589538  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.589516  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.589477  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.589546  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.589527  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.589634  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.589588  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.589578  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.589602  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.589515  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.589530  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.589548  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.589606  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.589587  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.589603  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.589600  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.589579  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.589550  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.589595  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.589645  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.589572  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.589628  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.589676  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.589686  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.589686  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.589714  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.589741  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.589752  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.589761  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.589806  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.589834  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.589807  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.589817  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.589842  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.589784  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.589803  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.589730  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.589684  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.589661  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.589655  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.589682  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.589638  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.589649  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.589649  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.589653  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.589620  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.589581  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.589625  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.589651  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.589700  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.589721  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.589703  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.589763  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.589777  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.589736  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.589715  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.589641  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.589629  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.589617  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.589623  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.589578  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.589626  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.589603  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.589626  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.589607  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.589644  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.589654  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.589684  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.589644  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.589639  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.589547  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.589597  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.589617  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.589590  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.589515  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.589483  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.589511  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.589532  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.589606  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.589594  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.589626  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.589591  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.589569  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.589623  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.589583  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.589588  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.589576  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.589585  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.589570  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.589551  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.589577  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.589544  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.589563  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.589576  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.589548  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.589491  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.589571  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.589612  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.589616  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.589610  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.589607  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.589587  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.589562  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.589592  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.589554  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.589546  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.589608  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.589635  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.589622  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.589614  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.589623  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.589621  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.589653  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.589654  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.589693  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.589672  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.589690  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.589704  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.589759  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.589760  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.589776  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.589781  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.589809  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.589774  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.589827  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.589807  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.589814  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.589742  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.589734  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.589696  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.589680  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.589715  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.589707  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.589719  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.589706  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.589717  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.589697  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.589731  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.589751  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.589742  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.589679  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.589703  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.589690  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.589700  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.589685  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.589719  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.589744  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.589711  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.589688  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.589665  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.589681  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.589686  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.589691  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.589725  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.589745  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.589780  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.589732  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.589753  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.589757  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.589704  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.589714  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.589753  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.589746  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.589734  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.589747  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.589775  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.589837  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.589820  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.589843  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.589863  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.589858  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.589821  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.589857  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.589872  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.589866  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.589840  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.589857  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.589875  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.589860  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.589826  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.589837  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.589849  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.589831  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.589843  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.589866  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.589870  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.589884  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.589928  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.589947  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.589983  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.589933  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.589899  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.589887  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.589846  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.589864  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.589921  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.589934  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.589952  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.589962  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.589965  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.589922  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.589951  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.589924  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.589912  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.589895  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.589866  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.589840  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.589868  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.589849  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.589858  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.589860  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.589866  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.589819  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.589838  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.589801  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.589832  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.589822  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.589842  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.589845  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.589862  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.589845  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.589814  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.589821  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.589855  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.589811  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.589766  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.589765  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.589823  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.589831  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.589832  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.589854  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.589857  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.589852  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.589821  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.589817  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.589835  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.589845  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.589800  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.589781  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.589789  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.589777  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.587692\n",
      "@eval_loop_avg_loss=0.585420\n",
      "Epoch 7/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.570322  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.579756  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.584151  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.583659  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.588073  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.589092  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.590261  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.592643  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.588599  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.589356  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.590525  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.591384  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.592416  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.591506  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.590207  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.589346  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.589566  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.589341  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.589426  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.588797  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.589541  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.588525  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.587766  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.587372  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.588360  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.588901  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.588888  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.588432  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.588498  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.589139  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.589352  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.588921  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.589249  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.588795  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.589555  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.589772  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.589938  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.590152  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.590367  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.590440  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.590027  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.589894  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.590302  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.590634  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.590796  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.590546  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.590431  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.590186  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.590425  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.590383  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.590532  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.590747  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.590940  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.591079  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.591013  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.590968  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.590713  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.590424  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.589704  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.589821  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.589788  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.589612  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.589406  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.589994  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.590091  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.590409  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.590140  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.590104  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.590296  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.590505  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.590322  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.590414  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.590318  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.590141  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.590082  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.589825  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.589755  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.589904  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.589577  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.589349  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.589333  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.589477  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.589187  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.589195  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.588979  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.588751  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.588558  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.588342  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.588436  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.588307  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.588216  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.587949  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.587762  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.587935  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.587802  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.587921  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.587842  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.587923  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.587899  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.588072  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.588115  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.588087  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.588253  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.588059  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.587849  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.587894  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.587952  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.588001  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.588147  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.588311  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.588125  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.588123  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.588114  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.588113  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.588011  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.588014  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.587874  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.587654  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.587719  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.587803  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.587757  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.587971  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.587899  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.587875  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.588104  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.588046  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.588083  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.588239  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.588230  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.588107  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.588196  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.588190  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.588298  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.588388  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.588367  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.588390  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.588399  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.588348  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.588354  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.588430  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.588512  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.588473  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.588384  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.588367  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.588509  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.588359  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.588352  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.588207  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.588237  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.588180  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.588233  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.588242  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.588305  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.588412  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.588398  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.588390  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.588215  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.588439  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.588355  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.588321  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.588478  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.588456  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.588446  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.588495  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.588500  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.588439  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.588416  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.588328  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.588263  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.588327  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.588279  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.588257  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.588313  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.588397  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.588352  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.588169  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.588171  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.588156  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.588134  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.588042  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.588060  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.588045  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.587934  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.587980  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.587917  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.587782  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.587641  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.587707  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.587697  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.587685  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.587642  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.587700  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.587671  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.587694  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.587665  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.587708  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.587675  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.587736  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.587658  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.587741  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.587858  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.588047  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.587947  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.587857  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.587897  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.587945  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.587879  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.587911  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.587970  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.588130  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.588066  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.588085  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.588123  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.588043  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.588059  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.587997  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.587932  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.587934  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.587838  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.587836  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.587958  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.587950  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.587927  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.587874  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.587870  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.587787  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.587682  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.587655  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.587701  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.587644  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.587633  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.587581  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.587666  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.587747  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.587647  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.587622  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.587649  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.587651  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.587645  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.587563  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.587564  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.587526  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.587588  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.587510  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.587454  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.587483  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.587510  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.587455  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.587497  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.587483  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.587553  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.587520  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.587498  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.587481  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.587540  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.587609  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.587575  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.587697  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.587720  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.587676  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.587626  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.587650  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.587664  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.587733  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.587607  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.587599  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.587615  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.587586  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.587635  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.587702  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.587634  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.587632  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.587562  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.587564  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.587627  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.587684  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.587707  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.587631  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.587686  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.587640  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.587593  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.587655  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.587768  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.587667  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.587716  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.587716  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.587744  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.587840  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.587956  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.587994  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.587997  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.588017  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.588053  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.588096  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.588112  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.588099  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.588116  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.588070  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.588130  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.588098  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.587993  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.588058  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.588062  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.587993  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.587970  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.587968  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.587974  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.588082  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.588169  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.588136  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.588199  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.588120  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.588079  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.588091  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.588035  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.588030  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.588029  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.588046  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.588047  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.588031  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.588042  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.588065  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.588170  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.588135  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.588127  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.588060  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.588064  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.588100  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.588069  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.588030  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.588043  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.588061  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.588072  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.588079  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.588030  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.587987  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.587979  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.587956  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.587986  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.588043  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.588031  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.588054  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.587977  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.588033  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.587984  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.588040  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.588051  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.588046  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.588063  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.588092  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.588125  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.588144  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.588074  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.588023  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.588017  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.588001  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.588005  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.588037  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.588079  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.588094  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.588136  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.588145  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.588160  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.588162  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.588145  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.588093  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.588060  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.588044  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.588023  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.588022  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.588018  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.587986  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.588022  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.588028  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.588117  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.588167  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.588148  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.588110  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.588104  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.588123  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.588138  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.588165  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.588167  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.588199  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.588173  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.588116  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.588111  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.588122  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.588081  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.588093  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.588111  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.588104  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.588100  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.588053  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.588076  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.588078  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.588111  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.588116  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.588139  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.588129  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.588109  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.588097  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.588132  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.588135  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.588179  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.588198  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.588209  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.588210  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.588244  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.588231  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.588244  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.588260  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.588278  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.588307  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.588280  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.588279  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.588278  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.588271  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.588228  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.588236  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.588190  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.588212  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.588275  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.588293  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.588306  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.588317  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.588347  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.588381  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.588395  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.588352  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.588311  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.588364  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.588359  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.588342  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.588324  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.588375  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.588357  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.588336  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.588332  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.588339  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.588242  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.588224  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.588185  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.588174  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.588173  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.588184  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.588204  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.588222  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.588173  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.588116  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.588139  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.588173  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.588189  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.588188  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.588201  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.588201  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.588246  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.588221  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.588237  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.588216  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.588176  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.588230  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.588254  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.588228  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.588201  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.588243  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.588251  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.588285  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.588342  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.588374  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.588385  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.588416  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.588380  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.588408  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.588397  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.588403  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.588399  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.588477  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.588529  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.588499  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.588453  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.588447  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.588407  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.588374  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.588350  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.588354  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.588336  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.588337  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.588330  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.588384  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.588358  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.588329  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.588347  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.588340  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.588352  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.588322  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.588358  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.588338  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.588342  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.588347  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.588331  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.588323  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.588295  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.588281  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.588289  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.588315  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.588288  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.588293  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.588308  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.588276  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.588305  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.588301  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.588306  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.588342  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.588332  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.588317  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.588280  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.588291  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.588317  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.588340  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.588325  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.588370  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.588391  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.588389  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.588326  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.588312  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.588358  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.588339  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.588350  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.588361  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.588338  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.588358  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.588330  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.588347  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.588335  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.588347  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.588368  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.588351  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.588368  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.588393  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.588429  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.588388  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.588375  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.588344  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.588358  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.588325  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.588311  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.588370  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.588374  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.588375  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.588336  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.588295  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.588312  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.588335  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.588301  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.588295  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.588328  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.588335  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.588384  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.588397  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.588364  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.588368  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.588387  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.588409  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.588404  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.588396  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.588360  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.588357  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.588322  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.588309  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.588355  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.588388  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.588416  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.588403  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.588389  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.588354  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.588313  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.588305  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.588302  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.588327  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.588303  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.588325  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.588333  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.588345  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.588308  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.588338  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.588318  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.588282  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.588271  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.588225  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.588234  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.588246  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.588219  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.588203  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.588170  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.588123  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.588099  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.588068  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.588040  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.588034  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.586223\n",
      "@eval_loop_avg_loss=0.583975\n",
      "Epoch 8/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.583659  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.592335  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.598473  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.602063  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.603279  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.601573  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.600552  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.598738  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.600541  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.600100  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.598850  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.597055  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.596759  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.593927  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.593657  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.592849  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.592403  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.591842  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.591564  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.590707  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.589586  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.587977  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.589353  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.588369  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.588347  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.588370  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.587984  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.588835  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.588260  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.588029  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.587796  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.587685  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.587440  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.588167  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.588511  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.587909  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.587905  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.588108  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.587600  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.587325  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.588198  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.587949  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.587839  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.587850  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.587530  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.587444  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.587727  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.587277  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.586966  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.587029  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.586696  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.586916  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.586966  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.587244  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.587410  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.587660  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.587354  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.587221  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.587076  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.586937  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.586439  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.586742  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.586997  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.586752  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.586781  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.586976  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.587193  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.587117  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.587085  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.587109  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.587393  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.587516  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.587541  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.587418  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.587716  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.587789  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.587661  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.587355  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.587450  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.587603  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.587881  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.587784  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.587387  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.587084  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.586832  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.587125  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.587184  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.587146  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.587141  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.587424  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.587104  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.587147  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.586713  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.586844  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.586967  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.587135  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.586736  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.586885  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.587091  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.587172  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.586900  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.587020  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.587040  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.586985  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.586793  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.586716  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.586818  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.586705  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.586730  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.586765  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.586586  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.586472  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.586491  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.586428  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.586341  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.586355  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.586428  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.586442  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.586521  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.586760  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.586877  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.586888  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.586914  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.586874  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.586950  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.587064  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.586933  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.587011  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.587041  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.587083  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.587148  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.587163  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.587266  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.587040  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.586978  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.586938  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.586969  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.586982  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.586760  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.586805  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.587014  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.586980  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.587087  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.586990  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.587054  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.587069  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.587077  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.587063  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.587163  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.587028  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.587055  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.586827  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.586760  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.586796  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.586657  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.586514  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.586623  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.586778  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.586846  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.586864  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.586863  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.586992  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.587134  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.587067  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.586977  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.587039  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.587041  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.587087  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.587149  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.587057  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.587152  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.587226  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.587136  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.587139  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.587234  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.587219  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.587346  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.587408  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.587427  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.587492  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.587471  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.587481  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.587557  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.587580  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.587728  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.587711  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.587608  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.587622  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.587665  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.587760  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.587794  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.587741  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.587703  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.587733  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.587885  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.587875  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.587792  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.587751  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.587728  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.587597  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.587523  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.587494  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.587380  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.587327  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.587212  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.587215  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.587025  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.586965  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.586928  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.587039  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.587000  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.586978  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.586966  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.586963  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.586998  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.586984  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.586960  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.586979  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.586999  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.586994  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.587096  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.587040  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.587055  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.587064  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.586987  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.586994  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.587032  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.587063  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.587016  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.587032  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.587093  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.587107  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.587064  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.587113  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.587080  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.587010  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.587109  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.587130  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.587174  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.587104  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.587023  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.587029  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.587043  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.586889  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.586886  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.586864  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.586794  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.586733  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.586759  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.586704  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.586614  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.586676  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.586693  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.586743  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.586817  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.586880  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.586913  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.586958  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.586964  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.587025  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.587034  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.586962  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.587030  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.587062  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.587105  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.587070  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.587039  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.587039  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.587078  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.587085  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.587120  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.587113  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.587069  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.587138  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.587250  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.587255  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.587279  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.587322  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.587364  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.587403  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.587452  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.587413  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.587466  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.587429  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.587435  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.587526  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.587557  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.587643  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.587584  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.587594  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.587626  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.587644  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.587671  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.587555  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.587574  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.587535  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.587495  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.587512  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.587448  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.587512  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.587580  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.587577  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.587600  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.587651  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.587622  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.587610  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.587622  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.587623  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.587575  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.587502  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.587529  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.587588  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.587590  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.587632  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.587668  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.587624  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.587588  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.587637  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.587589  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.587577  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.587489  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.587486  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.587380  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.587398  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.587295  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.587294  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.587242  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.587260  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.587268  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.587321  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.587327  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.587376  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.587337  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.587279  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.587223  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.587263  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.587330  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.587338  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.587357  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.587424  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.587484  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.587501  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.587441  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.587445  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.587387  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.587412  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.587471  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.587420  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.587372  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.587406  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.587361  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.587328  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.587260  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.587271  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.587296  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.587267  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.587169  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.587156  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.587144  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.587179  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.587127  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.587165  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.587186  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.587155  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.587112  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.587077  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.587072  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.587093  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.587092  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.587149  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.587153  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.587156  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.587148  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.587149  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.587150  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.587200  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.587130  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.587114  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.587148  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.587183  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.587201  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.587216  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.587205  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.587169  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.587168  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.587134  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.587175  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.587109  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.587088  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.587100  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.587077  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.587092  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.587110  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.587050  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.587038  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.587072  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.587062  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.587090  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.587115  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.587058  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.587077  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.587113  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.587086  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.587105  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.587145  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.587193  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.587173  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.587170  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.587182  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.587170  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.587166  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.587224  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.587256  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.587199  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.587210  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.587204  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.587233  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.587221  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.587255  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.587238  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.587207  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.587204  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.587157  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.587233  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.587254  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.587252  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.587180  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.587233  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.587218  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.587228  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.587170  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.587227  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.587267  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.587203  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.587185  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.587155  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.587174  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.587156  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.587109  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.587100  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.587138  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.587179  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.587162  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.587096  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.587086  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.587101  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.587153  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.587126  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.587125  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.587139  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.587093  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.587120  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.587142  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.587055  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.587045  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.587029  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.587029  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.586995  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.586936  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.586939  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.586968  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.586963  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.586910  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.586928  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.586893  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.586914  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.586879  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.586872  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.586850  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.586882  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.586880  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.586849  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.586818  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.586766  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.586745  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.586726  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.586710  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.586705  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.586701  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.586679  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.586640  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.586649  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.586634  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.586634  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.586615  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.586648  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.586694  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.586691  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.586668  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.586635  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.586633  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.586699  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.586735  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.586768  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.586755  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.586734  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.586736  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.586759  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.586770  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.586738  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.586748  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.586810  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.586786  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.586753  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.586729  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.586753  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.586726  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.586741  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.586738  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.586721  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.586724  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.586771  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.586764  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.586724  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.586707  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.586724  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.586713  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.586714  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.586756  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.586750  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.586755  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.586792  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.586805  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.586793  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.586788  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.586767  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.586768  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.586767  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.586787  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.586777  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.586792  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.586803  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.586777  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.586811  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.586808  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.586797  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.586812  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.586839  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.586863  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.586824  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.586810  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.586793  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.586824  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.586818  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.586810  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.586775  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.586758  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.586753  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.586777  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.586782  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.586782  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.586769  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.586781  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.586795  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.586812  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.586841  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.586835  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.586829  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.586821  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.586827  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.586808  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.586804  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.586817  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.586815  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.586788  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.586804  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.586822  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.586816  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.586810  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.586805  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.586816  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.586794  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.586766  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.586785  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.586737  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.586767  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.586750  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.586735  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.586705  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.586717  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.586701  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.586675  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.586694  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.586649  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.586596  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.586591  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.586651  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.586672  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.586688  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.586693  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.586734  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.586748  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.586756  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.586748  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.586765  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.586792  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.586790  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.586804  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.586793  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.586797  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.584924\n",
      "@eval_loop_avg_loss=0.582706\n",
      "Epoch 9/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.581917  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.584348  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.585633  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.585161  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.591199  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.592696  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.597375  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.592084  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.590451  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.589234  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.588264  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.588657  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.587830  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.588052  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.588052  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.588380  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.588518  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.587833  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.587918  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.588970  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.588511  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.588005  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.587745  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.588407  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.588644  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.588588  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.588252  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.587483  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.587768  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.587553  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.587982  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.588098  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.587795  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.587712  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.587940  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.587358  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.587316  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.587658  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.587458  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.587533  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.587199  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.586757  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.586463  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.586199  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.585978  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.586334  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.586191  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.586134  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.586424  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.586256  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.586429  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.586128  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.586095  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.586114  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.586055  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.585430  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.585502  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.585254  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.584864  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.585327  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.585275  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.585034  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.585317  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.585482  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.585851  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.585905  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.585716  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.585623  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.585256  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.585589  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.585482  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.585206  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.585171  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.585368  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.585152  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.585516  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.585403  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.585322  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.584895  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.584966  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.585278  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.585466  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.585238  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.585405  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.585441  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.585214  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.585181  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.585235  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.585377  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.585267  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.585220  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.585396  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.585522  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.585327  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.585489  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.585534  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.585682  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.585500  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.585316  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.585073  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.585018  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.585033  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.585220  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.585304  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.585242  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.585253  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.585418  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.585348  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.585323  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.585211  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.585283  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.585493  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.585535  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.585567  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.585590  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.585566  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.585798  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.585751  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.585727  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.585950  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.586251  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.586329  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.586224  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.586062  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.586093  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.585956  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.586064  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.586211  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.586122  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.586109  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.586249  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.586074  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.586158  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.586170  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.586007  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.586055  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.585924  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.586003  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.586029  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.585979  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.586129  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.586091  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.586077  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.586183  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.586258  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.586252  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.586264  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.586048  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.586294  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.586263  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.586240  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.586333  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.586222  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.586178  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.586150  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.586126  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.586231  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.586307  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.586382  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.586473  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.586516  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.586456  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.586389  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.586438  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.586430  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.586471  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.586463  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.586385  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.586444  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.586433  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.586294  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.586227  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.586241  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.586159  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.586142  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.586230  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.586248  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.586242  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.586261  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.586383  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.586261  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.586299  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.586223  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.586309  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.586302  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.586320  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.586420  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.586264  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.586209  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.586157  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.586168  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.586108  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.586066  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.586084  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.586048  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.586100  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.586187  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.586286  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.586262  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.586169  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.586124  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.586080  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.586060  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.586026  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.586005  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.586015  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.586231  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.586174  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.586248  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.586220  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.586176  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.586160  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.586141  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.586187  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.586211  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.586155  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.586198  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.586078  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.586020  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.586022  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.586087  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.585959  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.585865  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.585766  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.585882  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.585992  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.585924  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.585957  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.585988  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.586177  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.586314  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.586259  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.586215  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.586261  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.586253  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.586187  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.586254  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.586200  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.586179  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.586116  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.586181  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.586130  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.586110  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.586139  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.586062  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.586052  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.586098  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.586185  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.586283  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.586201  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.586155  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.586192  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.586155  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.586146  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.586097  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.586122  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.586180  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.586198  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.586112  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.586106  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.586099  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.586072  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.586064  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.586027  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.585995  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.586078  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.586074  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.586079  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.586179  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.586157  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.586173  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.586195  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.586274  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.586299  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.586337  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.586408  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.586468  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.586575  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.586696  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.586744  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.586810  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.586752  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.586782  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.586753  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.586712  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.586788  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.586810  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.586753  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.586664  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.586646  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.586604  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.586647  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.586600  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.586656  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.586639  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.586491  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.586449  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.586490  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.586544  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.586501  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.586413  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.586450  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.586495  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.586445  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.586392  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.586456  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.586443  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.586411  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.586476  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.586397  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.586392  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.586369  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.586345  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.586275  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.586355  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.586373  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.586407  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.586408  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.586494  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.586456  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.586377  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.586389  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.586334  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.586279  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.586261  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.586255  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.586270  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.586222  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.586216  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.586186  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.586175  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.586166  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.586169  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.586121  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.586084  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.586114  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.586104  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.586096  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.586059  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.585977  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.585975  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.585993  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.585997  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.585964  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.585926  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.585997  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.585952  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.585976  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.585930  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.585853  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.585890  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.585892  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.585868  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.585869  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.585810  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.585815  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.585855  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.585780  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.585781  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.585838  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.585833  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.585812  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.585785  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.585828  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.585858  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.585849  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.585839  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.585818  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.585785  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.585803  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.585736  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.585763  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.585792  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.585762  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.585790  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.585782  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.585726  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.585776  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.585759  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.585796  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.585763  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.585750  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.585747  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.585746  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.585722  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.585666  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.585685  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.585695  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.585672  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.585705  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.585720  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.585736  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.585749  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.585772  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.585825  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.585794  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.585780  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.585775  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.585790  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.585820  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.585791  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.585736  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.585716  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.585738  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.585690  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.585674  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.585669  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.585654  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.585698  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.585682  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.585745  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.585761  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.585759  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.585760  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.585722  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.585708  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.585713  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.585741  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.585741  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.585778  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.585777  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.585792  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.585737  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.585736  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.585663  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.585658  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.585684  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.585671  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.585754  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.585753  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.585786  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.585763  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.585814  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.585884  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.585856  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.585818  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.585856  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.585896  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.585913  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.585936  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.585882  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.585882  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.585902  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.585907  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.585880  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.585868  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.585893  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.585927  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.585949  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.585912  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.585904  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.585924  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.585931  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.585910  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.585848  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.585899  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.585920  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.585928  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.585913  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.585931  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.585919  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.585930  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.585912  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.585899  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.585882  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.585905  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.585879  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.585886  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.585858  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.585878  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.585909  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.585846  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.585846  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.585882  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.585912  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.585919  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.585919  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.585939  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.585954  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.585976  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.585930  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.585954  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.585945  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.585993  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.585996  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.585976  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.585996  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.585984  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.585928  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.585905  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.585828  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.585805  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.585818  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.585848  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.585875  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.585819  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.585791  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.585812  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.585829  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.585842  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.585849  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.585810  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.585844  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.585809  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.585798  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.585776  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.585721  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.585687  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.585685  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.585674  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.585711  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.585722  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.585698  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.585684  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.585701  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.585709  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.585670  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.585724  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.585748  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.585786  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.585766  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.585779  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.585775  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.585776  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.585700  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.585708  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.585657  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.585677  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.585647  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.585588  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.585605  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.585589  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.585620  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.585602  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.585620  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.585600  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.585624  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.585618  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.585639  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.585651  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.585621  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.585631  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.585693  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.585732  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.585764  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.585746  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.585788  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.585813  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.585808  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.585809  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.585827  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.585893  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.585879  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.585848  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.585850  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.585849  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.585872  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.585861  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.585876  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.585866  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.585831  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.585845  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.585844  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.585830  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.585864  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.585813  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.585834  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.585814  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.585835  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.585838  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.585823  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.585804  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.585812  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.585829  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.585863  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.585875  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.585887  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.585888  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.585896  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.585869  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.585877  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.585870  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.585882  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.585905  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.585872  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.585877  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.585871  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.585879  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.585840  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.585819  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.585809  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.585792  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.585803  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.585805  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.585771  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.585773  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.585816  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.585763  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.585770  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.585737  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.584145\n",
      "@eval_loop_avg_loss=0.581943\n",
      "Epoch 10/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.595618  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.583269  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.580825  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.579988  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.578753  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.579768  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.583302  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.583607  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.584630  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.585933  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.583246  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.582439  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.582978  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.582941  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.581824  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.581570  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.582709  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.583448  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.585347  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.586050  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.586251  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.585793  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.586161  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.586139  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.586972  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.586425  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.586324  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.586414  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.586626  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.586599  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.587249  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.587803  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.587232  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.587611  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.587584  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.587385  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.587802  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.587861  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.587811  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.588229  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.587837  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.588117  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.588408  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.587691  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.587331  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.587642  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.587254  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.587532  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.587992  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.588556  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.588444  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.588241  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.587892  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.587946  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.587985  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.588069  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.587505  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.587393  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.587778  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.587924  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.587753  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.587420  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.587363  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.587267  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.587470  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.587672  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.587557  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.587508  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.587212  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.586866  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.586973  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.587122  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.587013  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.586933  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.586766  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.586602  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.586526  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.586821  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.586755  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.586990  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.586696  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.586859  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.586838  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.586579  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.586368  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.586089  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.586199  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.586142  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.586076  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.586089  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.585860  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.585849  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.585899  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.585751  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.585525  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.585200  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.584972  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.585223  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.585310  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.585521  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.585652  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.585583  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.585591  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.585706  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.585629  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.585653  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.585593  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.585727  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.585860  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.585590  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.585414  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.585246  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.585144  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.585289  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.585306  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.585337  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.585249  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.585347  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.585358  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.585283  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.585138  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.585198  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.585339  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.585482  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.585373  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.585382  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.585415  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.585354  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.585339  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.585272  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.585059  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.585143  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.585196  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.585291  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.585206  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.585142  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.585191  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.585195  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.585188  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.585087  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.585258  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.585354  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.585434  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.585486  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.585528  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.585500  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.585555  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.585709  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.585733  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.585799  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.585670  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.585521  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.585389  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.585370  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.585371  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.585380  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.585247  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.585307  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.585287  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.585420  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.585371  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.585330  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.585386  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.585147  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.585119  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.585132  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.585016  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.585068  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.585048  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.584953  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.585102  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.585098  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.585146  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.585203  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.585155  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.585279  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.585179  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.585085  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.585146  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.585183  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.585240  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.585263  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.585234  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.585310  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.585295  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.585332  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.585348  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.585340  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.585267  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.585267  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.585391  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.585401  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.585314  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.585437  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.585434  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.585343  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.585302  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.585298  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.585228  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.585412  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.585498  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.585652  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.585758  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.585915  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.585966  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.585943  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.586001  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.585955  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.585840  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.585851  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.585812  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.585752  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.585812  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.585856  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.585762  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.585726  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.585655  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.585647  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.585672  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.585654  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.585671  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.585744  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.585918  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.585779  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.585778  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.585692  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.585694  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.585746  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.585738  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.585761  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.585738  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.585745  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.585760  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.585734  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.585714  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.585587  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.585675  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.585698  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.585801  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.585830  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.585846  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.585814  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.585795  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.585712  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.585640  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.585585  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.585634  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.585610  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.585592  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.585540  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.585511  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.585529  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.585515  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.585490  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.585464  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.585399  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.585320  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.585347  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.585396  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.585404  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.585432  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.585472  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.585442  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.585407  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.585387  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.585416  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.585389  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.585376  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.585316  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.585272  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.585286  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.585302  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.585230  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.585276  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.585221  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.585222  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.585288  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.585286  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.585271  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.585304  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.585256  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.585182  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.585210  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.585224  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.585271  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.585393  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.585340  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.585383  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.585453  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.585581  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.585630  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.585677  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.585643  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.585678  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.585720  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.585707  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.585597  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.585623  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.585627  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.585638  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.585672  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.585676  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.585624  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.585736  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.585695  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.585667  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.585748  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.585725  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.585797  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.585811  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.585769  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.585912  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.585933  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.585849  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.585872  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.585850  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.585791  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.585794  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.585802  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.585867  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.585779  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.585872  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.585842  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.585841  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.585850  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.585897  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.585839  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.585713  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.585691  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.585726  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.585776  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.585755  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.585807  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.585830  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.585831  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.585871  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.585837  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.585806  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.585861  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.585883  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.585902  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.585976  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.585967  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.586040  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.586062  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.586016  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.586046  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.586087  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.586082  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.586120  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.586071  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.586013  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.586019  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.586099  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.586050  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.586064  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.586009  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.586015  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.586053  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.586052  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.586065  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.586109  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.586120  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.586137  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.586072  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.586079  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.586062  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.586092  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.586067  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.586073  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.586079  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.586114  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.586057  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.586085  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.586108  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.586025  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.586039  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.586055  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.586004  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.585979  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.585920  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.585918  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.585942  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.585940  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.586007  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.586003  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.585992  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.585948  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.585911  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.585873  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.585843  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.585819  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.585857  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.585855  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.585848  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.585836  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.585841  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.585899  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.585874  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.585873  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.585872  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.585953  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.586044  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.586066  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.586042  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.585996  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.585970  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.585987  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.585932  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.585925  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.585900  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.585905  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.585902  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.585884  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.585877  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.585865  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.585822  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.585806  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.585796  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.585843  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.585818  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.585775  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.585773  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.585770  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.585704  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.585764  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.585795  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.585785  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.585819  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.585787  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.585775  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.585766  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.585741  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.585734  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.585717  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.585692  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.585685  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.585716  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.585725  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.585731  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.585742  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.585780  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.585812  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.585802  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.585771  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.585760  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.585723  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.585670  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.585621  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.585618  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.585601  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.585584  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.585544  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.585539  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.585508  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.585477  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.585486  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.585495  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.585452  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.585454  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.585443  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.585500  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.585458  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.585424  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.585416  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.585459  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.585410  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.585425  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.585321  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.585360  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.585354  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.585369  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.585397  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.585366  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.585341  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.585290  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.585280  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.585253  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.585250  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.585227  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.585208  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.585216  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.585222  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.585182  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.585188  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.585163  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.585133  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.585127  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.585106  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.585117  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.585102  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.585082  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.585030  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.585056  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.585056  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.585050  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.585042  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.585033  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.584979  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.584937  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.584986  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.584968  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.584998  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.584989  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.584996  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.585020  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.585039  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.585039  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.585042  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.585031  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.585022  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.584996  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.585037  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.585065  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.585067  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.585071  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.585041  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.585023  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.585038  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.585085  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.585073  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.585084  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.585058  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.585039  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.585070  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.585092  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.585116  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.585135  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.585144  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.585097  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.585113  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.585098  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.585082  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.585050  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.585077  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.585070  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.585081  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.585054  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.585048  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.585066  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.585052  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.585058  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.585038  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.585031  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.584979  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.585012  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.584997  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.584989  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.585059  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.585063  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.585078  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.585071  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.585099  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.585098  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.585099  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.585097  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.585103  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.585075  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.585092  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.585096  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.585086  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.585111  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.585128  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.585141  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.585130  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.585099  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.585091  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.585103  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.585124  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.585155  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.585162  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.585183  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.585174  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.585142  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.585139  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.585151  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.585146  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.585123  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.585146  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.585169  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.585146  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.585162  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.585184  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.585171  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.585169  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.585187  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.585194  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.585220  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.585216  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.585212  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.585228  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.585237  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.585238  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.585223  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.585181  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.585209  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.585221  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.585207  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.585174  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.585182  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.583709\n",
      "@eval_loop_avg_loss=0.581526\n",
      "Epoch 11/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.590591  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.580128  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.583502  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.586141  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.585178  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.584758  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.584336  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.585768  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.585400  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.586065  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.587633  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.588277  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.588849  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.589317  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.587245  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.586772  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.586208  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.585318  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.585626  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.585994  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.585458  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.585538  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.586184  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.585571  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.585809  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.584937  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.586093  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.585914  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.584655  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.584185  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.583836  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.583772  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.582845  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.583261  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.583282  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.582416  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.582557  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.582512  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.582593  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.582160  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.582411  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.582545  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.582693  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.582722  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.582867  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.582632  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.583115  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.582693  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.583170  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.583360  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.583489  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.583780  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.583797  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.583995  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.584108  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.584374  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.584070  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.583948  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.583951  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.583998  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.583609  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.583723  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.583716  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.583819  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.583650  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.584018  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.584064  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.584110  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.583970  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.583980  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.583839  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.584109  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.584107  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.584081  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.583872  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.583783  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.583902  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.583936  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.583998  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.584144  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.584023  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.583884  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.583711  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.583609  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.583846  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.583705  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.583718  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.583644  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.583846  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.583663  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.583794  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.583889  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.583792  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.583668  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.583982  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.584193  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.584007  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.583906  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.583702  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.583817  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.583648  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.583610  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.583741  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.583841  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.583674  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.583842  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.584018  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.584273  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.584138  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.584041  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.584034  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.584062  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.584273  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.584567  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.584716  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.584787  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.584588  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.584684  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.584660  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.584460  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.584479  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.584585  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.584597  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.584627  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.584659  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.584817  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.585086  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.585099  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.585035  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.585063  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.585090  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.584963  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.585011  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.584963  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.585081  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.585206  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.585209  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.585160  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.585197  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.585205  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.585306  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.585277  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.585275  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.585068  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.585166  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.585176  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.585274  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.585345  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.585254  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.585150  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.585115  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.585030  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.584917  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.584911  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.584855  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.584915  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.584853  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.584894  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.584766  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.584847  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.584856  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.584758  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.584798  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.584660  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.584731  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.584613  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.584436  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.584545  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.584524  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.584470  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.584416  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.584269  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.584265  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.584258  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.584221  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.584225  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.584216  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.584153  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.584101  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.584146  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.584062  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.584070  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.584239  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.584177  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.584107  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.584100  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.584145  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.584359  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.584430  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.584255  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.584200  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.584186  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.584243  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.584193  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.584199  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.584261  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.584244  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.584250  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.584319  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.584365  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.584318  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.584359  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.584291  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.584229  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.584290  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.584272  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.584067  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.584009  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.584012  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.583873  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.583938  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.583969  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.583969  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.583960  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.584075  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.584077  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.584048  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.584077  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.584163  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.584257  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.584144  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.584260  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.584384  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.584320  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.584369  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.584287  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.584332  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.584279  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.584218  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.584175  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.584031  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.584014  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.584056  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.584016  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.583953  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.583888  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.583960  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.583907  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.583889  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.583938  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.584014  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.584076  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.584026  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.584009  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.583973  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.583988  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.584020  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.583951  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.583986  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.584105  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.584043  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.584042  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.584071  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.584140  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.584213  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.584152  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.584134  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.584148  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.584066  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.584050  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.584118  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.584153  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.584088  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.584061  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.584138  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.584151  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.584144  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.584157  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.584180  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.584062  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.584120  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.584121  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.584194  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.584237  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.584174  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.584217  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.584242  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.584326  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.584430  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.584403  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.584446  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.584463  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.584371  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.584340  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.584336  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.584296  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.584307  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.584314  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.584294  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.584363  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.584417  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.584393  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.584388  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.584394  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.584393  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.584406  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.584410  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.584419  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.584426  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.584402  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.584476  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.584433  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.584454  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.584416  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.584451  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.584426  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.584335  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.584399  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.584389  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.584384  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.584334  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.584368  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.584287  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.584279  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.584214  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.584175  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.584147  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.584091  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.584098  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.584084  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.584105  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.584077  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.584097  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.584087  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.584081  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.584114  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.584084  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.584106  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.584039  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.584010  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.584010  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.583991  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.584041  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.584040  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.584002  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.584013  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.584048  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.584103  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.584151  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.584148  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.584192  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.584229  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.584213  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.584203  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.584137  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.584165  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.584077  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.584034  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.584074  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.584158  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.584164  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.584177  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.584142  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.584216  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.584222  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.584238  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.584200  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.584170  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.584174  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.584181  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.584239  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.584292  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.584332  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.584358  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.584320  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.584349  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.584425  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.584499  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.584431  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.584445  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.584451  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.584473  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.584456  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.584426  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.584399  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.584424  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.584415  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.584423  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.584436  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.584425  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.584404  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.584343  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.584270  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.584287  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.584267  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.584303  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.584325  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.584285  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.584319  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.584327  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.584317  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.584343  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.584248  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.584252  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.584288  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.584355  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.584388  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.584420  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.584379  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.584424  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.584421  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.584396  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.584341  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.584347  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.584377  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.584348  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.584352  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.584308  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.584255  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.584322  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.584332  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.584359  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.584411  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.584394  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.584366  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.584391  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.584483  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.584528  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.584547  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.584508  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.584535  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.584502  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.584483  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.584448  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.584474  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.584489  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.584488  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.584454  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.584487  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.584447  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.584470  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.584508  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.584509  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.584465  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.584457  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.584443  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.584429  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.584425  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.584411  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.584412  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.584399  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.584398  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.584408  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.584432  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.584368  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.584392  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.584426  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.584443  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.584470  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.584520  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.584448  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.584440  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.584476  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.584531  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.584533  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.584546  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.584463  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.584476  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.584455  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.584475  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.584460  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.584534  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.584594  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.584572  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.584587  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.584626  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.584615  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.584635  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.584604  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.584637  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.584669  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.584673  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.584678  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.584655  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.584702  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.584696  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.584703  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.584725  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.584713  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.584675  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.584691  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.584692  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.584652  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.584646  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.584707  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.584753  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.584705  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.584747  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.584694  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.584709  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.584708  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.584745  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.584743  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.584766  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.584724  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.584695  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.584737  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.584755  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.584731  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.584750  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.584788  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.584736  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.584729  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.584745  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.584724  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.584745  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.584742  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.584745  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.584781  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.584781  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.584749  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.584772  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.584781  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.584771  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.584767  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.584767  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.584731  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.584743  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.584707  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.584748  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.584784  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.584797  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.584799  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.584802  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.584813  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.584800  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.584783  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.584779  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.584758  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.584744  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.584754  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.584724  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.584694  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.584667  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.584671  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.584653  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.584665  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.584660  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.584700  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.584712  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.584730  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.584673  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.584681  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.584703  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.584693  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.584653  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.584671  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.584710  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.584695  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.584692  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.584700  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.584696  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.584668  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.584656  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.584655  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.584634  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.584646  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.584663  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.584669  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.584676  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.584688  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.584699  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.584686  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.584685  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.584709  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.584697  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.584717  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.584738  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.584747  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.584774  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.584791  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.584814  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.584820  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.584815  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.584824  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.584852  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.584857  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.584885  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.584887  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.584883  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.584859  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.584863  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.584873  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.584859  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.584890  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.584867  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.584888  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.584852  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.584831  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.584760  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.584759  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.584760  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.584758  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.584765  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.584764  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.584719  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.584715  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.584780  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.584803  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.584770  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.583367\n",
      "@eval_loop_avg_loss=0.581191\n",
      "Epoch 12/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.583677  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.588442  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.592811  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.584784  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.584339  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.581184  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.582858  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.584046  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.583739  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.584302  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.583588  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.582995  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.584290  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.584352  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.582532  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.580741  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.580086  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.579886  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.580593  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.580627  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.580437  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.579578  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.580354  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.580594  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.580645  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.581299  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.581474  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.581783  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.582268  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.582463  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.582894  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.584413  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.584557  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.584541  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.584827  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.585560  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.585693  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.585823  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.585701  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.585900  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.585676  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.585846  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.586585  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.586330  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.586646  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.586141  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.585894  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.586350  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.586495  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.586685  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.587002  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.587178  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.586958  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.586892  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.586943  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.586739  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.586537  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.586861  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.587236  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.587129  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.587154  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.587070  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.586643  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.586461  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.585818  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.586021  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.585759  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.585617  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.585536  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.585124  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.584967  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.584811  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.584710  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.584993  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.584983  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.584777  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.584648  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.584665  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.584641  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.584717  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.584591  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.584644  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.584755  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.585004  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.585090  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.584889  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.585241  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.585255  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.585191  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.584965  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.585158  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.585078  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.585204  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.585167  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.585333  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.585412  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.585388  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.585327  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.585102  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.585146  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.585350  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.585311  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.585003  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.584751  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.584842  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.584817  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.584828  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.584941  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.584946  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.584997  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.585071  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.585102  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.585078  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.584943  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.585145  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.585193  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.585208  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.585252  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.585480  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.585575  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.585635  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.585694  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.585432  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.585355  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.585351  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.585376  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.585336  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.585392  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.585397  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.585425  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.585432  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.585429  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.585559  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.585581  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.585590  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.585581  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.585575  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.585676  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.585676  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.585927  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.586008  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.586010  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.585930  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.585978  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.585802  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.585822  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.585796  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.585892  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.585641  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.585636  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.585597  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.585567  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.585585  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.585630  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.585522  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.585403  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.585365  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.585400  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.585419  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.585486  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.585484  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.585498  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.585510  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.585561  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.585668  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.585653  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.585665  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.585600  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.585506  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.585490  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.585606  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.585623  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.585645  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.585611  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.585595  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.585577  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.585721  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.585666  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.585589  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.585592  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.585631  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.585668  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.585742  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.585711  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.585597  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.585539  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.585572  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.585591  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.585551  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.585522  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.585437  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.585446  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.585412  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.585369  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.585338  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.585407  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.585305  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.585273  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.585165  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.585251  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.585116  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.585050  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.585088  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.585107  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.585074  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.585054  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.584972  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.584935  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.584949  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.584971  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.584985  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.585028  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.585061  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.585004  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.585058  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.584960  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.585027  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.585047  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.584951  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.584959  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.584925  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.584930  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.584916  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.584901  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.585012  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.584995  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.584895  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.584819  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.584963  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.584944  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.584976  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.584995  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.585056  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.585053  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.585205  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.585284  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.585218  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.585152  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.585149  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.585030  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.584928  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.585035  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.585061  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.584999  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.584992  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.584950  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.584963  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.584929  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.584976  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.585050  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.585031  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.585066  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.585106  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.585113  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.585128  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.585132  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.585110  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.585092  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.585123  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.585106  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.585239  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.585211  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.585182  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.585101  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.585041  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.585059  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.585066  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.584984  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.584917  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.584890  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.584955  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.584926  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.584877  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.584820  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.584839  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.584737  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.584806  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.584929  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.584990  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.584973  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.584985  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.584972  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.584935  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.584965  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.584898  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.584980  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.584946  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.584910  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.585031  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.585043  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.585057  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.585113  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.585090  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.585076  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.584993  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.585020  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.585049  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.585036  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.584991  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.585006  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.585034  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.584973  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.584964  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.584953  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.585055  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.585013  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.584989  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.584977  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.584967  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.584916  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.584945  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.584969  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.584996  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.584977  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.584957  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.584975  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.584999  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.585026  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.585035  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.584985  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.585018  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.584952  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.584946  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.584950  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.584972  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.584982  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.584952  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.585013  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.585041  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.585043  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.585064  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.585026  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.584990  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.585027  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.585001  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.584987  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.584958  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.584999  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.585039  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.584955  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.584949  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.584848  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.584744  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.584760  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.584728  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.584737  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.584804  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.584867  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.584790  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.584743  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.584646  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.584684  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.584686  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.584695  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.584693  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.584672  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.584635  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.584668  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.584662  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.584654  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.584631  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.584685  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.584742  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.584673  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.584692  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.584694  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.584675  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.584684  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.584595  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.584582  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.584540  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.584591  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.584587  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.584652  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.584702  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.584711  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.584698  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.584643  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.584642  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.584629  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.584632  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.584630  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.584629  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.584601  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.584558  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.584530  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.584571  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.584592  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.584612  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.584599  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.584559  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.584530  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.584510  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.584534  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.584538  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.584506  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.584448  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.584481  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.584462  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.584481  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.584432  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.584531  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.584508  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.584517  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.584498  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.584499  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.584523  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.584590  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.584594  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.584580  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.584556  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.584530  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.584546  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.584583  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.584652  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.584644  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.584635  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.584661  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.584660  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.584733  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.584698  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.584757  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.584771  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.584715  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.584687  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.584730  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.584730  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.584765  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.584738  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.584733  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.584692  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.584651  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.584632  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.584611  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.584553  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.584547  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.584594  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.584615  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.584575  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.584573  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.584553  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.584525  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.584515  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.584494  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.584571  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.584631  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.584588  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.584608  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.584581  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.584568  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.584554  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.584585  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.584608  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.584632  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.584648  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.584638  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.584662  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.584663  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.584684  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.584709  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.584645  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.584693  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.584668  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.584614  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.584599  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.584582  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.584553  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.584507  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.584459  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.584415  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.584396  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.584437  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.584458  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.584444  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.584432  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.584412  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.584432  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.584372  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.584430  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.584471  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.584494  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.584556  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.584551  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.584532  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.584531  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.584598  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.584565  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.584574  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.584585  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.584587  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.584595  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.584600  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.584616  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.584609  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.584610  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.584560  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.584546  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.584554  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.584564  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.584607  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.584582  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.584582  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.584627  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.584591  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.584590  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.584568  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.584606  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.584593  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.584615  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.584612  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.584608  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.584588  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.584641  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.584665  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.584663  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.584615  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.584628  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.584590  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.584610  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.584620  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.584586  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.584524  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.584506  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.584523  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.584510  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.584516  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.584511  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.584498  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.584479  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.584457  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.584484  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.584448  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.584437  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.584436  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.584418  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.584458  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.584498  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.584496  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.584475  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.584441  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.584436  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.584422  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.584412  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.584434  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.584477  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.584485  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.584492  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.584503  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.584509  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.584488  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.584499  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.584484  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.584431  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.584467  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.584455  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.584472  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.584517  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.584510  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.584552  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.584574  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.584554  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.584540  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.584499  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.584452  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.584443  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.584435  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.584468  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.584447  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.584415  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.584476  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.584458  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.584427  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.584407  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.584393  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.584409  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.584392  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.584407  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.584379  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.584394  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.584386  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.584403  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.584410  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.584467  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.584462  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.584476  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.584444  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.584442  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.584478  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.584471  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.584504  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.584533  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.584495  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.584499  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.584478  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.584465  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.584472  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.584448  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.584424  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.584418  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.584417  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.582949\n",
      "@eval_loop_avg_loss=0.580802\n",
      "Epoch 13/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.589911  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.606506  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.595707  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.586303  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.581320  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.585184  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.587471  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.583419  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.583845  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.584229  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.582988  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.583509  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.581890  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.581180  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.581401  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.580715  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.581579  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.583697  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.583646  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.584070  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.585099  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.584672  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.584054  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.584182  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.584293  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.583955  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.583721  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.583869  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.583076  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.582215  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.581784  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.581825  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.581068  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.580306  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.580348  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.580111  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.580315  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.580307  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.580329  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.581132  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.581592  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.581832  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.581509  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.581322  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.582043  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.582427  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.582599  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.583018  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.583454  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.583006  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.583091  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.583220  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.583436  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.583299  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.583208  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.583264  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.583494  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.583909  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.583358  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.583034  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.583031  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.582562  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.582260  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.582007  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.581879  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.582066  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.582037  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.582041  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.582222  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.582522  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.582583  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.582467  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.582676  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.582641  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.582382  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.582376  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.582203  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.582270  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.582390  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.581990  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.582176  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.582276  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.582047  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.582142  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.582232  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.582403  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.582174  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.582563  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.582930  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.582864  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.582793  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.582806  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.582759  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.582873  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.582864  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.582814  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.582849  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.582755  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.582386  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.582300  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.582480  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.582553  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.582392  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.582561  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.582675  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.582635  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.582641  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.582680  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.582753  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.582748  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.582817  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.582665  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.582632  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.582628  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.582564  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.582651  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.582653  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.582559  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.582541  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.582673  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.582616  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.582506  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.582478  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.582346  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.582312  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.582345  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.582449  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.582369  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.582520  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.582387  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.582506  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.582367  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.582385  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.582245  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.582373  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.582436  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.582632  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.582602  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.582433  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.582568  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.582586  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.582503  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.582579  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.582486  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.582379  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.582276  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.582311  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.582428  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.582363  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.582433  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.582460  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.582458  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.582467  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.582495  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.582559  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.582686  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.582630  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.582491  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.582479  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.582474  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.582537  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.582695  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.582654  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.582760  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.582783  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.582767  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.582907  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.582814  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.582709  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.582662  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.582819  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.582781  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.582750  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.582912  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.582924  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.582762  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.582949  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.582886  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.583038  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.583005  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.582983  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.582991  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.583072  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.583293  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.583277  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.583347  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.583378  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.583349  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.583151  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.583229  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.583199  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.583268  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.583167  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.583157  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.583143  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.583021  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.583050  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.583115  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.583206  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.583160  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.583207  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.583276  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.583228  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.583241  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.583335  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.583314  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.583256  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.583220  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.583339  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.583237  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.583216  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.583155  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.583138  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.583157  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.583178  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.583246  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.583222  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.583198  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.583204  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.583220  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.583181  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.583183  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.583235  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.583356  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.583416  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.583472  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.583588  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.583547  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.583606  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.583651  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.583667  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.583645  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.583664  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.583722  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.583770  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.583802  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.583750  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.583839  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.583804  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.583732  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.583726  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.583694  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.583595  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.583710  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.583703  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.583769  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.583787  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.583808  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.583728  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.583707  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.583773  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.583676  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.583771  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.583803  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.583803  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.583790  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.583833  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.583762  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.583739  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.583664  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.583673  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.583706  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.583640  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.583615  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.583642  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.583643  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.583702  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.583729  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.583683  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.583612  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.583505  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.583556  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.583557  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.583491  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.583532  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.583514  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.583523  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.583595  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.583608  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.583621  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.583607  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.583648  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.583627  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.583570  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.583572  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.583461  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.583533  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.583419  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.583350  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.583331  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.583380  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.583263  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.583205  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.583122  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.583187  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.583115  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.583047  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.583010  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.583028  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.583118  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.583217  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.583265  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.583291  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.583353  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.583349  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.583334  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.583287  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.583369  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.583382  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.583400  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.583383  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.583421  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.583463  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.583394  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.583334  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.583362  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.583408  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.583379  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.583463  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.583491  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.583555  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.583550  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.583564  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.583626  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.583577  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.583576  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.583632  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.583671  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.583604  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.583566  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.583564  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.583511  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.583477  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.583554  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.583611  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.583610  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.583527  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.583609  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.583577  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.583638  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.583667  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.583624  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.583593  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.583538  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.583505  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.583579  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.583609  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.583591  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.583584  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.583614  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.583636  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.583634  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.583627  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.583560  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.583516  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.583548  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.583620  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.583612  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.583635  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.583653  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.583629  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.583631  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.583605  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.583606  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.583585  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.583586  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.583640  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.583665  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.583682  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.583664  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.583693  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.583669  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.583649  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.583679  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.583700  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.583650  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.583704  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.583726  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.583732  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.583755  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.583699  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.583653  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.583659  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.583668  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.583696  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.583765  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.583810  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.583755  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.583751  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.583779  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.583816  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.583777  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.583811  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.583819  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.583816  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.583790  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.583823  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.583781  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.583725  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.583676  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.583716  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.583710  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.583719  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.583696  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.583716  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.583754  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.583789  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.583825  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.583865  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.583827  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.583838  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.583915  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.583982  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.584071  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.584063  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.584049  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.584122  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.584167  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.584103  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.584077  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.584056  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.584020  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.583970  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.583944  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.584005  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.583997  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.583970  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.584027  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.584024  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.583989  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.584003  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.583975  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.583988  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.583983  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.584005  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.583977  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.583979  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.583939  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.583982  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.584002  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.583992  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.584046  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.584059  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.584048  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.584005  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.584010  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.584056  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.584057  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.583988  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.584046  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.584067  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.584041  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.584054  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.584059  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.584047  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.584023  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.584007  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.583944  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.583975  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.584011  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.583995  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.583966  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.583952  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.583962  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.583979  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.583972  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.583923  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.583935  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.583943  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.583960  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.583951  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.583959  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.583958  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.583964  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.583989  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.584018  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.584030  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.584023  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.584022  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.584033  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.583995  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.583954  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.583951  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.583921  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.583928  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.583976  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.583956  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.583932  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.583920  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.583937  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.583955  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.583956  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.583969  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.583950  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.583904  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.583930  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.583885  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.583889  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.583891  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.583917  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.583893  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.583937  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.583927  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.583893  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.583848  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.583803  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.583795  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.583779  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.583764  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.583766  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.583786  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.583780  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.583760  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.583727  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.583739  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.583737  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.583696  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.583666  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.583644  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.583637  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.583629  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.583692  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.583690  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.583671  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.583680  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.583708  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.583715  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.583663  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.583655  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.583641  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.583627  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.583648  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.583635  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.583679  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.583723  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.583721  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.583720  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.583722  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.583713  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.583722  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.583715  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.583706  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.583708  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.583715  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.583717  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.583734  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.583745  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.583762  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.583772  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.583815  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.583819  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.583861  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.583837  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.583828  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.583833  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.583807  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.583797  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.583753  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.583727  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.583729  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.583708  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.583644  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.583670  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.583699  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.583718  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.583706  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.583675  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.583660  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.583686  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.583713  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.583698  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.583694  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.583726  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.583752  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.583751  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.583784  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.583767  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.583803  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.583785  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.583782  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.583793  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.583823  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.583844  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.583891  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.583866  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.583886  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.583920  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.583949  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.583980  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.584008  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.584004  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.584049  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.584072  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.584067  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.584028  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.584036  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.584062  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.584065  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.584067  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.584099  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.582546\n",
      "@eval_loop_avg_loss=0.580408\n",
      "Epoch 14/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.567841  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.583293  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.589397  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.591958  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.591465  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.590012  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.592822  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.593439  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.594464  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.594548  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.595466  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.592959  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.593061  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.592553  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.593769  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.593994  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.593534  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.593285  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.592048  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.591425  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.591096  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.590538  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.590744  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.590274  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.590268  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.589603  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.589722  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.589308  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.588983  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.589027  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.588915  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.588775  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.589229  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.589032  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.588784  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.588695  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.588302  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.587946  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.587892  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.587186  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.586898  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.587195  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.586874  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.587142  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.587256  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.587284  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.587229  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.587727  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.587632  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.587713  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.587447  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.587644  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.587271  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.587180  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.586989  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.587008  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.587124  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.587264  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.587008  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.587214  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.587092  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.587144  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.586888  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.587353  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.587251  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.587204  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.587208  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.586930  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.587168  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.587435  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.587541  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.587692  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.587517  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.587268  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.587112  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.587250  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.587327  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.586968  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.586993  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.587016  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.587054  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.586829  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.586836  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.586915  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.586685  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.586721  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.586923  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.587040  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.586978  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.587041  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.586835  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.586965  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.586717  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.586685  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.586639  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.586641  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.586481  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.586616  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.586440  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.586487  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.586690  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.586738  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.586713  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.586613  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.586639  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.586905  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.586927  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.587010  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.586920  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.586713  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.586759  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.586646  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.586654  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.586728  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.586823  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.586902  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.586962  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.586899  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.586905  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.586914  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.586821  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.586744  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.586750  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.586389  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.586363  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.586374  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.586344  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.586247  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.586126  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.585947  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.585831  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.585813  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.585845  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.585887  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.586013  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.585950  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.585924  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.586025  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.586035  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.585954  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.586034  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.586048  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.586010  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.585867  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.585826  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.585810  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.585759  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.585686  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.585723  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.585784  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.585735  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.585751  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.585701  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.585751  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.585779  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.585783  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.585926  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.585910  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.585803  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.585700  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.585704  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.585656  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.585659  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.585651  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.585592  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.585531  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.585445  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.585426  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.585303  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.585363  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.585289  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.585142  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.585089  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.585148  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.585170  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.585116  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.585069  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.585039  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.584961  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.584921  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.584845  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.584754  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.584780  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.584767  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.584705  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.584542  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.584561  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.584512  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.584512  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.584505  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.584366  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.584288  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.584243  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.584172  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.584263  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.584218  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.584201  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.584288  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.584232  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.584350  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.584227  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.584308  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.584254  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.584192  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.584225  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.584249  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.584249  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.584142  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.584172  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.584190  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.584196  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.584122  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.584100  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.583991  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.583997  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.584034  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.584017  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.583928  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.584015  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.583884  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.583895  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.583799  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.583741  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.583714  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.583726  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.583758  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.583750  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.583876  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.583872  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.583846  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.583937  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.583894  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.583920  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.583900  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.583920  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.583915  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.583895  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.583919  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.583917  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.583930  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.583979  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.583983  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.583963  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.583910  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.583924  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.583874  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.583881  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.583952  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.583907  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.583843  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.583879  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.583860  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.583787  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.583861  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.583863  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.583901  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.583751  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.583755  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.583829  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.583816  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.583871  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.583866  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.583943  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.583952  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.583926  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.583884  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.583904  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.583857  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.583802  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.583817  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.583814  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.583746  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.583769  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.583734  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.583656  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.583688  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.583746  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.583791  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.583751  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.583749  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.583790  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.583780  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.583735  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.583661  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.583635  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.583642  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.583556  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.583560  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.583509  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.583533  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.583521  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.583590  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.583398  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.583417  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.583446  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.583526  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.583412  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.583412  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.583445  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.583444  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.583525  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.583480  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.583475  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.583514  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.583424  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.583429  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.583480  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.583467  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.583486  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.583531  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.583579  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.583630  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.583645  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.583627  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.583572  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.583566  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.583520  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.583454  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.583497  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.583583  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.583561  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.583519  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.583493  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.583504  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.583576  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.583631  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.583689  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.583661  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.583689  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.583656  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.583639  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.583582  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.583644  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.583689  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.583639  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.583601  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.583639  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.583615  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.583596  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.583601  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.583585  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.583591  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.583579  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.583517  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.583544  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.583490  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.583513  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.583585  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.583581  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.583606  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.583654  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.583629  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.583601  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.583612  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.583576  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.583542  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.583549  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.583471  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.583501  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.583537  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.583524  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.583479  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.583491  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.583518  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.583524  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.583547  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.583521  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.583474  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.583415  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.583364  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.583308  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.583325  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.583307  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.583220  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.583246  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.583230  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.583171  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.583203  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.583207  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.583143  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.583090  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.583125  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.583137  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.583162  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.583164  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.583176  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.583175  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.583207  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.583171  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.583158  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.583150  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.583142  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.583042  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582998  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.582976  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.583012  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.583029  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.583057  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.583093  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.583083  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.583119  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.583106  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.583085  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.583030  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.582954  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.582943  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.582938  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.582965  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.583002  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.583013  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.583042  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.583036  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.583032  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.583009  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.583028  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.583027  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.583007  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.583024  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.583036  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.583052  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.583056  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.583045  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.583007  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.583032  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.582985  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.582955  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.582950  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.582980  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.582992  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.582997  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.582956  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.583026  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.583056  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.583055  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.583084  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.583044  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.583018  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.582954  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.582942  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.582925  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.582924  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.582935  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.582907  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.582840  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.582823  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.582872  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.582916  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.582942  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.582982  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.583015  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.583019  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.583037  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.583041  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.583072  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.583084  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.583055  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.583061  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.583070  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.583099  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.583105  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.583134  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.583190  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.583217  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.583203  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.583208  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.583214  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.583166  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.583152  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.583191  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.583205  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.583166  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.583180  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.583207  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.583234  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.583219  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.583245  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.583244  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.583260  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.583260  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.583280  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.583304  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.583318  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.583314  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.583292  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.583302  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.583282  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.583317  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.583324  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.583347  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.583329  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.583349  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.583398  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.583407  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.583387  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.583419  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.583460  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.583426  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.583487  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.583517  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.583533  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.583563  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.583541  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.583530  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.583510  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.583546  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.583551  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.583564  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.583597  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.583630  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.583667  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.583652  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.583627  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.583594  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.583582  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.583563  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.583554  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.583577  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.583589  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.583551  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.583565  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.583564  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.583586  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.583579  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.583589  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.583655  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.583664  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.583722  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.583778  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.583745  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.583755  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.583730  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.583688  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.583667  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.583653  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.583675  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.583684  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.583720  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.583748  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.583804  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.583846  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.583839  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.583842  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.583848  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.583816  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.583845  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.583833  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.583852  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.583864  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.583857  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.583862  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.583897  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.583896  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.583915  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.583902  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.583908  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.583887  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.583865  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.583844  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.583860  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.583835  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.583869  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.583863  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.583852  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.583843  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.583886  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.583824  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.583841  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.583858  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.583848  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.583788  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.583826  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.583864  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.583859  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.583866  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.583841  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.583827  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.583814  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.583817  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.583814  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.583798  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.583791  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.583737  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.583732  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.583730  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.583703  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.583698  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.583717  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.583730  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.583746  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.583737  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.583767  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.583737  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.583737  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.583753  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.583760  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.583731  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.583723  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.583759  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.583758  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.583775  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.582306\n",
      "@eval_loop_avg_loss=0.580169\n",
      "Epoch 15/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.563145  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.580972  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.574438  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.579367  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.579036  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.579027  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.578505  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.577549  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.579452  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.579454  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.580514  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.580579  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.581226  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.580909  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.583281  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.583199  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.581654  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.581829  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.582916  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.584303  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.584665  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.584705  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.585475  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.584535  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.584628  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.584403  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.584332  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.584937  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.584603  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.585197  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.585095  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.585377  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.585650  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.585340  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.585032  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.584707  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.584442  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.584463  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.584316  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.583923  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.583835  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.583937  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.584436  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.584585  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.585083  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.584094  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.583967  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.583470  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.583689  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.583571  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.583230  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.582975  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.582659  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.582248  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.582049  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.582085  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.582096  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.582072  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.582073  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.582412  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.582553  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.583101  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.583129  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.583252  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.583577  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.583585  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.583548  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.583745  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.583933  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.583947  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.584167  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.584358  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.584151  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.584202  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.584533  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.584611  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.584993  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.585041  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.585285  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.584931  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.585270  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.585003  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.585008  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.584842  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.585153  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.585169  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.585026  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.584846  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.584559  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.584510  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.584132  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.584153  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.583944  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.583991  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.584098  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.584094  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.583893  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.583633  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.583821  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.583810  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.583811  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.583780  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.583730  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.583586  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.583563  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.583569  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.583825  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.583895  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.583725  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.583638  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.583433  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.583603  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.583433  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.583209  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.583559  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.583625  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.583698  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.583773  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.583720  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.583726  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.583535  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.583555  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.583513  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.583327  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.583443  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.583345  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.583340  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.583403  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.583451  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.583477  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.583471  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.583535  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.583472  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.583336  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.583394  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.583494  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.583584  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.583605  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.583916  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.583868  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.583919  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.583955  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.583809  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.583741  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.583602  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.583654  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.583754  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.583843  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.583812  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.583782  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.583845  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.583864  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.583760  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.583787  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.583867  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.583855  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.583831  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.584015  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.584050  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.584138  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.584059  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.583908  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.583790  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.583719  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.583562  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.583560  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.583482  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.583646  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.583623  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.583786  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.583876  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.584094  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.584170  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.584216  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.584280  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.584232  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.584305  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.584230  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.584327  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.584536  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.584579  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.584606  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.584495  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.584636  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.584516  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.584439  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.584593  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.584607  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.584725  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.584713  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.584737  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.584774  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.584789  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.584715  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.584628  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.584582  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.584484  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.584480  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.584437  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.584537  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.584565  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.584477  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.584515  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.584616  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.584603  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.584572  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.584560  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.584575  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.584564  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.584560  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.584553  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.584536  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.584600  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.584648  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.584660  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.584537  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.584487  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.584553  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.584520  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.584430  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.584510  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.584538  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.584489  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.584471  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.584561  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.584583  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.584560  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.584565  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.584534  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.584443  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.584426  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.584451  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.584391  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.584375  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.584361  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.584375  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.584364  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.584269  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.584266  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.584231  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.584232  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.584138  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.584156  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.584205  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.584196  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.584147  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.584153  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.584181  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.584253  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.584253  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.584277  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.584294  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.584261  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.584173  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.584135  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.584067  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.584111  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.584118  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.584176  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.584146  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.584112  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.584141  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.584120  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.584186  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.584190  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.584173  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.584125  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.584115  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.584074  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.584057  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.584025  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.584011  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.583955  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.583920  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.583888  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.583919  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.583881  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.583798  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.583761  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.583676  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.583624  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.583551  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.583559  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.583553  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.583624  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.583634  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.583706  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.583704  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.583729  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.583739  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.583742  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.583762  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.583778  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.583818  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.583888  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.583901  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.583848  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.583768  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.583739  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.583766  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.583786  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.583737  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.583728  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.583780  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.583697  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.583728  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.583713  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.583662  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.583605  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.583557  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.583496  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.583463  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.583563  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.583541  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.583535  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.583555  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.583520  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.583467  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.583590  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.583504  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.583559  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.583611  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.583691  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.583749  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.583739  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.583713  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.583707  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.583740  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.583650  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.583646  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.583641  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.583614  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.583599  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.583554  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.583561  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.583525  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.583550  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.583560  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.583560  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.583589  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.583590  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.583615  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.583611  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.583579  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.583578  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.583645  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.583623  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.583598  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.583631  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.583718  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.583812  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.583780  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.583820  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.583820  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.583838  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.583839  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.583820  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.583864  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.583871  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.583882  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.583790  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.583830  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.583790  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.583812  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.583811  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.583829  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.583850  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.583795  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.583751  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.583733  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.583713  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.583733  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.583806  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.583858  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.583877  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.583866  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.583819  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.583873  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.583796  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.583807  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.583729  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.583698  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.583715  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.583696  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.583692  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.583758  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.583777  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.583765  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.583712  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.583701  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.583648  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.583581  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.583582  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.583546  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.583544  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.583567  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.583580  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.583548  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.583595  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.583617  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.583611  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.583622  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.583678  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.583669  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.583689  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.583718  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.583645  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.583669  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.583606  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.583643  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.583646  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.583674  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.583663  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.583686  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.583703  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.583698  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.583660  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.583687  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.583693  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.583692  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.583720  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.583734  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.583750  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.583794  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.583775  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.583781  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.583850  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.583889  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.583926  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.583929  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.583954  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.583922  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.583917  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.583890  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.583866  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.583897  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.583871  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.583912  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.583858  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.583779  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.583768  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.583737  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.583804  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.583803  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.583780  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.583764  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.583709  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.583678  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.583693  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.583697  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.583656  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.583661  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.583671  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.583678  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.583642  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.583617  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.583597  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.583567  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.583578  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.583584  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.583525  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.583567  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.583546  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.583576  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.583599  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.583566  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.583612  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.583652  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.583634  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.583622  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.583589  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.583617  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.583644  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.583622  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.583658  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.583618  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.583661  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.583654  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.583668  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.583654  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.583618  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.583606  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.583601  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.583584  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.583527  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.583474  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.583474  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.583475  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.583493  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.583506  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.583436  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.583392  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.583366  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.583374  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.583401  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.583430  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.583394  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.583393  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.583422  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.583464  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.583495  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.583553  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.583588  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.583589  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.583568  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.583549  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.583522  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.583491  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.583482  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.583462  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.583419  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.583387  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.583287  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.583323  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.583315  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.583290  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.583253  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.583313  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.583321  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.583362  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.583382  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.583379  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.583353  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.583362  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.583347  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.583320  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.583319  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.583301  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.583313  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.583316  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.583275  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.583291  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.583316  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.583260  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.583248  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.583234  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.583157  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.583135  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.583140  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.583186  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.583214  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.583205  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.583169  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.583146  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.583200  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.583197  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.583232  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.583237  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.583254  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.583272  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.583275  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.583251  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.583258  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.583278  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.583299  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.583321  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.583285  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.583308  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.583357  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.583365  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.583371  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.583370  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.583364  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.583358  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.583379  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.583373  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.583367  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.583421  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.583419  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.583411  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.583416  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.583370  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.583343  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.583307  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.583303  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.583282  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.583299  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.583273  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.583259  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.583267  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.583306  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.583334  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.583329  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.583342  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.583327  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.583358  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.583356  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.583348  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.583422  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.583455  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.583442  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.583430  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.583475  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.583498  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.583533  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.583511  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.583540  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.583495  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.583515  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.583511  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.582099\n",
      "@eval_loop_avg_loss=0.579996\n",
      "Epoch 16/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.567783  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.574594  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.576238  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.578492  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.579947  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.581940  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.580846  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.582997  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.582904  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.585470  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.584299  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.585875  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.585338  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.586039  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.585378  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.586501  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.585671  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.584656  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.585582  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.585975  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.585674  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.585476  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.584522  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.584454  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.584153  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.584110  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.584620  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.584204  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.584165  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.584326  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.584770  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.584350  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.583864  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.583959  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.583963  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.583223  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.583865  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.583356  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.583214  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.583155  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.583697  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.583663  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.583599  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.583785  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.583834  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.583685  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.583424  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.583126  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.582965  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.582878  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.582555  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.582607  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.582492  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.582400  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.582732  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.582674  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.582542  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.582851  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.583071  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.583217  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.582916  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.583175  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.583126  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.583330  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.583065  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.583117  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.583398  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.583500  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.583023  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.583005  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.582706  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.582815  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.582551  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.582470  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.582547  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.582796  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.582467  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.582548  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.582763  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.582809  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.582867  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.582898  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.582901  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.583047  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.582913  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.583012  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.582990  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.582949  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.582709  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.582875  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.583065  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.582872  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.582871  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.582858  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.583117  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.582879  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.582509  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.582608  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.582715  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.582808  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.583042  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.582895  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.582790  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.582863  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.582760  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.582898  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.583041  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.583149  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.582931  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.583224  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.583358  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.583559  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.583703  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.583965  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.584085  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.584176  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.584155  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.583956  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.583834  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.583929  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.583849  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.584013  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.584068  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.584071  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.584132  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.584103  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.584226  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.584273  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.584224  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.584407  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.584632  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.584632  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.584691  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.584578  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.584661  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.584635  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.584653  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.584424  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.584331  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.584243  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.584118  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.584029  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.584016  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.584015  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.583978  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.583936  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.583990  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.583884  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.583883  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.583833  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.583889  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.584008  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.583986  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.583955  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.584062  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.583945  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.583979  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.584025  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.584164  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.584045  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.584101  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.584096  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.584139  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.583849  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.583828  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.583783  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.583844  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.583815  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.583895  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.583873  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.583906  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.583771  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.583755  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.583728  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.583681  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.583597  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.583690  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.583823  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.583781  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.583688  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.583783  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.583752  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.583823  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.583925  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.583918  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.583989  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.583869  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.583876  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.583872  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.583851  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.583813  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.583997  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.583971  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.583861  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.583935  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.583947  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.583921  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.583939  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.583958  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.583838  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.583889  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.583888  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.583893  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.583954  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.583976  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.583843  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.583942  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.583881  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.583904  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.583892  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.583913  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.584005  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.584024  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.583975  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.584070  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.584100  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.584115  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.584165  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.584218  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.584205  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.584085  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.584042  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.584022  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.584039  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.584083  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.584040  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.584020  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.584061  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.584035  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.584092  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.584122  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.584131  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.584137  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.584168  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.584139  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.584222  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.584350  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.584273  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.584248  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.584171  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.584162  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.584118  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.584103  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.584081  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.584039  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.584008  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.584037  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.584066  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.584190  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.584183  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.584183  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.584073  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.584068  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.584052  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.584074  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.584132  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.584178  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.584117  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.584031  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.584084  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.584124  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.584079  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.584034  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.584027  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.583957  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.583981  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.583917  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.583918  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.583890  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.583933  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.583948  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.584000  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.583952  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.584010  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.583961  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.583992  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.583992  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.584020  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.584014  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.584010  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.583982  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.584013  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.584083  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.584042  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.584056  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.584123  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.584113  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.584090  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.584056  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.584100  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.584055  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.583992  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.583937  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.583970  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.583910  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.583972  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.584004  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.583992  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.583981  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.583968  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.584010  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.584044  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.584109  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.584122  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.584126  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.584142  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.584042  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.584021  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.583964  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.583871  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.583830  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.583841  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.583824  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.583811  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.583743  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.583671  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.583633  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.583665  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.583676  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.583623  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.583566  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.583533  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.583521  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.583469  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.583389  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.583431  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.583502  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.583464  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.583457  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.583399  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.583435  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.583500  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.583556  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.583649  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.583607  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.583616  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.583696  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.583686  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.583750  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.583763  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.583692  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.583669  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.583644  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.583644  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.583643  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.583628  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.583610  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.583656  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.583638  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.583579  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.583611  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.583651  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.583551  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.583577  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.583652  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.583647  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.583668  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.583655  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.583743  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.583731  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.583768  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.583674  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.583594  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.583599  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.583574  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.583584  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.583538  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.583534  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.583486  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.583487  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.583472  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.583483  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.583481  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.583525  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.583579  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.583519  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.583535  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.583479  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.583455  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.583399  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.583381  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.583389  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.583407  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.583439  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.583452  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.583476  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.583516  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.583516  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.583540  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.583536  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.583547  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.583544  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.583580  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.583512  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.583474  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.583450  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.583437  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.583446  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.583444  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.583416  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.583441  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.583449  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.583443  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.583469  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.583434  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.583397  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.583446  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.583403  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.583380  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.583347  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.583319  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.583311  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.583287  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.583249  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.583218  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.583222  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.583268  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.583297  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.583263  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.583255  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.583214  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.583207  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.583268  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.583242  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.583256  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.583257  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.583254  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.583233  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.583222  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.583230  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.583278  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.583233  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.583204  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.583220  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.583187  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.583167  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.583154  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.583164  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.583091  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.583107  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.583121  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.583133  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.583187  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.583203  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.583192  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.583180  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.583191  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.583173  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.583166  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.583156  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.583149  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.583094  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.583122  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.583166  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.583136  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.583117  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.583080  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.583046  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.583038  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.583088  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.583029  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.583021  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.583046  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.583034  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.583000  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.582997  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.582951  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.582945  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.582951  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.582943  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.582994  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.583028  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.583064  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.583009  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.582965  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.583007  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.582981  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.582966  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.583040  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.582962  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.582953  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.582952  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.582911  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.582918  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.582933  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.582946  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.582949  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.582946  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.582947  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.582974  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.583023  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.583065  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.583062  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.583052  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.583032  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.583000  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.582999  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.583042  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.583063  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.583069  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.583104  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.583118  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.583182  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.583212  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.583217  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.583199  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.583217  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.583300  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.583339  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.583337  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.583355  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.583335  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.583315  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.583304  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.583316  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.583308  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.583303  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.583334  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.583289  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.583266  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.583222  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.583224  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.583159  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.583201  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.583185  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.583253  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.583221  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.583268  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.583286  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.583258  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.583302  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.583274  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.583269  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.583248  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.583237  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.583263  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.583250  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.583208  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.583229  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.583314  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.583354  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.583357  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.583366  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.583324  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.583285  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.583304  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.583323  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.583305  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.583293  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.583286  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.583259  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.583256  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.583266  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.583248  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.583205  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.583226  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.583232  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.583240  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.583259  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.583277  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.583269  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.583280  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.583297  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.583331  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.583327  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.583335  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.583331  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.583332  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.583278  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.583283  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.583320  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.583335  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.583320  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.583294  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.583304  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.583315  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.583286  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.583309  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.583306  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.583311  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.583325  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.583327  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.583316  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.583320  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.583316  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.583346  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.583296  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.583300  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.583324  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.583310  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.583323  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.583346  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.583368  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.583392  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.583392  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.583377  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.583371  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.583350  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.583329  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.583333  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581958\n",
      "@eval_loop_avg_loss=0.579860\n",
      "Epoch 17/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.559909  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.566451  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.568491  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.576678  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.583238  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.582499  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.580340  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.577548  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.578728  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.579202  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.578181  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.578668  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.579193  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.578832  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.578817  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.578803  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.578410  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.580036  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.580616  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.579697  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.580230  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.579812  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.579762  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.580192  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.580030  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.580033  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.580083  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.579384  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.579750  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.580236  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.580315  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.581051  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.581312  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.581207  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.581259  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.581042  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.581096  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.580749  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.580622  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.580645  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.580809  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.580910  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.581301  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.581359  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.581432  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.581471  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.581012  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.581066  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.581224  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.581388  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.581087  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.580924  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.580910  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.580633  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.580394  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.580399  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.580542  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.580540  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.580557  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.580431  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.580454  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.580623  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.580823  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.580869  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.581026  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.581310  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.581192  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.581164  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.581275  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.581052  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.581225  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.581507  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.581276  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.581175  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.581387  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.581054  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.580962  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.580883  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.581051  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.580858  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.580794  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.580595  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.580754  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.580470  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.580396  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.580425  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.580297  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.580331  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.580383  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.580404  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.580638  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.580770  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.580949  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.581067  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.580790  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.580775  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.580924  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.580719  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.580816  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.580940  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.580794  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.580898  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.580865  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.580891  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.580831  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.580929  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.581174  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.581239  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.581114  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.581196  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.581276  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.581280  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.581519  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.581813  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.581794  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.581678  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.581954  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.581792  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.581878  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.582121  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.582231  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.582332  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.582249  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.582211  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.582365  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.582554  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.582628  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.582547  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.582484  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.582580  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.582484  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.582337  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.582365  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.582476  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.582427  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.582673  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.582751  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.582677  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.582612  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.582614  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.582573  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.582717  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.582803  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.582637  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.582491  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.582443  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.582335  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.582379  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.582392  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.582425  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.582538  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.582698  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.582800  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.582831  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.582895  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.583116  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.583213  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.583259  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.583300  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.583294  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.583160  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.583213  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.583229  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.583376  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.583278  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.583203  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.583298  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.583293  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.583278  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.583163  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.583183  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.583152  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.582995  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.582996  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.583024  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.583035  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.583034  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.582949  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.582962  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.582906  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.582929  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.583024  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.582991  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.583000  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.583131  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.583217  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.583048  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.583077  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.583110  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.583255  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.583278  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.583436  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.583346  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.583375  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.583408  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.583245  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.583251  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.583392  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.583237  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.583411  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.583420  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.583363  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.583382  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.583272  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.583355  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.583396  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.583539  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.583515  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.583397  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.583387  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.583312  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.583337  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.583320  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.583342  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.583366  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.583429  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.583533  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.583502  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.583622  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.583588  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.583597  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.583659  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.583656  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.583733  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.583619  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.583605  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.583713  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.583721  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.583631  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.583529  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.583385  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.583440  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.583466  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.583491  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.583431  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.583431  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.583516  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.583638  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.583707  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.583692  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.583705  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.583820  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.583763  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.583774  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.583709  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.583708  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.583662  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.583574  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.583584  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.583508  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.583578  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.583665  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.583740  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.583634  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.583664  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.583644  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.583663  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.583569  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.583558  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.583625  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.583640  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.583578  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.583560  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.583547  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.583571  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.583492  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.583573  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.583556  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.583577  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.583651  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.583691  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.583763  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.583795  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.583732  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.583814  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.583871  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.583753  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.583783  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.583795  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.583874  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.584020  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.584038  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.584077  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.584078  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.584010  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.583988  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.584013  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.584043  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.584087  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.583956  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.583956  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.584013  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.583955  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.583902  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.583947  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.583909  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.583880  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.583827  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.583803  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.583760  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.583686  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.583682  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.583617  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.583606  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.583630  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.583703  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.583692  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.583636  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.583709  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.583776  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.583707  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.583698  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.583681  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.583720  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.583721  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.583753  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.583757  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.583703  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.583766  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.583822  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.583791  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.583809  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.583765  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.583836  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.583806  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.583835  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.583785  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.583851  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.583859  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.583900  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.583880  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.583864  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.583879  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.583779  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.583795  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.583807  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.583770  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.583768  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.583705  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.583693  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.583694  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.583667  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.583634  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.583672  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.583586  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.583570  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.583536  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.583471  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.583447  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.583425  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.583408  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.583445  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.583522  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.583523  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.583541  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.583474  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.583530  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.583456  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.583462  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.583457  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.583500  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.583492  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.583514  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.583485  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.583484  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.583504  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.583553  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.583618  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.583576  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.583611  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.583678  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.583700  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.583747  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.583655  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.583647  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.583630  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.583708  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.583653  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.583622  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.583634  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.583582  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.583617  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.583597  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.583516  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.583533  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.583603  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.583577  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.583525  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.583508  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.583459  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.583402  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.583444  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.583419  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.583431  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.583471  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.583473  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.583409  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.583457  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.583442  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.583461  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.583437  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.583391  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.583417  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.583401  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.583390  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.583379  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.583413  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.583465  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.583448  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.583358  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.583438  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.583387  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.583358  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.583451  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.583464  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.583382  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.583438  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.583494  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.583479  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.583420  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.583450  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.583420  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.583486  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.583479  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.583434  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.583442  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.583464  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.583467  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.583529  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.583523  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.583542  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.583546  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.583503  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.583523  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.583578  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.583604  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.583605  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.583632  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.583645  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.583680  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.583653  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.583670  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.583720  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.583719  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.583720  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.583649  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.583621  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.583648  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.583590  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.583636  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.583675  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.583674  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.583700  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.583682  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.583687  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.583691  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.583692  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.583725  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.583685  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.583642  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.583659  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.583661  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.583619  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.583623  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.583616  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.583649  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.583614  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.583619  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.583604  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.583594  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.583541  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.583585  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.583598  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.583635  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.583541  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.583507  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.583454  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.583443  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.583449  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.583397  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.583389  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.583435  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.583451  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.583440  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.583438  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.583415  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.583456  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.583486  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.583481  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.583494  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.583433  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.583396  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.583391  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.583394  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.583407  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.583395  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.583426  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.583410  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.583439  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.583415  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.583421  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.583467  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.583454  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.583498  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.583503  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.583508  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.583520  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.583525  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.583521  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.583515  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.583505  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.583539  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.583554  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.583577  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.583561  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.583527  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.583494  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.583498  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.583490  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.583496  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.583510  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.583487  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.583451  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.583398  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.583408  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.583432  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.583431  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.583449  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.583438  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.583453  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.583433  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.583450  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.583440  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.583442  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.583427  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.583440  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.583423  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.583420  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.583410  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.583441  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.583491  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.583572  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.583532  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.583524  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.583545  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.583579  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.583644  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.583616  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.583648  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.583658  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.583657  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.583640  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.583608  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.583564  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.583588  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.583597  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.583574  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.583529  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.583495  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.583508  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.583522  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.583542  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.583562  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.583549  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.583521  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.583538  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.583524  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.583546  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.583506  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.583488  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.583499  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.583482  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.583434  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.583433  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.583431  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.583416  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.583369  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.583359  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.583307  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.583330  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.583310  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.583341  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.583350  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.583340  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.583342  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.583330  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.583315  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.583314  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.583317  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.583329  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.583300  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.583284  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.583210  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.583192  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.583177  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.583136  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.583109  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.583099  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.583153  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.583172  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581769\n",
      "@eval_loop_avg_loss=0.579685\n",
      "Epoch 18/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.564875  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.572321  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.576852  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.573303  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.574717  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.574659  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.573244  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.573240  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.574668  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.575644  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.576691  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.579653  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.579892  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.580933  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.580312  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.579628  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.580477  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.580668  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.582776  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.583606  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.583103  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.582217  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.583132  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.583900  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.583250  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.582181  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.582906  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.583583  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.583815  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.584508  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.584501  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.584456  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.584764  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.584463  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.585068  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.584561  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.584872  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.584882  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.584789  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.584616  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.584144  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.584701  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.584450  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.584535  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.584729  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.584688  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.584771  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.584634  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.584303  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.584461  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.584549  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.584470  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.584245  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.583866  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.584034  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.583695  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.583718  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.583289  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.583081  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.583031  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.583465  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.583984  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.583905  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.584061  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.583882  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.583810  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.583632  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.583844  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.583675  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.583805  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.583902  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.583780  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.583801  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.583861  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.583990  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.584264  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.584170  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.584545  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.584669  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.584546  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.584303  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.584174  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.584141  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.584439  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.584361  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.584382  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.584371  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.584132  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.584422  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.584114  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.584187  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.584356  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.584183  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.584410  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.584169  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.584270  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.584269  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.584389  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.584161  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.583736  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.583716  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.583724  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.583608  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.583490  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.583466  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.583492  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.583695  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.583640  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.583932  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.584076  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.584035  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.584091  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.583914  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.583923  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.583994  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.583815  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.583684  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.583912  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.583819  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.583878  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.583842  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.583858  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.583955  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.583843  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.583713  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.583780  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.583656  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.583680  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.583525  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.583487  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.583643  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.583719  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.584023  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.584006  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.584103  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.584137  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.584258  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.584233  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.584340  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.584380  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.584442  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.584473  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.584448  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.584354  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.584476  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.584452  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.584307  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.584253  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.584231  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.584221  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.584106  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.584175  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.584006  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.583886  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.584006  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.583876  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.583858  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.584169  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.584192  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.584223  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.584264  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.584281  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.584201  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.584142  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.584083  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.584242  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.584357  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.584338  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.584381  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.584397  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.584340  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.584231  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.584269  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.584223  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.584113  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.584045  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.584061  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.583980  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.584028  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.584104  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.584014  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.584078  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.584011  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.584059  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.584208  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.584244  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.584171  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.584227  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.584188  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.584232  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.584229  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.583925  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.583709  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.583601  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.583563  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.583627  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.583556  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.583466  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.583410  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.583546  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.583635  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.583627  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.583656  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.583686  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.583716  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.583800  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.583792  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.583805  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.583874  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.583887  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.583749  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.583726  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.583700  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.583547  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.583513  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.583466  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.583331  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.583289  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.583378  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.583440  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.583578  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.583520  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.583494  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.583345  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.583197  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.583114  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.583092  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.583093  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.583007  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.583001  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.582989  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.583005  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.583021  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.583140  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.583109  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.583176  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.583106  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.583088  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.583118  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.583146  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.583147  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.583208  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.583130  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.583233  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.583206  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.583170  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.583164  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.583121  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.583051  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.583078  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.582969  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.583008  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.583144  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.583041  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.583010  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.583081  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.583040  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.583079  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.583159  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.583173  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.583113  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.583090  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.583160  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.583152  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.583185  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.583246  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.583225  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.583184  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.583104  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.583053  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.583145  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.583047  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.583071  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.582975  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.582973  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.583011  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.583118  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.583141  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.583004  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.582996  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.582943  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.582887  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.582947  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.582892  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.582946  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.582883  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.582873  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.582864  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.582843  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.582855  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.582829  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.582895  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.582866  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.582878  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.582842  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.582790  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.582748  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.582740  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.582761  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.582819  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.582819  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.582792  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.582753  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.582819  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.582817  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.582808  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.582782  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.582759  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.582827  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.582874  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.582849  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.582738  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.582718  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.582752  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.582807  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.582812  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.582864  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.582851  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.582840  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.582873  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.582862  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.582892  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.582896  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.582967  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.582946  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.582960  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.582973  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.582997  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.582994  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.583107  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.583129  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.583063  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.583080  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.583063  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.583116  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.583126  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.583153  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.583145  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.583130  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.583126  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.583106  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.583043  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.583021  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.582958  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.582941  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.582922  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.582978  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.582987  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.583045  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.583085  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.583064  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.582979  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.583007  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.583002  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.583028  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.583017  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.582981  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.582959  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.582942  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.582950  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.582995  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.582969  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.582956  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.582975  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.582974  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.582954  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.583011  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.582976  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.582971  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.582972  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.582986  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.582972  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.582938  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.582947  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.582991  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.582926  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.582946  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.583011  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.582960  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.582941  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.582900  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.582924  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.582985  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.583020  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.582941  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.582915  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.582884  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.582883  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.582950  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.582918  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.582936  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.582902  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.582893  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582892  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.582898  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.582900  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.582927  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.582861  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.582872  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.582881  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.582956  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.582980  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.582925  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.582938  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.582921  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.582979  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.583017  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.583030  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.582913  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.582978  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.582984  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.583030  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.583075  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.583128  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.583104  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.583132  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.583202  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.583182  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.583156  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.583142  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.583210  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.583234  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.583187  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.583194  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.583167  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.583199  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.583231  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.583179  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.583164  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.583199  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.583192  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.583174  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.583171  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.583168  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.583191  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.583127  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.583195  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.583202  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.583160  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.583195  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.583166  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.583176  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.583199  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.583212  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.583181  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.583173  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.583144  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.583141  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.583206  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.583266  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.583268  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.583256  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.583253  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.583240  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.583293  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.583268  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.583246  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.583292  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.583272  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.583326  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.583362  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.583398  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.583389  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.583335  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.583406  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.583376  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.583386  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.583330  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.583328  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.583370  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.583356  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.583380  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.583382  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.583396  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.583423  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.583463  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.583418  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.583444  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.583457  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.583466  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.583427  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.583387  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.583329  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.583300  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.583309  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.583272  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.583292  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.583263  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.583273  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.583255  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.583224  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.583193  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.583259  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.583277  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.583279  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.583273  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.583288  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.583275  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.583238  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.583222  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.583243  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.583246  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.583248  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.583251  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.583242  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.583200  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.583225  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.583213  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.583223  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.583235  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.583246  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.583262  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.583277  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.583257  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.583234  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.583202  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.583227  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.583248  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.583231  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.583238  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.583208  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.583164  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.583189  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.583159  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.583175  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.583146  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.583133  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.583119  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.583120  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.583116  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.583122  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.583095  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.583127  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.583067  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.583091  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.583036  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.583009  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.582984  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.583026  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.583056  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.583077  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.583100  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.583067  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.583093  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.583150  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.583143  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.583141  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.583177  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.583201  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.583262  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.583235  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.583272  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.583265  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.583260  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.583263  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.583264  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.583304  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.583318  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.583322  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.583350  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.583358  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.583362  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.583372  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.583370  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.583360  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.583374  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.583303  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.583270  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.583246  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.583256  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.583272  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.583230  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.583219  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.583218  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.583227  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.583239  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.583239  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.583227  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.583260  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.583233  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.583201  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.583223  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.583245  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.583282  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.583234  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.583196  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.583189  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.583163  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.583157  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.583172  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.583159  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.583135  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.583131  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.583114  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.583131  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.583091  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.583049  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.583026  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.582994  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.583031  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581597\n",
      "@eval_loop_avg_loss=0.579530\n",
      "Epoch 19/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.606212  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.593469  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.591448  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.591879  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.588190  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.585314  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.585960  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.581791  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.583479  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.583225  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.583392  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.585278  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.585037  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.585127  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.586161  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.584825  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.585149  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.584853  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.583580  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.584439  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.583484  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.583415  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.582983  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.583989  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.585069  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.585901  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.586141  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.586470  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.586697  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.585630  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.585400  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.584659  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.584186  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.584404  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.583391  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.582492  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.583182  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.582773  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.583110  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.583229  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.583565  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.583283  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.583383  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.583566  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.583712  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.584199  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.583871  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.584308  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.584648  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.584224  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.584581  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.584655  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.584896  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.585051  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.584660  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.584666  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.584588  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.584200  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.584557  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.584474  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.584927  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.585090  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.585127  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.584566  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.584695  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.584792  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.584671  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.584434  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.584357  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.584190  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.583903  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.584073  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.584063  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.584173  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.584348  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.584516  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.584521  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.584490  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.584219  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.584143  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.584336  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.584227  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.584081  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.583949  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.583898  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.583724  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.583724  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.583834  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.584003  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.583777  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.583987  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.583855  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.583800  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.583909  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.583819  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.583709  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.583630  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.583727  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.583934  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.583926  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.583754  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.583545  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.583592  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.583595  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.583788  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.583782  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.583595  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.583544  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.583534  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.583832  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.583946  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.583883  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.583707  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.583504  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.583349  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.583489  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.583416  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.583381  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.583495  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.583505  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.583478  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.583518  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.583324  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.583460  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.583360  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.583356  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.583240  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.583234  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.583177  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.582987  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.583201  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.583066  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.583288  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.583192  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.583098  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.583220  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.583232  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.583080  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.583101  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.582917  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.583032  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.583092  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.583242  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.583365  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.583370  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.583318  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.583352  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.583359  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.583348  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.583138  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.583179  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.583119  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.583164  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.582999  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.582961  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.582833  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.582702  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.582557  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.582486  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.582600  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.582650  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.582701  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.582575  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.582676  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.582595  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.582665  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.582695  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.582600  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.582564  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.582381  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.582352  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.582322  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.582343  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.582308  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.582351  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.582434  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.582481  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.582468  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.582501  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.582593  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.582591  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.582612  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.582709  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.582693  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.582598  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.582573  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.582494  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.582408  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.582487  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.582472  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.582579  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.582458  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.582316  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.582265  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.582239  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.582236  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.582311  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.582348  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.582265  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.582194  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.582180  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.582228  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.582174  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.582015  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.582025  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.582070  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.582130  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.582181  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.582164  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.582078  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.582129  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.582214  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.582248  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.582329  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.582350  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.582308  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.582385  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.582374  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.582338  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.582272  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.582384  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.582380  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.582406  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.582439  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.582495  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.582424  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.582483  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.582457  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.582577  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.582709  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.582712  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.582701  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.582679  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.582724  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.582672  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.582733  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.582792  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.582737  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.582601  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.582642  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.582701  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.582603  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.582548  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.582602  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.582640  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.582625  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.582724  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.582743  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.582848  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.582872  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.582837  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.582871  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.582912  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.582829  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.582767  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.582817  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.582831  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.582788  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.582860  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.582812  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.582745  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.582771  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.582686  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.582648  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.582744  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.582732  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.582734  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.582744  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.582734  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.582774  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.582685  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.582715  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.582650  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.582649  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.582632  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.582702  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.582636  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.582646  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.582611  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.582539  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.582594  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.582583  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.582571  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.582558  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.582529  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.582559  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.582515  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.582505  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.582522  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.582524  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.582536  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.582669  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.582680  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.582673  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.582703  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.582713  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.582688  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.582714  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.582788  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.582835  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.582855  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.582850  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.582865  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.582874  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.582906  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.582952  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.582906  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.582886  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.582922  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.582932  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.582920  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.582898  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.582910  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.582962  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.582959  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.582983  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.582992  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.582870  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.582871  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.582818  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.582809  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.582784  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.582703  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.582761  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.582689  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.582686  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.582678  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.582681  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.582725  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.582687  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.582707  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.582697  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.582707  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.582777  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.582761  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.582697  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.582673  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.582615  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.582619  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.582617  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.582658  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.582672  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.582658  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.582689  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.582696  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.582734  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.582678  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.582760  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.582806  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.582783  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.582757  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.582658  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.582623  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.582528  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.582461  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.582513  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.582556  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.582641  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.582613  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.582657  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.582677  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.582693  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.582698  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.582620  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.582645  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.582663  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.582723  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.582714  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.582697  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.582726  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.582742  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.582692  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.582661  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.582648  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.582648  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.582636  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.582602  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.582587  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.582622  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.582597  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.582593  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.582633  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.582679  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.582689  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.582650  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.582612  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.582631  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.582652  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.582615  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.582547  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.582485  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.582504  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.582557  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582597  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.582563  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.582503  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.582508  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.582509  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.582513  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.582484  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.582460  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.582479  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.582477  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.582489  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.582406  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.582370  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.582354  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.582368  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.582383  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.582372  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.582325  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.582304  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.582291  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.582286  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.582235  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.582247  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.582245  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.582251  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.582265  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.582225  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.582291  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.582321  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.582354  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.582336  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.582323  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.582300  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.582300  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.582302  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.582320  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.582310  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.582337  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.582266  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.582296  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.582362  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.582368  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.582372  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.582404  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.582389  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.582388  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.582415  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.582433  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.582452  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.582486  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.582531  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.582455  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.582502  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.582548  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.582636  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.582607  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.582618  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.582637  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.582642  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.582709  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.582757  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.582783  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.582766  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.582807  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.582743  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.582750  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.582721  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.582708  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.582672  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.582651  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.582635  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.582678  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.582639  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.582596  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.582614  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.582577  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.582604  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.582546  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.582511  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.582521  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.582538  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.582547  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.582524  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.582524  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.582443  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.582414  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.582444  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.582459  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.582512  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.582507  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.582538  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.582517  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.582551  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.582492  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.582501  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.582507  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.582489  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.582465  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.582463  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.582464  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.582411  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.582417  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.582407  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.582420  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.582423  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.582480  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.582456  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.582464  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.582458  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.582466  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.582479  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.582512  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.582507  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.582499  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.582483  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.582450  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.582457  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.582499  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.582510  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.582524  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.582585  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.582620  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.582607  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.582608  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.582596  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.582580  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.582573  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.582624  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.582619  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.582593  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.582611  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.582578  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.582622  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.582598  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.582635  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.582662  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.582636  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.582636  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.582622  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.582591  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.582580  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.582552  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.582535  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.582548  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.582527  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.582521  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.582555  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.582585  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.582591  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.582609  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.582644  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.582635  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.582661  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.582641  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.582635  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.582671  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.582677  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.582662  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.582685  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.582695  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.582712  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.582708  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.582695  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.582744  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.582744  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.582735  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.582763  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.582716  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.582744  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.582726  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.582740  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.582755  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.582798  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.582806  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.582790  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.582774  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.582733  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.582770  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.582750  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.582773  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.582819  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.582862  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.582828  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.582788  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.582782  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.582806  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.582853  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.582865  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.582845  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.582876  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.582891  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.582840  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.582837  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.582879  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.582847  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.582851  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.582827  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.582858  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.582891  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.582873  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.582926  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.582889  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.582877  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.582880  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.582894  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.582907  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.582929  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581587\n",
      "@eval_loop_avg_loss=0.579529\n",
      "Epoch 20/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.584775  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.583423  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.579360  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.582357  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.581811  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.579898  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.577405  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.577434  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.578395  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.579683  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.581025  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.582175  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.584586  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.584097  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.583572  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.584869  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.585637  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.585175  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.584078  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.584466  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.583402  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.583926  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.582949  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.583018  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.582389  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.582483  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.582483  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.582807  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.582621  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.582355  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.582585  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.583390  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.583469  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.583171  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.583352  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.583026  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.583707  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.584523  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.584536  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.585105  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.584941  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.584536  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.584973  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.584838  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.584428  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.584481  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.583956  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.583308  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.583255  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.583510  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.583648  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.583310  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.583673  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.584406  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.584334  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.584197  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.584479  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.584286  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.584431  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.584699  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.584749  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.584614  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.584486  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.584442  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.584533  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.584729  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.584675  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.584467  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.584649  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.584872  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.584996  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.584826  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.585177  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.585048  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.584865  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.584852  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.584848  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.584764  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.584673  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.584455  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.584597  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.584588  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.584740  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.584889  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.584843  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.584745  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.585032  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.585345  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.585416  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.585579  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.585359  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.585179  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.585098  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.585357  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.585435  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.585668  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.585666  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.585809  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.585742  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.585597  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.585690  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.585588  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.585705  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.585766  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.585687  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.585584  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.585479  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.585276  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.584960  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.585194  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.585047  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.585147  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.584954  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.584968  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.584953  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.584920  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.584873  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.584780  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.584869  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.584818  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.585088  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.585265  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.585224  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.585332  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.585272  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.585495  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.585488  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.585542  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.585549  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.585493  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.585295  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.585141  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.585036  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.585136  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.585170  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.585108  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.585153  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.585076  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.585015  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.584995  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.584996  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.584917  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.584860  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.584785  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.584825  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.584943  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.585100  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.584991  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.585089  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.585030  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.585027  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.585081  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.585065  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.585177  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.585028  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.585089  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.585059  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.584955  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.585217  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.585391  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.585364  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.585381  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.585348  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.585209  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.585064  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.584934  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.584874  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.584966  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.585122  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.585005  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.584867  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.584845  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.584847  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.584942  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.584808  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.584707  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.584689  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.584689  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.584736  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.584698  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.584733  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.584723  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.584833  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.584842  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.584854  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.584699  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.584750  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.584674  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.584593  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.584644  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.584655  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.584583  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.584588  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.584482  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.584525  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.584625  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.584660  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.584690  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.584649  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.584723  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.584794  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.584733  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.584707  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.584652  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.584548  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.584584  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.584536  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.584567  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.584602  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.584472  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.584369  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.584292  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.584272  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.584237  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.584299  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.584307  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.584275  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.584273  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.584356  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.584278  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.584217  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.584247  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.584312  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.584335  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.584279  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.584322  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.584331  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.584259  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.584361  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.584363  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.584413  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.584424  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.584444  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.584445  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.584487  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.584475  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.584462  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.584498  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.584576  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.584544  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.584526  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.584516  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.584556  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.584558  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.584503  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.584501  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.584386  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.584328  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.584342  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.584367  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.584396  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.584383  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.584365  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.584270  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.584331  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.584384  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.584314  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.584262  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.584221  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.584273  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.584322  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.584237  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.584263  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.584328  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.584286  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.584219  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.584160  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.584094  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.584065  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.584014  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.584046  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.584140  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.584086  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.584195  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.584203  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.584191  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.584235  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.584234  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.584285  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.584275  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.584222  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.584158  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.584135  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.584093  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.584211  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.584175  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.584032  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.584035  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.584058  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.584096  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.584158  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.584177  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.584126  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.584171  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.584129  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.584173  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.584251  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.584284  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.584261  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.584265  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.584330  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.584330  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.584287  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.584209  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.584179  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.584134  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.584101  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.584038  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.583958  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.583973  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.583988  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.583983  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.584011  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.584036  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.584013  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.584058  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.584112  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.584154  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.584117  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.584150  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.584153  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.584183  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.584197  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.584269  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.584308  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.584320  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.584292  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.584326  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.584313  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.584238  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.584264  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.584309  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.584288  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.584226  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.584227  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.584242  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.584307  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.584267  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.584288  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.584225  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.584178  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.584165  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.584146  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.584221  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.584171  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.584104  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.584115  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.584092  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.584095  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.584139  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.584124  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.584174  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.584191  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.584198  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.584262  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.584264  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.584248  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.584245  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.584277  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.584291  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.584323  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.584251  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.584246  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.584194  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.584164  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.584129  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.584111  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.584118  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.584128  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.584225  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.584172  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.584189  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.584171  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.584162  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.584137  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.584118  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.584158  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.584119  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.584169  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.584149  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.584197  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.584227  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.584182  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.584115  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.584104  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.584036  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.584081  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.583999  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.584010  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.584035  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.583997  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.583947  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.583951  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.583961  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.584004  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.583922  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.583956  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.583990  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.583984  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.583944  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.583932  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.583899  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.583944  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.583967  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.583922  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.583941  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.583930  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.583863  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.583908  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.583877  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.583881  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.583880  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.583836  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.583810  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.583763  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.583764  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.583765  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.583768  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.583798  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.583756  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.583783  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.583800  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.583848  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.583827  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.583832  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.583788  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.583797  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.583821  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.583786  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.583725  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.583769  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.583724  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.583697  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.583683  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.583682  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.583663  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.583660  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.583663  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.583635  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.583605  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.583600  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.583628  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.583613  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.583572  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.583571  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.583551  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.583578  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.583554  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.583576  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.583595  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.583607  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.583545  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.583584  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.583564  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.583551  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.583599  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.583535  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.583603  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.583559  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.583515  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.583507  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.583499  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.583457  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.583389  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.583391  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.583403  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.583368  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.583342  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.583346  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.583269  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.583262  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.583239  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.583218  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.583190  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.583171  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.583089  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.583121  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.583114  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.583115  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.583109  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.583045  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.583038  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.583056  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.583101  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.583042  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.583013  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.582991  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.583043  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.583025  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.583008  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.582973  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.582932  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.582980  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.582974  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.583028  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.582996  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.582996  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.583053  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.583096  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.583053  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.583028  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.583027  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.583046  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.583058  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.583105  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.583096  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.583082  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.583107  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.583067  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.583042  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.583032  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.583040  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.583036  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.583037  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.583058  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.583063  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.583050  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.583084  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.583079  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.583041  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.583026  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.583002  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.583015  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.583013  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.583014  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.583017  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.583020  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.583047  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.583024  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.582990  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.582969  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.582977  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.583042  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.583035  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.583036  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.583018  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.582977  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.582965  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.582949  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.582941  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.582901  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.582919  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.582913  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.582882  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.582916  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.582905  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.582914  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.582924  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.582948  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.582977  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.582974  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.582977  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.583017  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.583032  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.583021  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.582984  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.582985  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.582961  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.582935  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.582907  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.582951  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.582955  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.582916  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.582926  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.582903  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.582869  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.582850  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.582864  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.582854  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.582832  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.582794  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.582825  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.582841  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.582793  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.582811  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.582800  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.582841  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.582881  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.582917  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.582908  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.582915  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.582904  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.582908  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.582876  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.582856  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.582861  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.582876  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.582863  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.582854  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.582855  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.582870  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.582862  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.582875  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.582870  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.582876  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.582873  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.582877  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.582890  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.582862  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.582830  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581509\n",
      "@eval_loop_avg_loss=0.579466\n",
      "Epoch 21/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.562614  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.577598  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.577004  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.572601  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.577259  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.576588  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.576258  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.575039  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.577413  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.577304  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.581137  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.579386  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.579898  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.580137  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.579923  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.578621  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.579819  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.580228  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.580642  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.582208  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.583070  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.583975  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.583824  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.584083  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.584878  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.584734  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.584611  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.585013  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.585997  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.586121  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.586064  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.586455  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.586826  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.587160  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.587052  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.587248  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.587016  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.586060  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.585615  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.585001  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.584374  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.584666  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.583724  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.583784  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.583769  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.584007  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.584504  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.584343  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.583602  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.583232  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.583298  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.583231  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.582991  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.583236  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.583555  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.583431  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.583298  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.583583  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.583701  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.583965  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.583662  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.583719  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.583656  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.583651  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.583907  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.583655  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.583209  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.583286  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.583308  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.583345  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.583353  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.583214  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.583048  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.583198  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.583463  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.583524  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.583623  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.583608  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.583905  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.584155  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.584563  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.584207  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.584274  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.584280  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.583879  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.583824  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.584206  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.584312  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.584382  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.584495  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.584624  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.584643  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.584595  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.584707  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.584541  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.584575  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.584438  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.584289  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.584168  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.584050  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.584237  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.583960  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.583669  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.583846  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.583852  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.583978  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.583943  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.584192  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.584132  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.584338  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.584141  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.584191  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.584034  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.584331  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.584116  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.584032  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.583974  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.583919  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.583943  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.583755  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.583598  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.583705  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.583552  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.583669  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.583663  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.583520  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.583549  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.583569  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.583470  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.583432  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.583215  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.583130  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.583110  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.583077  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.583158  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.583041  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.583067  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.583025  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.582985  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.582880  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.582880  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.582885  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.582821  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.582741  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.582684  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.582801  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.582956  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.583040  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.583069  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.583046  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.583127  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.583267  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.583258  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.583249  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.583235  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.583144  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.583183  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.583226  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.583281  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.583076  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.582936  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.582889  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.582874  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.582815  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.582869  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.582833  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.582832  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.582788  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.582833  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.582801  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.582935  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.582905  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.583043  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.583017  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.583146  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.582999  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.583056  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.583068  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.583153  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.583239  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.583314  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.583423  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.583385  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.583355  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.583200  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.583052  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.583136  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.583140  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.583195  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.583119  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.583086  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.583104  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.583024  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.583037  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.583006  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.582954  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.582879  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.582743  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.582705  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.582619  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.582642  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.582624  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.582747  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.582958  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.583013  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.582989  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.583048  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.583043  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.583104  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.583172  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.583213  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.583218  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.583048  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.583028  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.582994  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.582999  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.583262  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.583274  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.583261  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.583337  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.583217  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.583175  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.583323  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.583321  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.583330  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.583241  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.583260  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.583151  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.583092  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.583068  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.583015  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.583007  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.582944  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.582957  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.582999  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.583015  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.583030  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.582981  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.582883  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.582884  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.582841  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.582698  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.582760  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.582743  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.582789  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.582807  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.582849  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.582847  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.582906  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.582846  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.582913  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.582747  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.582762  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.582651  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.582611  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.582535  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.582535  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.582531  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.582523  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.582526  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.582612  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.582603  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.582544  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.582473  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.582436  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.582390  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.582420  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.582234  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.582235  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.582182  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.582198  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.582192  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.582303  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.582282  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.582321  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.582354  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.582391  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.582404  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.582365  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.582397  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.582342  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.582300  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.582202  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.582237  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.582245  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.582189  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.582214  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.582260  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.582270  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.582286  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.582258  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.582196  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.582285  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.582264  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.582265  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.582306  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.582262  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.582301  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.582312  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.582298  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.582293  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.582302  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.582277  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.582339  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.582387  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.582339  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.582367  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.582354  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.582325  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.582340  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.582374  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.582403  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.582418  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.582442  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.582470  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.582469  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.582449  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.582469  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.582458  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.582453  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.582446  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.582382  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.582402  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.582360  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.582367  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.582379  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.582326  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.582335  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.582238  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.582312  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.582274  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.582303  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.582303  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.582411  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.582392  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.582441  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.582437  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.582433  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.582403  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.582382  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.582404  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.582394  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.582368  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.582379  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.582438  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.582444  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.582458  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.582386  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.582432  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.582453  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.582387  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.582350  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.582331  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.582279  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.582271  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.582284  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.582284  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.582304  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.582276  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.582322  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.582378  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.582314  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.582288  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.582342  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.582347  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.582395  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.582433  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.582467  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.582402  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.582381  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.582409  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.582411  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.582502  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.582460  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.582390  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.582387  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.582414  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.582434  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.582492  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.582456  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.582454  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.582431  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.582390  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.582384  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.582320  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.582305  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.582295  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.582313  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.582355  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.582324  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.582265  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.582248  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.582279  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582278  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.582239  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.582191  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.582151  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.582154  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.582151  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.582168  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.582223  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.582250  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.582212  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.582227  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.582280  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.582285  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.582260  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.582268  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.582265  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.582224  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.582224  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.582169  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.582186  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.582154  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.582102  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.582128  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.582125  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.582054  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.582072  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.582034  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.582021  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.581959  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.581970  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.582041  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.582070  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.582077  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.582068  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.582054  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.582042  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.582062  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.582082  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.582107  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.582115  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.582162  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.582191  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.582186  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.582226  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.582224  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.582187  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.582141  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.582159  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.582146  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.582169  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.582221  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.582174  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.582195  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.582161  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.582183  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.582143  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.582117  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.582055  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.582048  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.582096  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.582072  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.582091  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.582116  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.582117  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.582122  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.582191  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.582209  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.582245  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.582194  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.582162  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.582182  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.582218  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.582272  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.582289  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.582264  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.582265  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.582244  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.582291  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.582374  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.582378  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.582407  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.582412  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.582413  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.582377  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.582379  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.582356  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.582325  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.582375  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.582377  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.582455  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.582461  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.582439  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.582437  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.582446  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.582428  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.582429  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.582481  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.582521  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.582545  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.582558  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.582615  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.582587  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.582573  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.582514  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.582525  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.582514  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.582559  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.582558  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.582611  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.582608  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.582591  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.582581  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.582570  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.582574  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.582553  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.582540  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.582589  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.582636  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.582628  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.582625  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.582629  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.582612  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.582622  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.582607  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.582606  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.582594  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.582594  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.582596  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.582589  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.582631  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.582637  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.582621  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.582615  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.582607  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.582610  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.582620  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.582606  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.582650  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.582633  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.582621  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.582629  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.582609  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.582589  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.582594  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.582588  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.582630  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.582632  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.582603  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.582582  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.582588  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.582633  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.582591  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.582578  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.582580  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.582547  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.582556  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.582528  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.582545  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.582540  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.582503  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.582479  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.582498  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.582442  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.582422  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.582455  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.582468  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.582515  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.582564  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.582559  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.582554  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.582562  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.582559  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.582531  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.582531  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.582559  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.582554  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.582552  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.582540  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.582537  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.582538  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.582537  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.582516  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.582510  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.582491  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.582481  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.582487  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.582509  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.582533  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.582555  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.582588  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.582636  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.582643  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.582646  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.582663  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.582713  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.582732  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.582737  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.582731  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.582760  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.582806  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.582816  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.582822  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.582808  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.582797  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.582766  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.582752  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.582736  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581331\n",
      "@eval_loop_avg_loss=0.579293\n",
      "Epoch 22/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.574473  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.580254  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.573167  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.568964  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.569753  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.571739  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.575710  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.571633  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.572561  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.571884  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.570556  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.571012  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.572086  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.572722  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.572883  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.573738  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.573962  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.574800  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.575449  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.575778  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.575344  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.576703  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.576929  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.578357  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.577620  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.577568  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.577323  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.577677  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.578207  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.578606  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.578657  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.578376  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.578710  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.578913  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.578138  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.578705  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.578209  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.577533  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.577354  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.577443  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.578052  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.577934  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.578129  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.578530  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.578489  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.578473  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.578410  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.578334  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.578305  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.578926  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.579098  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.579292  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.579122  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.578624  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.578457  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.578818  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.578870  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.578854  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.579071  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.578835  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.578806  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.579025  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.578710  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.578720  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.579015  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.579463  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.579444  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.579437  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.579402  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.579443  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.579626  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.580095  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.580338  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.580371  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.580307  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.580662  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.580864  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.580921  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.580681  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.580558  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.580626  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.580687  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.580750  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.580661  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.580717  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.580841  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.581218  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.581166  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.581504  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.581281  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.581390  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.581326  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.581641  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.581916  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.581988  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.581870  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.581806  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.581894  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.581967  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.581970  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.582116  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.581895  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.582145  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.582057  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.582237  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.582253  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.582184  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.582199  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.582162  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.581930  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.581823  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.581675  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.581563  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.581747  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.581671  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.581580  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.581547  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.581589  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.581365  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.581281  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.581334  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.581419  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.581452  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.581309  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.581373  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.581259  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.581322  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.581306  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.581306  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.581157  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.581089  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.581041  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.581066  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.581164  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.581207  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.581185  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.581197  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.581129  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.581211  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.581224  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.581242  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.581245  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.581264  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.581334  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.581454  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.581493  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.581496  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.581562  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.581345  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.581409  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.581488  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.581608  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.581605  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.581705  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.581821  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.581812  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.581721  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.581798  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.581777  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.581751  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.581584  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.581605  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.581575  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.581619  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.581620  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.581511  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.581476  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.581507  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.581486  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.581525  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.581465  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.581455  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.581167  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.581142  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.581009  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.581070  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.581184  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.581233  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.581273  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.581205  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.581144  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.581195  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.581164  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.581213  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.581276  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.581203  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.581160  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.581284  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.581216  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.581294  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.581233  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.581315  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.581252  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.581114  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.581067  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.581077  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.581100  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.581079  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.581155  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.581080  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.581070  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.581072  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.581044  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.581039  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.581097  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.581103  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.581111  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.581117  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.581147  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.581133  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.581110  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.581084  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.581057  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.581145  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.581177  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.581195  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.581118  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.581151  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.581094  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.581064  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.581062  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.581100  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.581121  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.581102  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.581181  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.581249  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.581253  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.581179  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.581309  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.581310  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.581425  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.581418  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.581505  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.581468  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.581548  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.581583  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.581591  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.581545  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.581396  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.581348  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.581404  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.581484  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.581581  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.581564  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.581634  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.581575  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.581568  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.581501  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.581526  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.581480  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.581507  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.581557  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.581573  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.581685  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.581623  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.581694  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.581739  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.581615  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.581693  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.581716  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.581799  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.581722  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.581789  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.581854  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.581893  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.581820  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.581820  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.581810  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.581892  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.581860  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.581811  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.581816  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.581794  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.581778  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.581695  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.581686  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.581720  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.581714  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.581722  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.581734  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.581726  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.581761  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.581780  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.581758  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.581694  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.581663  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.581679  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.581725  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.581728  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.581723  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.581732  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.581710  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.581800  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.581871  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.581817  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.581914  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.581919  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.581907  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.581877  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.581937  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.581957  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.582012  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.581920  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.581946  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.581937  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.581930  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.581969  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.582024  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.582012  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.582003  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.582018  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.581960  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.581941  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.581986  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.582043  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.582009  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.581991  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.582063  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.582027  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.582060  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.582154  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.582206  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.582190  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.582209  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.582187  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.582164  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.582165  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.582217  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.582264  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.582241  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.582297  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.582230  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.582218  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.582212  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.582234  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.582137  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.582161  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.582152  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.582154  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.582200  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.582145  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.582111  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.582060  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.582051  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.582054  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.582000  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.581991  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.581987  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.581971  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.581919  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.581959  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.582035  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.582123  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.582082  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.582115  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.582098  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.582141  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.582113  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.582047  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.582041  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.582052  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.582041  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.581989  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.582019  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.582039  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.582036  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.582019  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.581979  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.581996  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.581974  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.582042  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.582082  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.582065  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.582039  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.582131  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.582111  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.582111  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.582133  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.582142  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.582128  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.582118  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.582089  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.582054  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.582085  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.582093  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.582061  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.582124  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.582161  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.582183  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.582219  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.582246  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.582257  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.582301  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582218  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.582186  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.582205  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.582182  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.582176  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.582127  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.582102  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.582130  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.582158  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.582199  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.582251  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.582301  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.582281  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.582254  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.582268  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.582299  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.582299  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.582286  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.582296  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.582284  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.582235  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.582195  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.582238  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.582170  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.582204  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.582230  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.582227  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.582252  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.582225  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.582267  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.582237  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.582221  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.582234  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.582250  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.582273  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.582343  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.582309  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.582254  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.582322  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.582254  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.582225  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.582186  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.582175  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.582148  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.582177  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.582193  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.582236  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.582255  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.582222  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.582227  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.582224  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.582232  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.582284  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.582271  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.582234  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.582220  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.582266  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.582212  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.582174  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.582214  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.582190  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.582251  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.582265  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.582289  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.582335  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.582365  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.582366  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.582377  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.582378  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.582344  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.582325  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.582345  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.582368  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.582391  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.582408  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.582357  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.582333  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.582384  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.582423  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.582425  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.582443  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.582421  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.582415  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.582462  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.582454  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.582383  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.582432  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.582382  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.582408  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.582422  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.582368  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.582316  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.582346  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.582325  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.582326  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.582299  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.582322  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.582364  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.582365  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.582332  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.582335  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.582334  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.582315  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.582291  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.582224  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.582243  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.582267  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.582287  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.582300  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.582269  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.582260  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.582238  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.582210  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.582184  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.582188  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.582214  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.582242  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.582237  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.582276  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.582302  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.582296  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.582311  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.582275  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.582270  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.582317  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.582298  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.582335  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.582375  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.582378  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.582391  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.582387  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.582359  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.582363  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.582358  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.582354  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.582345  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.582335  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.582380  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.582381  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.582364  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.582374  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.582364  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.582401  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.582387  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.582414  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.582433  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.582425  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.582462  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.582497  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.582511  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.582569  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.582566  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.582571  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.582642  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.582629  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.582635  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.582669  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.582593  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.582588  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.582597  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.582587  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.582592  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.582644  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.582638  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.582665  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.582656  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.582659  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.582643  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.582645  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.582629  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.582653  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.582657  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.582679  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.582681  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.582711  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.582660  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.582669  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.582643  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.582640  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.582601  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.582565  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.582599  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.582601  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.582567  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.582580  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.582560  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.582534  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.582508  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.582492  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.582530  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.582485  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.582487  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.582488  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.582510  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.582503  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.582468  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.582458  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.582526  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.582544  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.582548  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.582552  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.582524  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.582539  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.582568  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.582544  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.582545  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.582584  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.581152\n",
      "@eval_loop_avg_loss=0.579129\n",
      "Epoch 23/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.572260  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.576209  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.581474  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.578300  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.578985  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.576657  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.579415  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.580631  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.580636  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.580022  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.582537  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.581504  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.581473  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.580787  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.581018  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.580844  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.581303  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.581379  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.580727  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.580780  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.580975  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.581491  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.582082  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.581158  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.581205  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.581188  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.581639  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.582511  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.582576  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.582747  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.582670  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.583087  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.582207  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.581747  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.581037  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.580535  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.581597  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.582094  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.581626  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.581649  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.581176  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.580904  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.581222  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.580955  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.580679  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.580876  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.581488  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.581239  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.581432  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.581123  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.580602  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.580716  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.580684  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.580732  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.580823  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.581004  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.580930  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.580653  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.580782  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.581012  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.580919  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.581122  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.581049  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.580781  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.581078  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.580826  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.581178  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.581424  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.581543  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.581639  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.581207  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.581384  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.581257  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.581173  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.581084  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.581018  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.580775  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.580885  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.581497  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.581255  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.581168  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.581144  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.581197  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.581186  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.581199  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.581378  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.581265  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.581105  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.581024  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.581200  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.580988  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.580921  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.581144  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.581119  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.581116  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.581277  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.581293  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.581485  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.581462  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.581561  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.581463  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.581474  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.581505  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.581257  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.581368  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.581299  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.581371  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.581512  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.581444  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.581474  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.581612  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.581556  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.581653  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.581566  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.581584  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.581501  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.581661  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.581824  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.581920  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.581986  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.581797  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.581745  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.581739  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.581767  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.581811  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.581800  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.581685  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.581703  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.581744  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.581742  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.581790  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.581828  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.581905  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.581972  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.582069  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.582324  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.582474  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.582540  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.582422  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.582358  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.582358  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.582258  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.582334  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.582325  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.582399  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.582348  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.582362  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.582233  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.582273  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.582253  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.582377  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.582110  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.582416  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.582372  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.582260  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.582338  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.582419  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.582396  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.582239  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.582271  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.582186  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.582146  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.581875  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.582074  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.582027  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.581960  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.581903  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.581741  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.582025  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.582092  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.582156  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.582073  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.582075  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.582137  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.582133  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.582192  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.582224  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.582271  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.582214  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.582134  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.582037  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.581998  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.581938  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.582017  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.582092  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.582284  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.582213  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.582047  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.581968  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.581959  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.581962  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.582019  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.582122  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.582138  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.582176  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.582241  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.582249  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.582191  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.582213  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.582208  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.582247  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.582191  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.582099  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.582122  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.581986  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.582040  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.582009  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.581889  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.581868  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.581812  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.581864  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.581824  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.581803  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.581878  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.581859  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.581920  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.581974  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.582012  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.582023  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.581969  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.581917  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.581976  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.581900  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.581839  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.581737  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.581788  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.581777  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.581814  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.581840  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.581813  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.581781  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.581723  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.581620  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.581625  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.581538  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.581488  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.581555  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.581667  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.581789  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.581786  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.581778  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.581755  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.581832  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.581828  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.581828  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.581974  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.582000  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.581964  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.582054  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.582112  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.582070  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.582019  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.581977  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.581948  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.582002  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.581992  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.582024  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.582009  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.581957  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.581986  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.582073  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.582074  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.582084  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.582116  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.582122  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.582192  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.582239  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.582292  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.582223  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.582143  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.582191  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.582161  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.582135  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.582122  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.582189  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.582205  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.582238  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.582268  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.582246  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.582179  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.582171  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.582207  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.582197  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.582241  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.582259  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.582195  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.582117  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.582152  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.582155  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.582146  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.582208  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.582160  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.582077  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.582076  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.582095  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.582127  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.582184  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.582226  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.582193  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.582144  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.582176  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.582152  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.582169  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.582066  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.582167  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.582145  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.582086  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.582126  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.582093  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.582083  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.582055  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.582081  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.582083  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.582054  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.582022  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.582041  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.582085  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.582036  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.582065  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.582122  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.582191  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.582181  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.582124  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.582084  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.582037  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.582062  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.582049  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.582035  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.582025  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.582095  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.582102  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.582045  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.582026  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.582102  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.582138  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.582155  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.582128  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.582107  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.582118  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.582066  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.582059  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.582143  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.582140  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.582135  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.582121  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.582181  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.582217  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.582132  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.582144  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.582169  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.582252  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.582242  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.582205  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.582161  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.582166  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.582131  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.582124  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.582190  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.582239  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.582315  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.582318  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.582310  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.582360  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.582373  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.582342  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.582295  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.582339  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.582381  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.582359  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.582382  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.582398  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.582361  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.582351  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.582390  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.582386  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.582341  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.582379  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.582341  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.582322  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.582323  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.582258  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.582273  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.582232  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.582195  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.582218  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.582196  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.582149  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.582106  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.582058  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.582065  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.582029  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.582007  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.581991  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582012  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.581983  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.582014  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.582015  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.582055  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.582144  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.582176  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.582194  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.582219  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.582211  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.582160  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.582150  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.582154  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.582146  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.582146  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.582199  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.582202  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.582224  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.582195  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.582212  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.582165  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.582157  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.582203  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.582200  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.582267  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.582274  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.582316  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.582299  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.582295  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.582272  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.582237  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.582250  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.582251  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.582317  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.582252  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.582209  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.582224  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.582162  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.582210  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.582246  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.582268  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.582256  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.582209  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.582211  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.582243  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.582262  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.582278  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.582292  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.582239  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.582261  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.582168  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.582163  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.582137  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.582137  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.582151  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.582201  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.582245  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.582213  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.582186  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.582226  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.582255  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.582263  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.582276  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.582286  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.582290  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.582264  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.582302  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.582321  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.582311  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.582332  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.582392  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.582368  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.582329  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.582327  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.582271  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.582272  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.582234  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.582252  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.582274  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.582275  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.582287  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.582293  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.582252  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.582228  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.582198  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.582184  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.582202  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.582229  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.582299  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.582333  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.582354  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.582352  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.582353  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.582353  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.582375  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.582417  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.582429  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.582475  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.582490  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.582477  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.582422  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.582421  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.582398  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.582420  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.582430  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.582455  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.582476  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.582434  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.582429  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.582436  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.582432  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.582469  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.582466  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.582444  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.582419  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.582426  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.582380  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.582386  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.582381  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.582425  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.582402  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.582414  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.582423  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.582454  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.582475  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.582469  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.582422  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.582412  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.582387  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.582395  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.582414  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.582408  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.582430  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.582377  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.582367  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.582329  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.582303  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.582320  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.582335  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.582333  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.582313  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.582364  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.582355  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.582367  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.582370  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.582381  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.582376  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.582377  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.582370  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.582347  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.582350  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.582316  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.582346  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.582360  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.582319  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.582283  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.582263  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.582300  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.582320  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.582282  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.582283  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.582257  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.582238  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.582231  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.582255  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.582215  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.582173  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.582176  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.582212  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.582248  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.582249  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.582268  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.582199  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.582188  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.582195  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.582202  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.582231  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.582239  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.582307  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.582328  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.582324  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.582306  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.582286  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.582322  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.582328  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.582307  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.582240  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.582277  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.582284  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.582315  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.582298  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.582342  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.582341  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.582345  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.582341  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.582327  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.582304  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.582282  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.582270  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.582305  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.582308  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.582326  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.582328  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.582312  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.582315  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.582333  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.582394  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580996\n",
      "@eval_loop_avg_loss=0.578969\n",
      "Epoch 24/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.623784  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.600729  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.601186  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.592235  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.588399  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.588158  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.586222  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.587503  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.588337  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.587110  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.587464  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.586935  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.586644  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.587204  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.585428  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.585186  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.584926  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.583571  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.583465  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.584154  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.584529  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.584727  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.585027  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.585197  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.585534  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.585321  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.585166  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.585686  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.585402  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.585064  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.584362  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.584339  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.584026  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.583840  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.583567  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.583116  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.582758  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.583427  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.583910  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.584222  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.583768  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.583991  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.583727  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.583480  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.584000  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.584202  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.584312  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.584797  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.584777  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.584471  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.584122  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.584504  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.584693  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.585105  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.585212  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.585104  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.585844  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.585829  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.585753  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.585422  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.585753  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.585414  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.585181  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.585165  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.585369  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.585586  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.585467  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.585472  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.585494  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.585604  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.585515  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.585791  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.585707  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.585621  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.585400  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.585160  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.585072  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.585151  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.585207  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.585254  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.585314  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.585397  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.585582  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.585369  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.585513  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.585470  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.585606  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.585306  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.585352  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.585253  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.585045  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.585130  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.585031  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.584774  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.584694  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.584580  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.584643  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.584502  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.584615  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.584555  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.584737  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.584777  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.584581  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.584455  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.584486  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.584235  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.584146  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.584330  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.584110  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.584200  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.584100  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.584026  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.584212  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.584359  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.584258  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.584242  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.584157  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.584040  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.583816  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.583768  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.583643  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.583569  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.583690  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.583704  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.583689  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.583870  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.583845  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.583792  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.583751  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.583687  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.583575  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.583608  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.583746  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.583599  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.583580  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.583564  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.583501  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.583437  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.583546  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.583353  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.583361  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.583426  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.583477  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.583413  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.583515  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.583709  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.583534  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.583517  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.583427  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.583422  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.583446  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.583262  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.583401  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.583696  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.583893  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.583827  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.583773  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.583721  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.583681  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.583793  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.583902  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.583982  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.583844  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.583774  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.584013  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.583991  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.583961  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.583994  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.583928  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.583789  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.583643  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.583629  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.583750  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.583756  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.583739  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.583710  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.583735  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.583723  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.583838  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.583951  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.583891  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.583831  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.583789  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.583703  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.583704  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.583721  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.583790  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.583867  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.583956  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.583872  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.583911  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.583816  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.583917  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.583885  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.583955  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.583971  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.583956  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.583838  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.583881  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.583854  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.583771  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.583835  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.583798  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.583737  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.583797  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.583746  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.583739  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.583701  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.583704  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.583688  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.583705  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.583686  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.583705  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.583721  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.583615  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.583598  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.583640  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.583568  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.583457  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.583488  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.583465  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.583621  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.583549  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.583512  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.583462  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.583496  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.583526  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.583424  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.583396  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.583302  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.583431  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.583439  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.583456  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.583469  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.583449  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.583432  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.583339  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.583261  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.583163  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.583173  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.583187  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.583128  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.583212  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.583270  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.583226  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.583246  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.583199  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.583154  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.583166  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.583063  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.583059  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.583048  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.582984  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.583102  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.583071  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.583058  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.583115  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.583095  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.583063  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.583106  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.583024  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.583054  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.583086  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.583128  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.583090  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.583119  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.582979  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.583026  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.583039  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.583024  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.583001  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.582879  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.582890  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.582835  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.582867  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.582827  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.582854  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.582805  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.582685  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.582644  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.582666  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.582646  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.582566  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.582582  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.582595  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.582669  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.582609  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.582639  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.582681  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.582673  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.582549  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.582629  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.582607  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.582547  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.582604  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.582609  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.582574  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.582558  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.582497  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.582461  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.582406  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.582397  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.582403  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.582357  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.582275  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.582267  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.582283  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.582296  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.582302  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.582268  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.582381  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.582281  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.582302  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.582308  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.582325  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.582384  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.582393  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.582438  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.582562  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.582491  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.582441  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.582404  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.582359  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.582401  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.582407  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.582413  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.582448  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.582437  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.582437  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.582382  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.582377  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.582345  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.582387  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.582455  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.582460  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.582477  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.582535  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.582574  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.582581  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.582542  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.582632  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.582570  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.582572  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.582516  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.582527  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.582561  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.582546  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.582557  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.582598  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.582605  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.582591  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.582557  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.582531  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.582579  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.582653  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.582648  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.582628  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.582663  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.582604  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.582550  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.582489  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.582478  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.582508  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.582457  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.582454  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.582419  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.582399  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.582456  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.582408  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.582358  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.582424  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.582352  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.582383  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.582381  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.582433  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.582422  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.582359  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.582375  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.582379  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.582392  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.582412  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.582434  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.582435  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.582399  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.582408  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.582359  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.582336  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.582374  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.582373  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.582370  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.582315  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.582333  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.582261  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582222  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.582245  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.582282  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.582318  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.582332  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.582328  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.582262  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.582309  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.582291  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.582332  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.582315  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.582253  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.582218  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.582211  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.582226  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.582258  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.582191  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.582202  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.582228  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.582273  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.582268  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.582272  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.582235  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.582288  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.582322  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.582290  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.582334  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.582330  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.582381  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.582398  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.582383  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.582384  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.582322  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.582346  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.582341  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.582343  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.582334  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.582365  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.582349  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.582340  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.582309  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.582359  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.582360  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.582415  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.582470  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.582511  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.582431  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.582396  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.582369  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.582399  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.582349  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.582357  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.582350  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.582343  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.582395  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.582420  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.582459  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.582457  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.582497  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.582497  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.582502  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.582507  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.582558  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.582559  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.582541  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.582574  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.582575  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.582582  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.582542  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.582539  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.582549  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.582558  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.582535  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.582561  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.582496  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.582451  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.582434  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.582433  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.582448  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.582458  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.582476  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.582470  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.582451  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.582427  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.582456  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.582415  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.582396  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.582375  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.582403  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.582426  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.582432  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.582420  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.582419  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.582463  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.582446  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.582488  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.582491  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.582487  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.582469  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.582469  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.582492  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.582508  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.582578  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.582602  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.582573  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.582530  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.582495  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.582509  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.582457  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.582435  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.582371  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.582406  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.582402  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.582372  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.582370  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.582381  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.582341  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.582286  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.582301  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.582285  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.582313  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.582300  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.582303  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.582288  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.582338  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.582320  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.582296  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.582302  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.582291  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.582322  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.582341  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.582283  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.582307  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.582358  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.582383  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.582374  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.582330  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.582313  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.582314  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.582326  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.582268  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.582245  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.582253  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.582268  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.582309  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.582286  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.582293  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.582245  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.582269  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.582281  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.582304  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.582315  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.582335  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.582366  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.582311  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.582309  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.582355  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.582361  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.582355  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.582345  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.582372  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.582360  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.582334  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.582331  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.582338  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.582332  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.582338  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.582322  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.582287  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.582296  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.582275  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.582291  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.582291  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.582279  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.582276  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.582313  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.582340  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.582366  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.582349  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.582352  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.582347  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.582370  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.582368  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.582369  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.582391  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.582381  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.582349  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.582363  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.582347  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.582324  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.582330  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.582330  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.582333  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.582332  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.582321  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.582375  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.582349  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.582331  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.582255  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.582248  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.582277  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.582275  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.582289  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.582290  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.582305  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.582313  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.582293  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580955\n",
      "@eval_loop_avg_loss=0.578945\n",
      "Epoch 25/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.566936  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.570584  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.564325  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.560977  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.567134  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.570360  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.570093  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.571057  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.570761  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.572618  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.572190  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.574061  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.575808  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.577503  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.577210  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.576413  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.577245  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.578191  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.578386  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.578321  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.577988  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.577400  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.577669  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.577230  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.577079  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.577791  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.577924  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.578522  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.579510  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.578535  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.578560  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.579154  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.579246  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.578618  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.578253  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.578283  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.578329  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.578955  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.579581  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.579687  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.579858  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.579458  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.579411  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.579625  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.579826  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.580124  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.580588  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.580641  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.580465  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.580567  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.580863  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.581474  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.581492  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.581530  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.581641  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.581333  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.581221  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.581093  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.581150  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.581226  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.581710  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.581732  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.581743  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.581680  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.581787  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.582012  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.581711  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.581717  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.581747  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.581813  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.581580  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.581596  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.581545  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.581607  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.581568  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.581229  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.581067  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.581332  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.581364  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.581422  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.581435  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.581255  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.581133  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.581012  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.581030  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.580994  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.580733  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.580752  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.580723  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.580636  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.580723  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.580386  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.580071  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.580040  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.580055  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.580105  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.579988  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.579802  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.579903  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.579971  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.580108  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.580122  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.580140  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.580127  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.580026  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.580173  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.580197  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.580306  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.580412  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.580397  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.580403  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.580473  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.580564  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.580466  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.580412  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.580494  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.580393  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.580324  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.580185  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.580301  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.580412  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.580698  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.580654  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.580732  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.580716  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.580609  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.580541  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.580337  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.580434  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.580467  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.580526  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.580688  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.580698  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.580771  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.580819  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.581012  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.581008  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.580944  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.580962  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.580863  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.580793  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.580929  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.580849  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.580814  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.580733  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.580599  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.580491  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.580541  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.580603  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.580661  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.580618  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.580513  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.580675  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.580596  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.580526  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.580683  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.580753  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.580761  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.580757  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.580717  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.580514  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.580617  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.580524  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.580678  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.580598  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.580641  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.580553  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.580685  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.580572  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.580661  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.580699  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.580584  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.580699  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.580703  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.580665  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.580697  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.580699  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.580629  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.580562  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.580579  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.580627  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.580553  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.580489  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.580558  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.580355  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.580358  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.580509  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.580506  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.580561  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.580515  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.580522  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.580552  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.580458  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.580492  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.580505  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.580473  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.580548  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.580697  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.580630  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.580584  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.580545  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.580630  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.580674  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.580583  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.580610  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.580579  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.580537  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.580460  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.580417  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.580543  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.580575  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.580591  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.580502  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.580578  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.580640  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.580644  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.580622  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.580663  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.580685  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.580639  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.580651  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.580515  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.580503  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.580524  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.580450  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.580577  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.580722  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.580751  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.580601  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.580597  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.580613  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.580707  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.580766  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.580819  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.580854  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.580832  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.580919  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.580898  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.580970  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.581084  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.581040  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.580932  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.580864  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.580969  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.581000  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.581089  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.581186  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.581171  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.581103  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.581038  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.581068  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.580985  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.581080  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.581102  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.581088  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.581007  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.581020  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.581019  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.581049  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.581082  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.581154  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.581168  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.581193  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.581180  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.581078  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.581018  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.581027  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.581000  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.581008  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.581035  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.581048  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.581004  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.580936  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.580926  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.580820  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.580886  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.580937  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.580856  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.580944  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.580949  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.580974  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.581049  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.580996  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.580967  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.580990  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.580873  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.580908  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.580940  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.580967  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.580964  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.580955  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.581013  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.580981  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.580947  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.581042  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.581040  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.581069  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.581093  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.581074  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.581184  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.581161  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.581161  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.581103  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.581029  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.581089  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.581139  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.581070  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.581061  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.581117  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.581135  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.581164  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.581246  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.581288  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.581283  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.581311  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.581281  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.581349  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.581359  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.581385  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.581384  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.581410  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.581424  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.581364  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.581460  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.581498  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.581490  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.581530  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.581597  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.581622  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.581689  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.581656  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.581621  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.581605  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.581548  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.581617  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.581633  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.581651  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.581707  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.581747  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.581734  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.581764  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.581787  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.581767  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.581767  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.581778  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.581757  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.581791  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.581750  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.581752  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.581835  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.581857  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.581838  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.581895  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.581877  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.581863  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.581821  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.581853  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.581807  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.581809  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.581830  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.581860  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.581887  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.581883  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.581872  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.581892  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.581954  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.581975  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.582002  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.582054  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.582038  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.582088  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.582098  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.582055  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.582029  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.582039  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.582060  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.582088  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.582067  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.582055  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.582071  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.582080  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.582098  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.582095  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.582048  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.582035  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.582063  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.582087  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.582094  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.582101  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.582049  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.582066  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.582078  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.582066  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582025  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.581979  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.581979  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.581948  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.581949  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.581945  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.581920  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.581884  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.581879  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.581947  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.581889  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.581925  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.581911  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.581895  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.581919  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.581889  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.581869  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.581865  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.581813  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.581779  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.581820  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.581812  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.581823  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.581856  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.581853  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.581893  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.581950  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.581988  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.582011  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.582013  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.581988  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.582032  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.582086  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.582089  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.582077  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.582093  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.582119  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.582101  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.582035  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.581992  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.582007  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.582051  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.582022  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.582032  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.582048  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.582068  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.581956  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.581952  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.581971  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.581994  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.581979  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.582001  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.582032  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.582047  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.582039  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.582045  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.582041  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.582039  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.582043  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.582015  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.582009  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.582029  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.582048  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.582096  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.582101  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.582097  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.582081  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.582069  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.582099  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.582061  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.581988  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.581947  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.581960  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.581981  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.581958  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.581992  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.581990  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.582005  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.582000  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.581980  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.581978  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.582052  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.582051  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.581975  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.581978  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.582009  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.582042  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.582043  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.582032  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.582039  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.581992  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.582005  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.581994  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.582019  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.581964  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.581953  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.581961  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.581929  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.581899  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.581898  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.581890  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.581872  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.581907  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.581923  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.581964  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.581973  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.581967  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.581982  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.581975  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.582005  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.582020  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.581980  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.582034  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.582088  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.582123  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.582106  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.582142  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.582159  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.582156  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.582170  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.582165  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.582185  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.582169  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.582187  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.582172  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.582196  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.582209  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.582202  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.582262  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.582270  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.582288  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.582298  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.582266  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.582302  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.582307  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.582305  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.582318  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.582298  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.582300  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.582369  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.582401  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.582414  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.582446  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.582425  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.582414  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.582448  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.582395  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.582446  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.582463  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.582448  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.582442  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.582483  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.582496  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.582487  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.582516  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.582532  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.582505  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.582502  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.582454  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.582476  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.582393  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.582366  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.582351  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.582313  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.582295  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.582252  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.582233  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.582290  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.582321  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.582350  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.582329  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.582322  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.582319  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.582301  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.582300  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.582297  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.582265  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.582293  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.582262  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.582271  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.582252  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.582229  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.582228  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.582230  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.582231  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.582230  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.582228  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.582208  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.582184  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.582223  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.582282  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.582276  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.582258  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.582264  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.582294  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.582251  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.582223  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.582174  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.582174  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.582179  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.582199  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.582197  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.582160  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.582178  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.582176  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.582174  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.582191  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580781\n",
      "@eval_loop_avg_loss=0.578790\n",
      "Epoch 26/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.592368  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.594115  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.586157  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.586890  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.580880  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.582626  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.581459  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.584676  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.586750  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.587226  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.586681  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.587783  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.587523  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.586917  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.586572  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.586692  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.586698  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.585476  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.585613  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.584646  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.583864  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.585148  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.584038  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.584961  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.584675  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.585911  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.586175  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.586943  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.587106  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.586499  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.586268  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.586460  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.586431  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.586249  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.585977  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.586261  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.586155  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.585334  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.585135  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.584977  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.584904  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.584168  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.583953  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.583859  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.583881  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.583681  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.583787  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.583272  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.583205  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.583070  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.583311  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.583333  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.583692  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.583560  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.583893  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.583580  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.583944  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.583946  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.583886  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.583848  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.583599  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.583878  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.583773  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.583675  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.583890  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.584048  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.584275  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.584095  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.584200  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.584123  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.584224  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.584382  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.584361  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.584355  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.584272  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.584461  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.584414  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.584186  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.584215  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.584193  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.584176  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.584118  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.583993  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.584054  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.583954  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.583784  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.583822  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.583925  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.584108  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.584056  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.583970  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.583832  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.583711  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.583668  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.583432  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.583391  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.583551  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.583550  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.583510  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.583475  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.583688  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.583703  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.583693  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.583472  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.583437  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.583589  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.583573  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.583636  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.583572  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.583594  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.583417  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.583242  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.583173  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.583322  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.583331  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.583210  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.583156  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.583195  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.583208  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.583115  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.583189  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.583256  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.583335  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.583345  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.583512  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.583487  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.583354  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.583373  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.583428  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.583358  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.583384  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.583438  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.583469  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.583500  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.583559  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.583471  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.583475  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.583521  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.583293  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.583301  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.583104  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.583065  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.583064  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.583068  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.582918  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.582943  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.583099  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.583124  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.582914  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.582945  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.582902  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.582960  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.582975  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.583164  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.583050  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.582973  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.583169  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.583270  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.583168  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.583172  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.583224  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.583223  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.583068  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.583072  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.583119  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.583133  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.583188  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.583114  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.583111  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.583041  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.583117  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.583158  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.583112  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.583037  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.583131  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.583209  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.583191  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.583182  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.583301  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.583270  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.583205  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.583141  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.583134  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.583181  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.583017  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.583144  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.583237  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.583171  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.583088  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.582969  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.582925  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.582854  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.582782  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.582682  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.582639  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.582599  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.582590  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.582653  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.582738  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.582867  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.582912  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.582879  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.582907  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.582907  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.582849  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.582920  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.582891  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.582857  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.583010  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.583017  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.582984  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.582902  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.582725  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.582655  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.582677  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.582684  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.582773  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.582797  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.582835  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.582872  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.582792  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.582728  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.582654  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.582621  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.582575  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.582512  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.582525  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.582506  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.582458  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.582580  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.582581  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.582603  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.582709  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.582698  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.582724  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.582737  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.582683  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.582778  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.582814  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.582812  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.582735  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.582682  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.582678  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.582692  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.582581  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.582631  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.582590  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.582554  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.582501  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.582578  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.582577  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.582633  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.582647  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.582743  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.582791  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.582759  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.582767  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.582720  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.582686  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.582687  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.582678  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.582685  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.582700  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.582537  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.582595  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.582605  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.582589  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.582578  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.582532  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.582506  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.582597  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.582613  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.582550  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.582463  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.582472  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.582540  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.582526  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.582512  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.582583  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.582540  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.582526  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.582577  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.582515  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.582473  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.582367  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.582430  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.582488  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.582540  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.582499  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.582519  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.582536  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.582542  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.582544  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.582590  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.582660  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.582695  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.582699  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.582758  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.582733  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.582672  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.582708  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.582639  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.582685  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.582680  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.582770  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.582698  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.582604  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.582548  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.582581  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.582595  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.582534  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.582499  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.582473  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.582461  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.582452  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.582429  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.582399  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.582369  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.582385  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.582357  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.582319  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.582286  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.582232  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.582170  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.582134  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.582128  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.582191  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.582194  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.582202  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.582234  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.582343  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.582276  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.582224  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.582254  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.582211  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.582206  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.582237  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.582238  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.582189  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.582167  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.582126  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.582118  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.582116  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.582169  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.582125  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.582195  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.582159  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.582170  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.582176  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.582181  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.582192  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.582153  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.582103  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.582079  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.582179  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.582146  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.582134  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.582155  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.582151  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.582136  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.582140  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.582121  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.582102  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.582182  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.582162  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.582163  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.582202  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.582264  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.582252  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.582268  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.582210  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.582143  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.582199  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.582219  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.582197  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.582110  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.582133  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.582170  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.582216  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.582200  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.582188  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.582243  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.582285  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.582204  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.582200  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.582284  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.582229  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.582229  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.582204  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.582216  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.582152  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.582153  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.582118  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582114  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.582115  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.582131  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.582129  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.582075  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.582053  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.582062  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.581957  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.581940  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.581887  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.581942  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.581972  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.581955  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.581972  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.582030  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.582069  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.582087  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.582095  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.582023  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.582058  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.582044  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.582016  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.582013  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.581976  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.581960  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.581877  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.581842  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.581892  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.581913  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.581908  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.581907  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.581917  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.581960  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.582043  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.582004  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.581995  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.582011  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.582076  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.582041  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.582108  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.582102  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.582127  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.582154  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.582151  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.582158  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.582130  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.582101  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.582111  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.582146  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.582194  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.582154  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.582156  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.582143  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.582152  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.582148  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.582191  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.582175  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.582187  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.582157  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.582146  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.582166  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.582156  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.582220  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.582241  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.582165  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.582158  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.582121  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.582154  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.582155  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.582188  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.582213  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.582193  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.582233  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.582239  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.582237  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.582206  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.582295  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.582324  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.582390  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.582354  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.582401  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.582367  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.582388  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.582311  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.582366  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.582339  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.582334  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.582319  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.582317  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.582303  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.582317  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.582375  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.582378  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.582365  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.582367  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.582335  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.582298  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.582252  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.582246  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.582285  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.582271  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.582299  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.582312  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.582277  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.582255  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.582251  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.582297  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.582281  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.582325  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.582249  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.582299  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.582313  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.582285  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.582283  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.582303  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.582274  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.582277  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.582314  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.582320  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.582344  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.582378  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.582358  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.582357  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.582385  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.582411  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.582433  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.582437  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.582468  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.582408  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.582420  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.582365  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.582388  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.582401  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.582336  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.582277  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.582268  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.582269  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.582247  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.582251  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.582232  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.582238  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.582296  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.582279  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.582275  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.582188  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.582220  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.582244  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.582231  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.582240  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.582306  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.582304  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.582304  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.582304  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.582316  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.582341  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.582313  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.582346  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.582348  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.582339  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.582333  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.582354  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.582340  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.582298  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.582280  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.582283  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.582286  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.582315  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.582321  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.582293  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.582292  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.582248  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.582263  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.582204  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.582196  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.582176  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.582174  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.582177  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.582179  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.582160  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.582150  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.582112  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.582094  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.582100  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.582128  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.582134  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.582088  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.582053  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.582090  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.582064  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.582085  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.582114  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.582080  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.582087  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.582120  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.582137  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.582112  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.582121  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.582113  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.582076  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.582072  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.582108  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.582074  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.582076  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.582108  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.582085  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.582084  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.582081  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580651\n",
      "@eval_loop_avg_loss=0.578666\n",
      "Epoch 27/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.590846  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.591932  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.588901  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.588465  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.593539  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.589873  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.587613  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.591043  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.589503  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.588482  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.588595  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.588141  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.586763  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.586289  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.585451  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.585239  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.584506  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.584447  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.584199  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.584922  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.585280  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.585468  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.585202  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.585515  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.585809  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.586714  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.586605  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.585757  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.585422  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.585277  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.583830  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.584045  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.584312  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.584289  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.583882  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.583861  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.583757  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.583986  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.584404  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.584070  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.584280  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.584276  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.584517  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.584520  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.584625  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.584635  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.584760  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.584315  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.584366  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.584260  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.584450  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.583994  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.583815  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.584287  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.584077  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.584233  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.584038  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.584009  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.584041  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.584347  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.584400  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.584616  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.584398  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.584460  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.584246  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.584397  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.584365  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.584653  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.584955  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.584592  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.584724  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.584672  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.584669  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.584359  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.584387  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.584259  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.584141  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.584341  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.584545  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.584355  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.584507  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.584513  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.584534  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.584576  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.584480  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.583923  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.583972  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.584216  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.584023  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.584179  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.584149  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.584074  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.584342  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.584218  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.584382  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.584359  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.584835  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.584694  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.584452  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.584517  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.584690  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.584537  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.584527  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.584552  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.584298  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.584047  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.584271  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.584228  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.584081  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.584088  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.583982  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.584152  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.584106  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.584072  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.584075  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.584136  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.584315  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.584122  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.583985  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.583994  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.583968  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.583792  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.583832  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.583831  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.583791  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.583559  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.583453  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.583470  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.583149  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.583119  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.583038  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.583063  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.583024  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.583073  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.583031  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.583017  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.582838  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.582780  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.582781  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.582726  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.582782  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.582742  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.582628  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.582731  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.582717  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.582799  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.582584  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.582684  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.582758  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.582941  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.582944  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.582935  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.583082  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.583153  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.583227  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.583136  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.583182  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.583037  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.582916  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.582913  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.582938  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.583035  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.582972  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.582936  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.582917  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.582996  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.583172  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.583121  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.583041  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.583015  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.583006  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.583026  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.583114  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.583141  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.583165  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.583238  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.583413  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.583368  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.583428  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.583376  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.583258  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.583301  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.583252  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.583301  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.583313  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.583342  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.583393  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.583295  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.583172  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.583144  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.583304  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.583321  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.583417  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.583392  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.583297  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.583367  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.583288  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.583407  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.583359  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.583517  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.583447  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.583542  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.583553  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.583611  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.583734  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.583814  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.583768  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.583808  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.583857  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.583935  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.584033  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.583996  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.583999  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.583973  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.583991  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.584024  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.584000  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.584130  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.584146  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.584155  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.584149  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.584026  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.583970  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.583811  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.583796  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.583813  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.583856  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.583782  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.583741  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.583850  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.583825  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.583802  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.583745  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.583647  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.583638  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.583616  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.583686  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.583731  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.583626  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.583647  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.583509  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.583509  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.583596  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.583590  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.583498  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.583481  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.583453  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.583360  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.583355  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.583417  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.583420  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.583443  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.583381  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.583389  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.583334  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.583341  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.583414  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.583404  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.583389  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.583365  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.583399  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.583373  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.583290  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.583250  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.583262  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.583199  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.583183  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.583155  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.583161  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.583008  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.582983  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.582922  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.582874  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.582964  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.582954  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.582967  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.582881  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.582877  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.582940  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.583005  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.582950  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.582907  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.582823  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.582789  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.582790  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.582695  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.582667  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.582710  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.582798  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.582804  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.582808  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.582809  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.582820  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.582825  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.582777  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.582808  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.582757  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.582711  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.582757  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.582703  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.582732  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.582736  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.582710  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.582653  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.582683  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.582693  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.582745  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.582748  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.582734  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.582616  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.582619  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.582576  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.582682  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.582691  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.582689  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.582680  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.582650  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.582595  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.582676  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.582597  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.582620  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.582627  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.582702  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.582731  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.582692  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.582661  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.582639  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.582640  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.582717  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.582725  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.582715  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.582686  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.582684  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.582662  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.582637  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.582607  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.582624  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.582669  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.582681  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.582729  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.582731  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.582718  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.582720  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.582646  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.582630  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.582576  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.582583  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.582621  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.582658  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.582690  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.582668  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.582682  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.582631  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.582669  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.582628  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.582650  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.582603  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.582569  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.582506  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.582499  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.582504  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.582553  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.582576  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.582626  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.582640  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.582563  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.582575  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.582569  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.582613  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.582597  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.582576  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.582583  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.582633  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.582598  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.582615  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.582591  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.582611  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.582691  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.582756  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.582799  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.582764  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.582803  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.582830  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.582858  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.582780  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.582823  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.582849  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.582803  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.582860  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.582938  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.582915  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.582852  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.582844  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582855  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.582856  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.582803  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.582793  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.582802  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.582743  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.582713  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.582760  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.582827  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.582838  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.582847  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.582877  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.582840  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.582902  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.582894  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.582860  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.582858  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.582867  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.582864  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.582874  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.582865  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.582896  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.582890  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.582893  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.582897  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.582863  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.582891  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.582829  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.582826  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.582832  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.582817  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.582767  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.582751  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.582747  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.582703  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.582728  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.582717  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.582678  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.582736  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.582736  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.582751  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.582793  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.582732  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.582699  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.582719  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.582641  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.582703  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.582665  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.582705  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.582721  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.582756  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.582724  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.582675  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.582691  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.582702  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.582644  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.582672  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.582636  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.582633  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.582610  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.582636  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.582659  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.582670  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.582657  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.582587  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.582574  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.582637  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.582589  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.582631  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.582634  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.582632  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.582619  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.582629  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.582604  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.582612  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.582635  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.582666  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.582695  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.582717  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.582753  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.582783  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.582756  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.582720  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.582688  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.582691  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.582672  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.582658  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.582690  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.582681  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.582692  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.582697  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.582701  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.582699  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.582717  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.582705  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.582680  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.582708  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.582708  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.582700  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.582689  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.582706  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.582695  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.582682  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.582683  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.582658  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.582609  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.582635  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.582636  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.582616  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.582621  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.582654  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.582686  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.582669  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.582686  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.582712  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.582663  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.582668  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.582636  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.582641  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.582658  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.582661  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.582610  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.582627  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.582656  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.582709  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.582694  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.582698  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.582705  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.582683  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.582694  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.582655  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.582620  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.582621  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.582676  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.582663  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.582647  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.582673  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.582624  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.582588  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.582570  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.582508  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.582463  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.582448  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.582484  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.582516  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.582538  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.582543  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.582543  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.582544  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.582534  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.582503  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.582500  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.582514  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.582513  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.582532  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.582526  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.582497  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.582466  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.582483  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.582466  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.582442  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.582403  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.582352  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.582336  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.582314  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.582337  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.582341  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.582326  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.582306  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.582332  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.582321  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.582306  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.582285  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.582297  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.582272  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.582271  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.582297  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.582277  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.582258  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.582274  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.582244  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.582203  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.582222  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.582227  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.582216  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.582175  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.582143  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.582135  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.582135  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.582171  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.582167  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.582207  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.582252  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.582220  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.582228  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.582192  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.582126  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.582110  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.582148  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.582122  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.582080  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.582092  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.582069  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.582059  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.582055  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.582018  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.582007  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580666\n",
      "@eval_loop_avg_loss=0.578698\n",
      "Epoch 28/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.560373  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.566231  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.568087  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.565612  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.574601  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.576118  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.580833  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.580781  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.581441  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.580432  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.580685  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.580828  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.580317  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.580695  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.579590  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.580179  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.579391  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.580019  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.580751  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.581904  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.582641  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.582219  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.582027  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.581679  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.581618  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.580674  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.580642  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.580314  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.580475  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.581189  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.581874  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.580476  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.580175  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.579081  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.579334  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.579257  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.579635  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.580406  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.579769  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.579947  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.580819  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.581124  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.581557  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.581444  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.581294  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.581269  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.581561  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.581911  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.581738  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.581330  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.581292  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.581669  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.581362  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.581715  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.581857  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.581646  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.582099  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.581534  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.581709  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.581694  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.582185  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.582389  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.581995  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.581902  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.582029  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.581701  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.581516  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.581858  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.581801  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.581859  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.581743  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.581955  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.582303  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.582214  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.582307  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.582304  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.582269  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.582473  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.582700  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.582534  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.582538  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.582460  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.582395  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.582474  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.582522  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.582485  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.582672  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.582747  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.582746  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.582750  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.582617  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.582474  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.582516  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.582520  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.582610  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.582615  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.582832  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.582770  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.582780  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.582743  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.583105  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.582870  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.582807  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.582833  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.582888  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.582593  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.582641  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.582643  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.582865  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.583007  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.582862  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.582972  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.583093  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.583008  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.583172  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.583106  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.583176  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.583361  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.583230  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.583238  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.583326  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.583303  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.583373  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.583466  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.583366  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.583586  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.583656  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.583528  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.583637  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.583561  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.583362  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.583214  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.583212  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.583383  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.583289  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.583302  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.583253  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.583248  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.583202  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.583326  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.583341  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.583284  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.583441  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.583486  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.583535  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.583543  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.583627  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.583730  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.583671  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.583663  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.583637  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.583678  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.583428  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.583528  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.583651  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.583636  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.583805  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.584009  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.584023  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.584115  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.584116  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.584111  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.584003  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.584061  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.584118  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.584115  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.584074  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.583970  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.583939  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.583815  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.583813  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.583912  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.583877  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.583808  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.583786  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.583847  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.583828  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.583910  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.583876  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.583877  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.583930  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.583884  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.583914  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.583975  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.583920  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.583828  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.583797  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.583777  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.583721  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.583787  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.583836  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.583835  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.583866  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.583792  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.583671  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.583600  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.583671  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.583771  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.583707  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.583710  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.583763  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.583763  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.583810  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.583773  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.583818  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.583796  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.583720  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.583602  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.583577  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.583668  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.583665  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.583546  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.583597  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.583638  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.583641  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.583657  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.583581  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.583632  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.583598  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.583515  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.583547  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.583494  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.583484  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.583470  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.583486  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.583513  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.583522  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.583497  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.583483  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.583295  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.583339  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.583229  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.583252  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.583251  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.583145  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.583074  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.583045  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.583026  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.582975  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.582924  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.582991  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.582964  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.582930  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.582942  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.583031  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.583005  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.583012  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.582987  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.582919  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.582930  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.582946  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.582932  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.583061  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.583011  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.583023  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.583008  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.583084  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.583118  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.583160  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.583295  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.583296  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.583364  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.583368  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.583405  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.583494  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.583442  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.583414  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.583426  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.583300  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.583238  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.583354  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.583379  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.583355  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.583326  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.583345  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.583370  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.583214  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.583180  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.583124  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.583120  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.583133  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.583130  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.583163  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.583134  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.583164  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.583118  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.583023  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.583083  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.583100  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.583020  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.583113  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.583071  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.583053  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.583116  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.583141  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.583106  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.582964  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.582954  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.582990  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.583069  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.583033  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.583007  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.582994  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.582945  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.582986  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.582946  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.582966  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.582948  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.582910  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.582918  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.582903  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.582900  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.582921  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.582845  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.582831  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.582856  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.582853  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.582872  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.582833  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.582815  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.582761  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.582770  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.582734  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.582612  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.582593  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.582600  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.582646  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.582582  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.582525  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.582519  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.582512  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.582497  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.582447  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.582389  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.582488  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.582431  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.582443  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.582443  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.582412  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.582442  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.582429  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.582430  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.582428  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.582471  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.582520  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.582540  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.582569  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.582602  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.582535  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.582508  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.582587  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.582659  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.582630  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.582604  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.582622  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.582675  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.582676  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.582695  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.582666  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.582581  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.582567  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.582593  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.582604  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.582554  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.582535  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.582483  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.582470  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.582501  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.582555  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.582545  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.582517  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.582512  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.582608  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.582619  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.582581  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.582597  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.582578  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.582557  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.582639  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.582616  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.582613  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.582632  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.582639  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.582650  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.582634  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.582596  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.582642  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.582660  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.582716  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.582762  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.582776  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.582725  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.582747  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582712  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.582769  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.582764  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.582739  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.582731  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.582685  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.582695  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.582688  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.582759  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.582759  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.582797  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.582793  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.582757  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.582761  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.582709  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.582691  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.582648  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.582650  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.582652  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.582624  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.582644  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.582650  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.582620  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.582494  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.582488  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.582538  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.582516  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.582471  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.582372  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.582320  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.582260  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.582282  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.582296  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.582340  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.582339  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.582264  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.582206  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.582225  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.582261  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.582294  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.582333  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.582322  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.582329  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.582330  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.582302  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.582263  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.582305  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.582290  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.582258  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.582214  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.582209  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.582218  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.582260  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.582284  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.582284  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.582308  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.582308  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.582292  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.582318  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.582306  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.582297  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.582344  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.582380  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.582357  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.582319  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.582254  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.582266  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.582309  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.582319  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.582322  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.582306  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.582285  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.582318  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.582263  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.582268  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.582269  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.582238  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.582237  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.582260  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.582233  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.582277  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.582252  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.582299  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.582259  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.582213  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.582247  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.582315  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.582297  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.582289  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.582224  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.582230  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.582237  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.582214  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.582207  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.582150  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.582205  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.582202  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.582219  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.582193  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.582216  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.582304  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.582349  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.582305  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.582285  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.582284  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.582260  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.582254  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.582270  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.582277  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.582313  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.582317  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.582322  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.582284  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.582261  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.582275  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.582238  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.582220  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.582208  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.582180  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.582153  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.582210  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.582187  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.582188  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.582175  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.582187  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.582161  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.582153  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.582156  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.582132  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.582142  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.582109  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.582096  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.582089  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.582099  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.582136  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.582160  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.582130  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.582123  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.582159  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.582097  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.582111  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.582133  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.582129  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.582134  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.582136  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.582145  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.582135  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.582174  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.582210  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.582189  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.582181  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.582143  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.582186  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.582165  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.582189  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.582185  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.582177  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.582161  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.582173  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.582132  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.582138  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.582120  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.582130  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.582143  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.582162  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.582114  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.582127  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.582058  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.582037  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.582015  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.581995  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.582007  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.581998  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.582026  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.582059  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.582030  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.582039  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.582000  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.582039  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.582008  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.582024  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.581987  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.581977  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.581960  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.581963  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.581958  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.581964  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.581948  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.581951  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.581983  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.581975  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.581960  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.581911  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.581894  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.581907  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.581918  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.581892  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.581864  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.581853  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.581906  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.581908  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.581890  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.581901  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.581912  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.581939  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.581943  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.581949  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580587\n",
      "@eval_loop_avg_loss=0.578614\n",
      "Epoch 29/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.566186  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.574913  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.581089  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.580193  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.580537  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.582500  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.581700  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.581376  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.580103  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.578343  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.579037  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.577406  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.578782  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.578681  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.578146  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.578308  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.580346  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.579652  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.580113  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.580307  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.579828  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.581065  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.581551  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.581169  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.581279  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.581015  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.580574  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.581301  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.580984  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.581227  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.580963  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.580921  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.580686  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.580656  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.579693  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.580678  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.581104  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.580646  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.580577  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.580920  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.581276  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.581000  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.580518  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.580217  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.580062  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.580722  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.580551  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.581023  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.581131  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.581324  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.581416  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.581820  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.581294  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.580986  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.580794  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.581373  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.581334  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.581658  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.581814  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.581433  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.581263  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.581080  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.580917  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.581399  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.581224  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.580982  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.580919  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.581093  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.581271  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.581096  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.581226  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.581033  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.580900  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.580808  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.580968  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.580905  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.580640  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.580894  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.581076  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.581291  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.581368  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.581526  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.581736  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.581763  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.581841  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.581843  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.581690  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.581710  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.581522  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.581033  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.581151  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.581179  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.580966  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.580790  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.580644  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.580550  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.580901  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.580771  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.580832  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.580942  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.580892  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.580894  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.580954  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.581014  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.581208  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.581242  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.581264  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.581562  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.581550  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.581581  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.581596  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.581581  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.581581  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.581494  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.581814  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.581688  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.581664  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.581657  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.581675  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.581733  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.581868  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.581911  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.581670  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.581646  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.581752  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.581950  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.582207  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.582005  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.582047  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.582215  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.582389  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.582400  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.582402  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.582288  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.582194  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.582157  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.582052  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.582162  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.582126  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.582084  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.582104  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.582287  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.582363  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.582500  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.582527  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.582584  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.582560  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.582637  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.582718  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.582633  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.582737  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.582633  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.582665  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.582528  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.582516  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.582392  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.582402  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.582492  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.582677  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.582610  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.582671  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.582749  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.582781  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.582726  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.582809  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.582799  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.582806  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.582718  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.582754  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.582703  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.582613  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.582612  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.582545  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.582602  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.582553  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.582673  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.582625  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.582580  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.582604  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.582479  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.582584  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.582483  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.582533  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.582353  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.582329  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.582282  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.582268  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.582178  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.582096  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.582042  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.582012  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.582037  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.582028  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.582070  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.582134  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.582055  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.581982  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.582139  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.582097  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.582144  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.582244  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.582317  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.582329  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.582329  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.582384  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.582370  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.582395  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.582335  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.582330  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.582202  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.582374  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.582338  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.582315  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.582382  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.582379  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.582300  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.582336  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.582382  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.582332  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.582303  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.582381  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.582349  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.582249  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.582097  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.582044  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.582117  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.582106  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.582129  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.582095  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.582141  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.582287  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.582158  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.582169  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.582141  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.582124  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.582059  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.582138  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.582080  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.582138  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.582109  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.582206  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.582186  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.582203  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.582269  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.582260  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.582234  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.582199  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.582281  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.582307  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.582289  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.582254  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.582241  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.582276  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.582248  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.582288  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.582227  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.582295  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.582238  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.582265  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.582357  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.582387  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.582337  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.582377  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.582268  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.582276  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.582384  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.582402  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.582459  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.582379  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.582342  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.582329  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.582376  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.582421  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.582442  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.582420  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.582461  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.582480  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.582488  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.582522  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.582534  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.582537  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.582678  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.582667  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.582639  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.582684  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.582788  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.582751  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.582732  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.582732  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.582758  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.582769  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.582774  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.582790  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.582662  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.582656  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.582614  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.582594  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.582518  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.582593  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.582614  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.582623  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.582596  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.582551  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.582528  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.582440  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.582389  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.582444  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.582393  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.582427  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.582439  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.582427  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.582378  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.582341  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.582305  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.582303  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.582261  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.582201  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.582148  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.582134  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.582157  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.582219  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.582177  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.582151  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.582174  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.582115  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.582135  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.582155  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.582166  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.582162  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.582226  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.582231  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.582263  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.582259  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.582263  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.582183  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.582130  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.582135  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.582092  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.582157  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.582257  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.582302  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.582283  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.582227  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.582237  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.582182  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.582211  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.582229  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.582255  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.582279  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.582235  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.582250  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.582229  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.582259  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.582185  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.582124  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.582204  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.582220  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.582257  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.582238  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.582179  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.582180  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.582179  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.582149  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.582175  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.582123  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.582205  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.582235  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.582238  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.582245  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.582204  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.582152  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.582143  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.582152  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.582231  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.582235  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.582260  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.582238  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.582229  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.582210  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.582225  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.582170  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.582113  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.582116  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.582049  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.582089  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.582027  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.582035  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.582024  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.581922  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.581918  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.581932  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.581926  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.581979  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582004  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.582047  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.582025  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.581972  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.581938  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.581968  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.581973  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.581914  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.581919  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.582001  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.581968  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.581947  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.581927  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.581939  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.581910  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.581904  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.581864  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.581837  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.581837  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.581850  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.581853  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.581764  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.581716  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.581724  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.581749  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.581764  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.581806  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.581815  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.581862  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.581876  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.581970  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.581977  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.582011  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.581999  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.581971  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.581964  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.581983  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.581994  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.582004  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.582042  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.582041  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.582093  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.582090  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.582079  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.581991  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.581909  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.581884  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.581864  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.581843  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.581875  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.581905  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.581911  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.581889  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.581903  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.581927  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.581954  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.581939  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.581871  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.581846  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.581897  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.581927  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.581947  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.581934  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.581955  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.581919  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.581925  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.581955  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.581952  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.581942  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.581890  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.581843  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.581852  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.581857  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.581852  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.581841  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.581827  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.581842  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.581834  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.581837  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.581837  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.581799  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.581724  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.581741  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.581751  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.581750  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.581750  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.581809  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.581803  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.581812  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.581786  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.581775  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.581807  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.581798  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.581793  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.581798  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.581833  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.581803  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.581770  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.581760  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.581760  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.581715  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.581645  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.581660  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.581710  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.581772  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.581784  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.581772  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.581822  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.581898  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.581920  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.581955  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.581978  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.581991  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.581973  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.581970  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.581937  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.581877  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.581902  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.581940  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.581930  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.581916  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.581934  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.581958  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.581933  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.581920  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.581880  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.581875  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.581897  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.581926  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.581882  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.581873  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.581924  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.581933  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.581948  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.581941  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.581912  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.581962  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.581950  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.582009  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.582039  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.582017  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.582054  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.582046  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.582058  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.582036  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.582040  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.582084  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.582084  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.582104  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.582063  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.582088  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.582115  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.582144  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.582131  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.582151  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.582175  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.582165  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.582197  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.582261  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.582247  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.582238  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.582184  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.582209  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.582169  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.582137  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.582181  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.582171  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.582165  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.582178  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.582152  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.582156  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.582134  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.582110  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.582088  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.582080  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.582076  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.582093  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.582116  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.582096  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.582072  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.582069  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.582092  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.582089  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.582083  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.582062  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.582051  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.582059  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.581998  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.581990  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.581960  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.581952  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.581916  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.581902  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.581899  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.581898  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.581904  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.581933  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.581906  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.581890  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.581934  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.581957  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.581963  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.581968  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.581910  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.581889  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.581878  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.581887  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580523\n",
      "@eval_loop_avg_loss=0.578561\n",
      "Epoch 30/30:\n",
      "-------------------------------\n",
      "  Batch     0/  600 - avrg_Loss: 0.600868  processed_samples: 0.166667%\n",
      "  Batch     1/  600 - avrg_Loss: 0.597589  processed_samples: 0.333333%\n",
      "  Batch     2/  600 - avrg_Loss: 0.594559  processed_samples: 0.500000%\n",
      "  Batch     3/  600 - avrg_Loss: 0.582056  processed_samples: 0.666667%\n",
      "  Batch     4/  600 - avrg_Loss: 0.581620  processed_samples: 0.833333%\n",
      "  Batch     5/  600 - avrg_Loss: 0.584261  processed_samples: 1.000000%\n",
      "  Batch     6/  600 - avrg_Loss: 0.578821  processed_samples: 1.166667%\n",
      "  Batch     7/  600 - avrg_Loss: 0.576031  processed_samples: 1.333333%\n",
      "  Batch     8/  600 - avrg_Loss: 0.576877  processed_samples: 1.500000%\n",
      "  Batch     9/  600 - avrg_Loss: 0.576923  processed_samples: 1.666667%\n",
      "  Batch    10/  600 - avrg_Loss: 0.577088  processed_samples: 1.833333%\n",
      "  Batch    11/  600 - avrg_Loss: 0.575805  processed_samples: 2.000000%\n",
      "  Batch    12/  600 - avrg_Loss: 0.576113  processed_samples: 2.166667%\n",
      "  Batch    13/  600 - avrg_Loss: 0.578774  processed_samples: 2.333333%\n",
      "  Batch    14/  600 - avrg_Loss: 0.579288  processed_samples: 2.500000%\n",
      "  Batch    15/  600 - avrg_Loss: 0.579823  processed_samples: 2.666667%\n",
      "  Batch    16/  600 - avrg_Loss: 0.580015  processed_samples: 2.833333%\n",
      "  Batch    17/  600 - avrg_Loss: 0.580772  processed_samples: 3.000000%\n",
      "  Batch    18/  600 - avrg_Loss: 0.581126  processed_samples: 3.166667%\n",
      "  Batch    19/  600 - avrg_Loss: 0.582241  processed_samples: 3.333333%\n",
      "  Batch    20/  600 - avrg_Loss: 0.581905  processed_samples: 3.500000%\n",
      "  Batch    21/  600 - avrg_Loss: 0.581917  processed_samples: 3.666667%\n",
      "  Batch    22/  600 - avrg_Loss: 0.583311  processed_samples: 3.833333%\n",
      "  Batch    23/  600 - avrg_Loss: 0.582484  processed_samples: 4.000000%\n",
      "  Batch    24/  600 - avrg_Loss: 0.582755  processed_samples: 4.166667%\n",
      "  Batch    25/  600 - avrg_Loss: 0.582765  processed_samples: 4.333333%\n",
      "  Batch    26/  600 - avrg_Loss: 0.582517  processed_samples: 4.500000%\n",
      "  Batch    27/  600 - avrg_Loss: 0.582251  processed_samples: 4.666667%\n",
      "  Batch    28/  600 - avrg_Loss: 0.582523  processed_samples: 4.833333%\n",
      "  Batch    29/  600 - avrg_Loss: 0.583238  processed_samples: 5.000000%\n",
      "  Batch    30/  600 - avrg_Loss: 0.582665  processed_samples: 5.166667%\n",
      "  Batch    31/  600 - avrg_Loss: 0.582051  processed_samples: 5.333333%\n",
      "  Batch    32/  600 - avrg_Loss: 0.582520  processed_samples: 5.500000%\n",
      "  Batch    33/  600 - avrg_Loss: 0.582579  processed_samples: 5.666667%\n",
      "  Batch    34/  600 - avrg_Loss: 0.582753  processed_samples: 5.833333%\n",
      "  Batch    35/  600 - avrg_Loss: 0.582908  processed_samples: 6.000000%\n",
      "  Batch    36/  600 - avrg_Loss: 0.583627  processed_samples: 6.166667%\n",
      "  Batch    37/  600 - avrg_Loss: 0.583286  processed_samples: 6.333333%\n",
      "  Batch    38/  600 - avrg_Loss: 0.583302  processed_samples: 6.500000%\n",
      "  Batch    39/  600 - avrg_Loss: 0.582889  processed_samples: 6.666667%\n",
      "  Batch    40/  600 - avrg_Loss: 0.582042  processed_samples: 6.833333%\n",
      "  Batch    41/  600 - avrg_Loss: 0.582020  processed_samples: 7.000000%\n",
      "  Batch    42/  600 - avrg_Loss: 0.581820  processed_samples: 7.166667%\n",
      "  Batch    43/  600 - avrg_Loss: 0.581933  processed_samples: 7.333333%\n",
      "  Batch    44/  600 - avrg_Loss: 0.582126  processed_samples: 7.500000%\n",
      "  Batch    45/  600 - avrg_Loss: 0.582073  processed_samples: 7.666667%\n",
      "  Batch    46/  600 - avrg_Loss: 0.581751  processed_samples: 7.833333%\n",
      "  Batch    47/  600 - avrg_Loss: 0.581700  processed_samples: 8.000000%\n",
      "  Batch    48/  600 - avrg_Loss: 0.581187  processed_samples: 8.166667%\n",
      "  Batch    49/  600 - avrg_Loss: 0.581144  processed_samples: 8.333333%\n",
      "  Batch    50/  600 - avrg_Loss: 0.580441  processed_samples: 8.500000%\n",
      "  Batch    51/  600 - avrg_Loss: 0.580341  processed_samples: 8.666667%\n",
      "  Batch    52/  600 - avrg_Loss: 0.580694  processed_samples: 8.833333%\n",
      "  Batch    53/  600 - avrg_Loss: 0.580364  processed_samples: 9.000000%\n",
      "  Batch    54/  600 - avrg_Loss: 0.580947  processed_samples: 9.166667%\n",
      "  Batch    55/  600 - avrg_Loss: 0.580953  processed_samples: 9.333333%\n",
      "  Batch    56/  600 - avrg_Loss: 0.580587  processed_samples: 9.500000%\n",
      "  Batch    57/  600 - avrg_Loss: 0.580459  processed_samples: 9.666667%\n",
      "  Batch    58/  600 - avrg_Loss: 0.580243  processed_samples: 9.833333%\n",
      "  Batch    59/  600 - avrg_Loss: 0.580459  processed_samples: 10.000000%\n",
      "  Batch    60/  600 - avrg_Loss: 0.580517  processed_samples: 10.166667%\n",
      "  Batch    61/  600 - avrg_Loss: 0.580536  processed_samples: 10.333333%\n",
      "  Batch    62/  600 - avrg_Loss: 0.581070  processed_samples: 10.500000%\n",
      "  Batch    63/  600 - avrg_Loss: 0.580932  processed_samples: 10.666667%\n",
      "  Batch    64/  600 - avrg_Loss: 0.581061  processed_samples: 10.833333%\n",
      "  Batch    65/  600 - avrg_Loss: 0.581062  processed_samples: 11.000000%\n",
      "  Batch    66/  600 - avrg_Loss: 0.581043  processed_samples: 11.166667%\n",
      "  Batch    67/  600 - avrg_Loss: 0.580973  processed_samples: 11.333333%\n",
      "  Batch    68/  600 - avrg_Loss: 0.580739  processed_samples: 11.500000%\n",
      "  Batch    69/  600 - avrg_Loss: 0.580941  processed_samples: 11.666667%\n",
      "  Batch    70/  600 - avrg_Loss: 0.581219  processed_samples: 11.833333%\n",
      "  Batch    71/  600 - avrg_Loss: 0.581558  processed_samples: 12.000000%\n",
      "  Batch    72/  600 - avrg_Loss: 0.581419  processed_samples: 12.166667%\n",
      "  Batch    73/  600 - avrg_Loss: 0.581067  processed_samples: 12.333333%\n",
      "  Batch    74/  600 - avrg_Loss: 0.581132  processed_samples: 12.500000%\n",
      "  Batch    75/  600 - avrg_Loss: 0.580973  processed_samples: 12.666667%\n",
      "  Batch    76/  600 - avrg_Loss: 0.580521  processed_samples: 12.833333%\n",
      "  Batch    77/  600 - avrg_Loss: 0.580420  processed_samples: 13.000000%\n",
      "  Batch    78/  600 - avrg_Loss: 0.580524  processed_samples: 13.166667%\n",
      "  Batch    79/  600 - avrg_Loss: 0.580522  processed_samples: 13.333333%\n",
      "  Batch    80/  600 - avrg_Loss: 0.580744  processed_samples: 13.500000%\n",
      "  Batch    81/  600 - avrg_Loss: 0.580776  processed_samples: 13.666667%\n",
      "  Batch    82/  600 - avrg_Loss: 0.580600  processed_samples: 13.833333%\n",
      "  Batch    83/  600 - avrg_Loss: 0.580301  processed_samples: 14.000000%\n",
      "  Batch    84/  600 - avrg_Loss: 0.580127  processed_samples: 14.166667%\n",
      "  Batch    85/  600 - avrg_Loss: 0.580251  processed_samples: 14.333333%\n",
      "  Batch    86/  600 - avrg_Loss: 0.580317  processed_samples: 14.500000%\n",
      "  Batch    87/  600 - avrg_Loss: 0.580324  processed_samples: 14.666667%\n",
      "  Batch    88/  600 - avrg_Loss: 0.580530  processed_samples: 14.833333%\n",
      "  Batch    89/  600 - avrg_Loss: 0.580625  processed_samples: 15.000000%\n",
      "  Batch    90/  600 - avrg_Loss: 0.580743  processed_samples: 15.166667%\n",
      "  Batch    91/  600 - avrg_Loss: 0.580958  processed_samples: 15.333333%\n",
      "  Batch    92/  600 - avrg_Loss: 0.581208  processed_samples: 15.500000%\n",
      "  Batch    93/  600 - avrg_Loss: 0.581079  processed_samples: 15.666667%\n",
      "  Batch    94/  600 - avrg_Loss: 0.581216  processed_samples: 15.833333%\n",
      "  Batch    95/  600 - avrg_Loss: 0.581214  processed_samples: 16.000000%\n",
      "  Batch    96/  600 - avrg_Loss: 0.581147  processed_samples: 16.166667%\n",
      "  Batch    97/  600 - avrg_Loss: 0.581331  processed_samples: 16.333333%\n",
      "  Batch    98/  600 - avrg_Loss: 0.581583  processed_samples: 16.500000%\n",
      "  Batch    99/  600 - avrg_Loss: 0.581899  processed_samples: 16.666667%\n",
      "  Batch   100/  600 - avrg_Loss: 0.581826  processed_samples: 16.833333%\n",
      "  Batch   101/  600 - avrg_Loss: 0.581729  processed_samples: 17.000000%\n",
      "  Batch   102/  600 - avrg_Loss: 0.581767  processed_samples: 17.166667%\n",
      "  Batch   103/  600 - avrg_Loss: 0.581965  processed_samples: 17.333333%\n",
      "  Batch   104/  600 - avrg_Loss: 0.582006  processed_samples: 17.500000%\n",
      "  Batch   105/  600 - avrg_Loss: 0.581865  processed_samples: 17.666667%\n",
      "  Batch   106/  600 - avrg_Loss: 0.581759  processed_samples: 17.833333%\n",
      "  Batch   107/  600 - avrg_Loss: 0.581931  processed_samples: 18.000000%\n",
      "  Batch   108/  600 - avrg_Loss: 0.581737  processed_samples: 18.166667%\n",
      "  Batch   109/  600 - avrg_Loss: 0.581904  processed_samples: 18.333333%\n",
      "  Batch   110/  600 - avrg_Loss: 0.582067  processed_samples: 18.500000%\n",
      "  Batch   111/  600 - avrg_Loss: 0.582168  processed_samples: 18.666667%\n",
      "  Batch   112/  600 - avrg_Loss: 0.582376  processed_samples: 18.833333%\n",
      "  Batch   113/  600 - avrg_Loss: 0.582311  processed_samples: 19.000000%\n",
      "  Batch   114/  600 - avrg_Loss: 0.582376  processed_samples: 19.166667%\n",
      "  Batch   115/  600 - avrg_Loss: 0.582250  processed_samples: 19.333333%\n",
      "  Batch   116/  600 - avrg_Loss: 0.582296  processed_samples: 19.500000%\n",
      "  Batch   117/  600 - avrg_Loss: 0.582276  processed_samples: 19.666667%\n",
      "  Batch   118/  600 - avrg_Loss: 0.582289  processed_samples: 19.833333%\n",
      "  Batch   119/  600 - avrg_Loss: 0.582319  processed_samples: 20.000000%\n",
      "  Batch   120/  600 - avrg_Loss: 0.582138  processed_samples: 20.166667%\n",
      "  Batch   121/  600 - avrg_Loss: 0.581948  processed_samples: 20.333333%\n",
      "  Batch   122/  600 - avrg_Loss: 0.581928  processed_samples: 20.500000%\n",
      "  Batch   123/  600 - avrg_Loss: 0.582097  processed_samples: 20.666667%\n",
      "  Batch   124/  600 - avrg_Loss: 0.582167  processed_samples: 20.833333%\n",
      "  Batch   125/  600 - avrg_Loss: 0.582235  processed_samples: 21.000000%\n",
      "  Batch   126/  600 - avrg_Loss: 0.582198  processed_samples: 21.166667%\n",
      "  Batch   127/  600 - avrg_Loss: 0.582429  processed_samples: 21.333333%\n",
      "  Batch   128/  600 - avrg_Loss: 0.582267  processed_samples: 21.500000%\n",
      "  Batch   129/  600 - avrg_Loss: 0.582137  processed_samples: 21.666667%\n",
      "  Batch   130/  600 - avrg_Loss: 0.582193  processed_samples: 21.833333%\n",
      "  Batch   131/  600 - avrg_Loss: 0.582134  processed_samples: 22.000000%\n",
      "  Batch   132/  600 - avrg_Loss: 0.582034  processed_samples: 22.166667%\n",
      "  Batch   133/  600 - avrg_Loss: 0.582009  processed_samples: 22.333333%\n",
      "  Batch   134/  600 - avrg_Loss: 0.582082  processed_samples: 22.500000%\n",
      "  Batch   135/  600 - avrg_Loss: 0.582413  processed_samples: 22.666667%\n",
      "  Batch   136/  600 - avrg_Loss: 0.582561  processed_samples: 22.833333%\n",
      "  Batch   137/  600 - avrg_Loss: 0.582609  processed_samples: 23.000000%\n",
      "  Batch   138/  600 - avrg_Loss: 0.582553  processed_samples: 23.166667%\n",
      "  Batch   139/  600 - avrg_Loss: 0.582536  processed_samples: 23.333333%\n",
      "  Batch   140/  600 - avrg_Loss: 0.582314  processed_samples: 23.500000%\n",
      "  Batch   141/  600 - avrg_Loss: 0.582490  processed_samples: 23.666667%\n",
      "  Batch   142/  600 - avrg_Loss: 0.582373  processed_samples: 23.833333%\n",
      "  Batch   143/  600 - avrg_Loss: 0.582449  processed_samples: 24.000000%\n",
      "  Batch   144/  600 - avrg_Loss: 0.582423  processed_samples: 24.166667%\n",
      "  Batch   145/  600 - avrg_Loss: 0.582529  processed_samples: 24.333333%\n",
      "  Batch   146/  600 - avrg_Loss: 0.582466  processed_samples: 24.500000%\n",
      "  Batch   147/  600 - avrg_Loss: 0.582534  processed_samples: 24.666667%\n",
      "  Batch   148/  600 - avrg_Loss: 0.582414  processed_samples: 24.833333%\n",
      "  Batch   149/  600 - avrg_Loss: 0.582349  processed_samples: 25.000000%\n",
      "  Batch   150/  600 - avrg_Loss: 0.582361  processed_samples: 25.166667%\n",
      "  Batch   151/  600 - avrg_Loss: 0.582242  processed_samples: 25.333333%\n",
      "  Batch   152/  600 - avrg_Loss: 0.582359  processed_samples: 25.500000%\n",
      "  Batch   153/  600 - avrg_Loss: 0.582400  processed_samples: 25.666667%\n",
      "  Batch   154/  600 - avrg_Loss: 0.582499  processed_samples: 25.833333%\n",
      "  Batch   155/  600 - avrg_Loss: 0.582484  processed_samples: 26.000000%\n",
      "  Batch   156/  600 - avrg_Loss: 0.582516  processed_samples: 26.166667%\n",
      "  Batch   157/  600 - avrg_Loss: 0.582490  processed_samples: 26.333333%\n",
      "  Batch   158/  600 - avrg_Loss: 0.582633  processed_samples: 26.500000%\n",
      "  Batch   159/  600 - avrg_Loss: 0.582724  processed_samples: 26.666667%\n",
      "  Batch   160/  600 - avrg_Loss: 0.582673  processed_samples: 26.833333%\n",
      "  Batch   161/  600 - avrg_Loss: 0.582649  processed_samples: 27.000000%\n",
      "  Batch   162/  600 - avrg_Loss: 0.582531  processed_samples: 27.166667%\n",
      "  Batch   163/  600 - avrg_Loss: 0.582595  processed_samples: 27.333333%\n",
      "  Batch   164/  600 - avrg_Loss: 0.582650  processed_samples: 27.500000%\n",
      "  Batch   165/  600 - avrg_Loss: 0.582615  processed_samples: 27.666667%\n",
      "  Batch   166/  600 - avrg_Loss: 0.582637  processed_samples: 27.833333%\n",
      "  Batch   167/  600 - avrg_Loss: 0.582515  processed_samples: 28.000000%\n",
      "  Batch   168/  600 - avrg_Loss: 0.582548  processed_samples: 28.166667%\n",
      "  Batch   169/  600 - avrg_Loss: 0.582638  processed_samples: 28.333333%\n",
      "  Batch   170/  600 - avrg_Loss: 0.582689  processed_samples: 28.500000%\n",
      "  Batch   171/  600 - avrg_Loss: 0.582695  processed_samples: 28.666667%\n",
      "  Batch   172/  600 - avrg_Loss: 0.582665  processed_samples: 28.833333%\n",
      "  Batch   173/  600 - avrg_Loss: 0.582655  processed_samples: 29.000000%\n",
      "  Batch   174/  600 - avrg_Loss: 0.582650  processed_samples: 29.166667%\n",
      "  Batch   175/  600 - avrg_Loss: 0.582616  processed_samples: 29.333333%\n",
      "  Batch   176/  600 - avrg_Loss: 0.582651  processed_samples: 29.500000%\n",
      "  Batch   177/  600 - avrg_Loss: 0.582720  processed_samples: 29.666667%\n",
      "  Batch   178/  600 - avrg_Loss: 0.582733  processed_samples: 29.833333%\n",
      "  Batch   179/  600 - avrg_Loss: 0.582589  processed_samples: 30.000000%\n",
      "  Batch   180/  600 - avrg_Loss: 0.582490  processed_samples: 30.166667%\n",
      "  Batch   181/  600 - avrg_Loss: 0.582572  processed_samples: 30.333333%\n",
      "  Batch   182/  600 - avrg_Loss: 0.582722  processed_samples: 30.500000%\n",
      "  Batch   183/  600 - avrg_Loss: 0.582733  processed_samples: 30.666667%\n",
      "  Batch   184/  600 - avrg_Loss: 0.582755  processed_samples: 30.833333%\n",
      "  Batch   185/  600 - avrg_Loss: 0.582760  processed_samples: 31.000000%\n",
      "  Batch   186/  600 - avrg_Loss: 0.582789  processed_samples: 31.166667%\n",
      "  Batch   187/  600 - avrg_Loss: 0.582731  processed_samples: 31.333333%\n",
      "  Batch   188/  600 - avrg_Loss: 0.582840  processed_samples: 31.500000%\n",
      "  Batch   189/  600 - avrg_Loss: 0.582737  processed_samples: 31.666667%\n",
      "  Batch   190/  600 - avrg_Loss: 0.582800  processed_samples: 31.833333%\n",
      "  Batch   191/  600 - avrg_Loss: 0.582863  processed_samples: 32.000000%\n",
      "  Batch   192/  600 - avrg_Loss: 0.583014  processed_samples: 32.166667%\n",
      "  Batch   193/  600 - avrg_Loss: 0.582968  processed_samples: 32.333333%\n",
      "  Batch   194/  600 - avrg_Loss: 0.583128  processed_samples: 32.500000%\n",
      "  Batch   195/  600 - avrg_Loss: 0.583199  processed_samples: 32.666667%\n",
      "  Batch   196/  600 - avrg_Loss: 0.583108  processed_samples: 32.833333%\n",
      "  Batch   197/  600 - avrg_Loss: 0.583096  processed_samples: 33.000000%\n",
      "  Batch   198/  600 - avrg_Loss: 0.583127  processed_samples: 33.166667%\n",
      "  Batch   199/  600 - avrg_Loss: 0.583025  processed_samples: 33.333333%\n",
      "  Batch   200/  600 - avrg_Loss: 0.582867  processed_samples: 33.500000%\n",
      "  Batch   201/  600 - avrg_Loss: 0.582928  processed_samples: 33.666667%\n",
      "  Batch   202/  600 - avrg_Loss: 0.583085  processed_samples: 33.833333%\n",
      "  Batch   203/  600 - avrg_Loss: 0.583130  processed_samples: 34.000000%\n",
      "  Batch   204/  600 - avrg_Loss: 0.583198  processed_samples: 34.166667%\n",
      "  Batch   205/  600 - avrg_Loss: 0.583237  processed_samples: 34.333333%\n",
      "  Batch   206/  600 - avrg_Loss: 0.583292  processed_samples: 34.500000%\n",
      "  Batch   207/  600 - avrg_Loss: 0.583330  processed_samples: 34.666667%\n",
      "  Batch   208/  600 - avrg_Loss: 0.583299  processed_samples: 34.833333%\n",
      "  Batch   209/  600 - avrg_Loss: 0.583245  processed_samples: 35.000000%\n",
      "  Batch   210/  600 - avrg_Loss: 0.583197  processed_samples: 35.166667%\n",
      "  Batch   211/  600 - avrg_Loss: 0.583134  processed_samples: 35.333333%\n",
      "  Batch   212/  600 - avrg_Loss: 0.583133  processed_samples: 35.500000%\n",
      "  Batch   213/  600 - avrg_Loss: 0.583059  processed_samples: 35.666667%\n",
      "  Batch   214/  600 - avrg_Loss: 0.583045  processed_samples: 35.833333%\n",
      "  Batch   215/  600 - avrg_Loss: 0.582875  processed_samples: 36.000000%\n",
      "  Batch   216/  600 - avrg_Loss: 0.582896  processed_samples: 36.166667%\n",
      "  Batch   217/  600 - avrg_Loss: 0.582760  processed_samples: 36.333333%\n",
      "  Batch   218/  600 - avrg_Loss: 0.582867  processed_samples: 36.500000%\n",
      "  Batch   219/  600 - avrg_Loss: 0.582866  processed_samples: 36.666667%\n",
      "  Batch   220/  600 - avrg_Loss: 0.583020  processed_samples: 36.833333%\n",
      "  Batch   221/  600 - avrg_Loss: 0.582925  processed_samples: 37.000000%\n",
      "  Batch   222/  600 - avrg_Loss: 0.582792  processed_samples: 37.166667%\n",
      "  Batch   223/  600 - avrg_Loss: 0.582797  processed_samples: 37.333333%\n",
      "  Batch   224/  600 - avrg_Loss: 0.582766  processed_samples: 37.500000%\n",
      "  Batch   225/  600 - avrg_Loss: 0.582795  processed_samples: 37.666667%\n",
      "  Batch   226/  600 - avrg_Loss: 0.582719  processed_samples: 37.833333%\n",
      "  Batch   227/  600 - avrg_Loss: 0.582648  processed_samples: 38.000000%\n",
      "  Batch   228/  600 - avrg_Loss: 0.582608  processed_samples: 38.166667%\n",
      "  Batch   229/  600 - avrg_Loss: 0.582584  processed_samples: 38.333333%\n",
      "  Batch   230/  600 - avrg_Loss: 0.582616  processed_samples: 38.500000%\n",
      "  Batch   231/  600 - avrg_Loss: 0.582624  processed_samples: 38.666667%\n",
      "  Batch   232/  600 - avrg_Loss: 0.582552  processed_samples: 38.833333%\n",
      "  Batch   233/  600 - avrg_Loss: 0.582400  processed_samples: 39.000000%\n",
      "  Batch   234/  600 - avrg_Loss: 0.582383  processed_samples: 39.166667%\n",
      "  Batch   235/  600 - avrg_Loss: 0.582379  processed_samples: 39.333333%\n",
      "  Batch   236/  600 - avrg_Loss: 0.582379  processed_samples: 39.500000%\n",
      "  Batch   237/  600 - avrg_Loss: 0.582332  processed_samples: 39.666667%\n",
      "  Batch   238/  600 - avrg_Loss: 0.582428  processed_samples: 39.833333%\n",
      "  Batch   239/  600 - avrg_Loss: 0.582436  processed_samples: 40.000000%\n",
      "  Batch   240/  600 - avrg_Loss: 0.582515  processed_samples: 40.166667%\n",
      "  Batch   241/  600 - avrg_Loss: 0.582445  processed_samples: 40.333333%\n",
      "  Batch   242/  600 - avrg_Loss: 0.582329  processed_samples: 40.500000%\n",
      "  Batch   243/  600 - avrg_Loss: 0.582339  processed_samples: 40.666667%\n",
      "  Batch   244/  600 - avrg_Loss: 0.582390  processed_samples: 40.833333%\n",
      "  Batch   245/  600 - avrg_Loss: 0.582407  processed_samples: 41.000000%\n",
      "  Batch   246/  600 - avrg_Loss: 0.582420  processed_samples: 41.166667%\n",
      "  Batch   247/  600 - avrg_Loss: 0.582381  processed_samples: 41.333333%\n",
      "  Batch   248/  600 - avrg_Loss: 0.582312  processed_samples: 41.500000%\n",
      "  Batch   249/  600 - avrg_Loss: 0.582386  processed_samples: 41.666667%\n",
      "  Batch   250/  600 - avrg_Loss: 0.582408  processed_samples: 41.833333%\n",
      "  Batch   251/  600 - avrg_Loss: 0.582364  processed_samples: 42.000000%\n",
      "  Batch   252/  600 - avrg_Loss: 0.582339  processed_samples: 42.166667%\n",
      "  Batch   253/  600 - avrg_Loss: 0.582349  processed_samples: 42.333333%\n",
      "  Batch   254/  600 - avrg_Loss: 0.582424  processed_samples: 42.500000%\n",
      "  Batch   255/  600 - avrg_Loss: 0.582511  processed_samples: 42.666667%\n",
      "  Batch   256/  600 - avrg_Loss: 0.582600  processed_samples: 42.833333%\n",
      "  Batch   257/  600 - avrg_Loss: 0.582591  processed_samples: 43.000000%\n",
      "  Batch   258/  600 - avrg_Loss: 0.582635  processed_samples: 43.166667%\n",
      "  Batch   259/  600 - avrg_Loss: 0.582581  processed_samples: 43.333333%\n",
      "  Batch   260/  600 - avrg_Loss: 0.582689  processed_samples: 43.500000%\n",
      "  Batch   261/  600 - avrg_Loss: 0.582632  processed_samples: 43.666667%\n",
      "  Batch   262/  600 - avrg_Loss: 0.582591  processed_samples: 43.833333%\n",
      "  Batch   263/  600 - avrg_Loss: 0.582596  processed_samples: 44.000000%\n",
      "  Batch   264/  600 - avrg_Loss: 0.582611  processed_samples: 44.166667%\n",
      "  Batch   265/  600 - avrg_Loss: 0.582446  processed_samples: 44.333333%\n",
      "  Batch   266/  600 - avrg_Loss: 0.582392  processed_samples: 44.500000%\n",
      "  Batch   267/  600 - avrg_Loss: 0.582424  processed_samples: 44.666667%\n",
      "  Batch   268/  600 - avrg_Loss: 0.582447  processed_samples: 44.833333%\n",
      "  Batch   269/  600 - avrg_Loss: 0.582415  processed_samples: 45.000000%\n",
      "  Batch   270/  600 - avrg_Loss: 0.582508  processed_samples: 45.166667%\n",
      "  Batch   271/  600 - avrg_Loss: 0.582597  processed_samples: 45.333333%\n",
      "  Batch   272/  600 - avrg_Loss: 0.582558  processed_samples: 45.500000%\n",
      "  Batch   273/  600 - avrg_Loss: 0.582557  processed_samples: 45.666667%\n",
      "  Batch   274/  600 - avrg_Loss: 0.582549  processed_samples: 45.833333%\n",
      "  Batch   275/  600 - avrg_Loss: 0.582532  processed_samples: 46.000000%\n",
      "  Batch   276/  600 - avrg_Loss: 0.582504  processed_samples: 46.166667%\n",
      "  Batch   277/  600 - avrg_Loss: 0.582465  processed_samples: 46.333333%\n",
      "  Batch   278/  600 - avrg_Loss: 0.582432  processed_samples: 46.500000%\n",
      "  Batch   279/  600 - avrg_Loss: 0.582365  processed_samples: 46.666667%\n",
      "  Batch   280/  600 - avrg_Loss: 0.582422  processed_samples: 46.833333%\n",
      "  Batch   281/  600 - avrg_Loss: 0.582320  processed_samples: 47.000000%\n",
      "  Batch   282/  600 - avrg_Loss: 0.582224  processed_samples: 47.166667%\n",
      "  Batch   283/  600 - avrg_Loss: 0.582198  processed_samples: 47.333333%\n",
      "  Batch   284/  600 - avrg_Loss: 0.582187  processed_samples: 47.500000%\n",
      "  Batch   285/  600 - avrg_Loss: 0.582149  processed_samples: 47.666667%\n",
      "  Batch   286/  600 - avrg_Loss: 0.582177  processed_samples: 47.833333%\n",
      "  Batch   287/  600 - avrg_Loss: 0.582241  processed_samples: 48.000000%\n",
      "  Batch   288/  600 - avrg_Loss: 0.582279  processed_samples: 48.166667%\n",
      "  Batch   289/  600 - avrg_Loss: 0.582397  processed_samples: 48.333333%\n",
      "  Batch   290/  600 - avrg_Loss: 0.582432  processed_samples: 48.500000%\n",
      "  Batch   291/  600 - avrg_Loss: 0.582462  processed_samples: 48.666667%\n",
      "  Batch   292/  600 - avrg_Loss: 0.582491  processed_samples: 48.833333%\n",
      "  Batch   293/  600 - avrg_Loss: 0.582432  processed_samples: 49.000000%\n",
      "  Batch   294/  600 - avrg_Loss: 0.582340  processed_samples: 49.166667%\n",
      "  Batch   295/  600 - avrg_Loss: 0.582407  processed_samples: 49.333333%\n",
      "  Batch   296/  600 - avrg_Loss: 0.582447  processed_samples: 49.500000%\n",
      "  Batch   297/  600 - avrg_Loss: 0.582398  processed_samples: 49.666667%\n",
      "  Batch   298/  600 - avrg_Loss: 0.582430  processed_samples: 49.833333%\n",
      "  Batch   299/  600 - avrg_Loss: 0.582424  processed_samples: 50.000000%\n",
      "  Batch   300/  600 - avrg_Loss: 0.582470  processed_samples: 50.166667%\n",
      "  Batch   301/  600 - avrg_Loss: 0.582399  processed_samples: 50.333333%\n",
      "  Batch   302/  600 - avrg_Loss: 0.582427  processed_samples: 50.500000%\n",
      "  Batch   303/  600 - avrg_Loss: 0.582494  processed_samples: 50.666667%\n",
      "  Batch   304/  600 - avrg_Loss: 0.582464  processed_samples: 50.833333%\n",
      "  Batch   305/  600 - avrg_Loss: 0.582406  processed_samples: 51.000000%\n",
      "  Batch   306/  600 - avrg_Loss: 0.582382  processed_samples: 51.166667%\n",
      "  Batch   307/  600 - avrg_Loss: 0.582314  processed_samples: 51.333333%\n",
      "  Batch   308/  600 - avrg_Loss: 0.582338  processed_samples: 51.500000%\n",
      "  Batch   309/  600 - avrg_Loss: 0.582323  processed_samples: 51.666667%\n",
      "  Batch   310/  600 - avrg_Loss: 0.582420  processed_samples: 51.833333%\n",
      "  Batch   311/  600 - avrg_Loss: 0.582400  processed_samples: 52.000000%\n",
      "  Batch   312/  600 - avrg_Loss: 0.582332  processed_samples: 52.166667%\n",
      "  Batch   313/  600 - avrg_Loss: 0.582343  processed_samples: 52.333333%\n",
      "  Batch   314/  600 - avrg_Loss: 0.582346  processed_samples: 52.500000%\n",
      "  Batch   315/  600 - avrg_Loss: 0.582360  processed_samples: 52.666667%\n",
      "  Batch   316/  600 - avrg_Loss: 0.582402  processed_samples: 52.833333%\n",
      "  Batch   317/  600 - avrg_Loss: 0.582335  processed_samples: 53.000000%\n",
      "  Batch   318/  600 - avrg_Loss: 0.582322  processed_samples: 53.166667%\n",
      "  Batch   319/  600 - avrg_Loss: 0.582340  processed_samples: 53.333333%\n",
      "  Batch   320/  600 - avrg_Loss: 0.582279  processed_samples: 53.500000%\n",
      "  Batch   321/  600 - avrg_Loss: 0.582293  processed_samples: 53.666667%\n",
      "  Batch   322/  600 - avrg_Loss: 0.582336  processed_samples: 53.833333%\n",
      "  Batch   323/  600 - avrg_Loss: 0.582275  processed_samples: 54.000000%\n",
      "  Batch   324/  600 - avrg_Loss: 0.582309  processed_samples: 54.166667%\n",
      "  Batch   325/  600 - avrg_Loss: 0.582348  processed_samples: 54.333333%\n",
      "  Batch   326/  600 - avrg_Loss: 0.582375  processed_samples: 54.500000%\n",
      "  Batch   327/  600 - avrg_Loss: 0.582361  processed_samples: 54.666667%\n",
      "  Batch   328/  600 - avrg_Loss: 0.582313  processed_samples: 54.833333%\n",
      "  Batch   329/  600 - avrg_Loss: 0.582292  processed_samples: 55.000000%\n",
      "  Batch   330/  600 - avrg_Loss: 0.582350  processed_samples: 55.166667%\n",
      "  Batch   331/  600 - avrg_Loss: 0.582309  processed_samples: 55.333333%\n",
      "  Batch   332/  600 - avrg_Loss: 0.582318  processed_samples: 55.500000%\n",
      "  Batch   333/  600 - avrg_Loss: 0.582271  processed_samples: 55.666667%\n",
      "  Batch   334/  600 - avrg_Loss: 0.582266  processed_samples: 55.833333%\n",
      "  Batch   335/  600 - avrg_Loss: 0.582272  processed_samples: 56.000000%\n",
      "  Batch   336/  600 - avrg_Loss: 0.582253  processed_samples: 56.166667%\n",
      "  Batch   337/  600 - avrg_Loss: 0.582235  processed_samples: 56.333333%\n",
      "  Batch   338/  600 - avrg_Loss: 0.582256  processed_samples: 56.500000%\n",
      "  Batch   339/  600 - avrg_Loss: 0.582237  processed_samples: 56.666667%\n",
      "  Batch   340/  600 - avrg_Loss: 0.582339  processed_samples: 56.833333%\n",
      "  Batch   341/  600 - avrg_Loss: 0.582377  processed_samples: 57.000000%\n",
      "  Batch   342/  600 - avrg_Loss: 0.582443  processed_samples: 57.166667%\n",
      "  Batch   343/  600 - avrg_Loss: 0.582443  processed_samples: 57.333333%\n",
      "  Batch   344/  600 - avrg_Loss: 0.582396  processed_samples: 57.500000%\n",
      "  Batch   345/  600 - avrg_Loss: 0.582469  processed_samples: 57.666667%\n",
      "  Batch   346/  600 - avrg_Loss: 0.582433  processed_samples: 57.833333%\n",
      "  Batch   347/  600 - avrg_Loss: 0.582446  processed_samples: 58.000000%\n",
      "  Batch   348/  600 - avrg_Loss: 0.582431  processed_samples: 58.166667%\n",
      "  Batch   349/  600 - avrg_Loss: 0.582511  processed_samples: 58.333333%\n",
      "  Batch   350/  600 - avrg_Loss: 0.582556  processed_samples: 58.500000%\n",
      "  Batch   351/  600 - avrg_Loss: 0.582603  processed_samples: 58.666667%\n",
      "  Batch   352/  600 - avrg_Loss: 0.582656  processed_samples: 58.833333%\n",
      "  Batch   353/  600 - avrg_Loss: 0.582700  processed_samples: 59.000000%\n",
      "  Batch   354/  600 - avrg_Loss: 0.582622  processed_samples: 59.166667%\n",
      "  Batch   355/  600 - avrg_Loss: 0.582606  processed_samples: 59.333333%\n",
      "  Batch   356/  600 - avrg_Loss: 0.582628  processed_samples: 59.500000%\n",
      "  Batch   357/  600 - avrg_Loss: 0.582687  processed_samples: 59.666667%\n",
      "  Batch   358/  600 - avrg_Loss: 0.582769  processed_samples: 59.833333%\n",
      "  Batch   359/  600 - avrg_Loss: 0.582787  processed_samples: 60.000000%\n",
      "  Batch   360/  600 - avrg_Loss: 0.582864  processed_samples: 60.166667%\n",
      "  Batch   361/  600 - avrg_Loss: 0.582873  processed_samples: 60.333333%\n",
      "  Batch   362/  600 - avrg_Loss: 0.582888  processed_samples: 60.500000%\n",
      "  Batch   363/  600 - avrg_Loss: 0.582903  processed_samples: 60.666667%\n",
      "  Batch   364/  600 - avrg_Loss: 0.582863  processed_samples: 60.833333%\n",
      "  Batch   365/  600 - avrg_Loss: 0.582887  processed_samples: 61.000000%\n",
      "  Batch   366/  600 - avrg_Loss: 0.582882  processed_samples: 61.166667%\n",
      "  Batch   367/  600 - avrg_Loss: 0.582861  processed_samples: 61.333333%\n",
      "  Batch   368/  600 - avrg_Loss: 0.582820  processed_samples: 61.500000%\n",
      "  Batch   369/  600 - avrg_Loss: 0.582851  processed_samples: 61.666667%\n",
      "  Batch   370/  600 - avrg_Loss: 0.582851  processed_samples: 61.833333%\n",
      "  Batch   371/  600 - avrg_Loss: 0.582808  processed_samples: 62.000000%\n",
      "  Batch   372/  600 - avrg_Loss: 0.582763  processed_samples: 62.166667%\n",
      "  Batch   373/  600 - avrg_Loss: 0.582745  processed_samples: 62.333333%\n",
      "  Batch   374/  600 - avrg_Loss: 0.582696  processed_samples: 62.500000%\n",
      "  Batch   375/  600 - avrg_Loss: 0.582724  processed_samples: 62.666667%\n",
      "  Batch   376/  600 - avrg_Loss: 0.582745  processed_samples: 62.833333%\n",
      "  Batch   377/  600 - avrg_Loss: 0.582722  processed_samples: 63.000000%\n",
      "  Batch   378/  600 - avrg_Loss: 0.582708  processed_samples: 63.166667%\n",
      "  Batch   379/  600 - avrg_Loss: 0.582699  processed_samples: 63.333333%\n",
      "  Batch   380/  600 - avrg_Loss: 0.582687  processed_samples: 63.500000%\n",
      "  Batch   381/  600 - avrg_Loss: 0.582701  processed_samples: 63.666667%\n",
      "  Batch   382/  600 - avrg_Loss: 0.582754  processed_samples: 63.833333%\n",
      "  Batch   383/  600 - avrg_Loss: 0.582718  processed_samples: 64.000000%\n",
      "  Batch   384/  600 - avrg_Loss: 0.582668  processed_samples: 64.166667%\n",
      "  Batch   385/  600 - avrg_Loss: 0.582681  processed_samples: 64.333333%\n",
      "  Batch   386/  600 - avrg_Loss: 0.582728  processed_samples: 64.500000%\n",
      "  Batch   387/  600 - avrg_Loss: 0.582727  processed_samples: 64.666667%\n",
      "  Batch   388/  600 - avrg_Loss: 0.582663  processed_samples: 64.833333%\n",
      "  Batch   389/  600 - avrg_Loss: 0.582664  processed_samples: 65.000000%\n",
      "  Batch   390/  600 - avrg_Loss: 0.582655  processed_samples: 65.166667%\n",
      "  Batch   391/  600 - avrg_Loss: 0.582670  processed_samples: 65.333333%\n",
      "  Batch   392/  600 - avrg_Loss: 0.582695  processed_samples: 65.500000%\n",
      "  Batch   393/  600 - avrg_Loss: 0.582686  processed_samples: 65.666667%\n",
      "  Batch   394/  600 - avrg_Loss: 0.582719  processed_samples: 65.833333%\n",
      "  Batch   395/  600 - avrg_Loss: 0.582690  processed_samples: 66.000000%\n",
      "  Batch   396/  600 - avrg_Loss: 0.582679  processed_samples: 66.166667%\n",
      "  Batch   397/  600 - avrg_Loss: 0.582705  processed_samples: 66.333333%\n",
      "  Batch   398/  600 - avrg_Loss: 0.582710  processed_samples: 66.500000%\n",
      "  Batch   399/  600 - avrg_Loss: 0.582735  processed_samples: 66.666667%\n",
      "  Batch   400/  600 - avrg_Loss: 0.582649  processed_samples: 66.833333%\n",
      "  Batch   401/  600 - avrg_Loss: 0.582605  processed_samples: 67.000000%\n",
      "  Batch   402/  600 - avrg_Loss: 0.582593  processed_samples: 67.166667%\n",
      "  Batch   403/  600 - avrg_Loss: 0.582557  processed_samples: 67.333333%\n",
      "  Batch   404/  600 - avrg_Loss: 0.582527  processed_samples: 67.500000%\n",
      "  Batch   405/  600 - avrg_Loss: 0.582494  processed_samples: 67.666667%\n",
      "  Batch   406/  600 - avrg_Loss: 0.582499  processed_samples: 67.833333%\n",
      "  Batch   407/  600 - avrg_Loss: 0.582531  processed_samples: 68.000000%\n",
      "  Batch   408/  600 - avrg_Loss: 0.582496  processed_samples: 68.166667%\n",
      "  Batch   409/  600 - avrg_Loss: 0.582516  processed_samples: 68.333333%\n",
      "  Batch   410/  600 - avrg_Loss: 0.582455  processed_samples: 68.500000%\n",
      "  Batch   411/  600 - avrg_Loss: 0.582459  processed_samples: 68.666667%\n",
      "  Batch   412/  600 - avrg_Loss: 0.582436  processed_samples: 68.833333%\n",
      "  Batch   413/  600 - avrg_Loss: 0.582405  processed_samples: 69.000000%\n",
      "  Batch   414/  600 - avrg_Loss: 0.582330  processed_samples: 69.166667%\n",
      "  Batch   415/  600 - avrg_Loss: 0.582379  processed_samples: 69.333333%\n",
      "  Batch   416/  600 - avrg_Loss: 0.582350  processed_samples: 69.500000%\n",
      "  Batch   417/  600 - avrg_Loss: 0.582383  processed_samples: 69.666667%\n",
      "  Batch   418/  600 - avrg_Loss: 0.582430  processed_samples: 69.833333%\n",
      "  Batch   419/  600 - avrg_Loss: 0.582439  processed_samples: 70.000000%\n",
      "  Batch   420/  600 - avrg_Loss: 0.582488  processed_samples: 70.166667%\n",
      "  Batch   421/  600 - avrg_Loss: 0.582473  processed_samples: 70.333333%\n",
      "  Batch   422/  600 - avrg_Loss: 0.582465  processed_samples: 70.500000%\n",
      "  Batch   423/  600 - avrg_Loss: 0.582528  processed_samples: 70.666667%\n",
      "  Batch   424/  600 - avrg_Loss: 0.582510  processed_samples: 70.833333%\n",
      "  Batch   425/  600 - avrg_Loss: 0.582492  processed_samples: 71.000000%\n",
      "  Batch   426/  600 - avrg_Loss: 0.582515  processed_samples: 71.166667%\n",
      "  Batch   427/  600 - avrg_Loss: 0.582528  processed_samples: 71.333333%\n",
      "  Batch   428/  600 - avrg_Loss: 0.582532  processed_samples: 71.500000%\n",
      "  Batch   429/  600 - avrg_Loss: 0.582541  processed_samples: 71.666667%\n",
      "  Batch   430/  600 - avrg_Loss: 0.582513  processed_samples: 71.833333%\n",
      "  Batch   431/  600 - avrg_Loss: 0.582487  processed_samples: 72.000000%\n",
      "  Batch   432/  600 - avrg_Loss: 0.582533  processed_samples: 72.166667%\n",
      "  Batch   433/  600 - avrg_Loss: 0.582547  processed_samples: 72.333333%\n",
      "  Batch   434/  600 - avrg_Loss: 0.582536  processed_samples: 72.500000%\n",
      "  Batch   435/  600 - avrg_Loss: 0.582565  processed_samples: 72.666667%\n",
      "  Batch   436/  600 - avrg_Loss: 0.582556  processed_samples: 72.833333%\n",
      "  Batch   437/  600 - avrg_Loss: 0.582569  processed_samples: 73.000000%\n",
      "  Batch   438/  600 - avrg_Loss: 0.582553  processed_samples: 73.166667%\n",
      "  Batch   439/  600 - avrg_Loss: 0.582510  processed_samples: 73.333333%\n",
      "  Batch   440/  600 - avrg_Loss: 0.582423  processed_samples: 73.500000%\n",
      "  Batch   441/  600 - avrg_Loss: 0.582443  processed_samples: 73.666667%\n",
      "  Batch   442/  600 - avrg_Loss: 0.582445  processed_samples: 73.833333%\n",
      "  Batch   443/  600 - avrg_Loss: 0.582495  processed_samples: 74.000000%\n",
      "  Batch   444/  600 - avrg_Loss: 0.582470  processed_samples: 74.166667%\n",
      "  Batch   445/  600 - avrg_Loss: 0.582450  processed_samples: 74.333333%\n",
      "  Batch   446/  600 - avrg_Loss: 0.582417  processed_samples: 74.500000%\n",
      "  Batch   447/  600 - avrg_Loss: 0.582385  processed_samples: 74.666667%\n",
      "  Batch   448/  600 - avrg_Loss: 0.582408  processed_samples: 74.833333%\n",
      "  Batch   449/  600 - avrg_Loss: 0.582414  processed_samples: 75.000000%\n",
      "  Batch   450/  600 - avrg_Loss: 0.582409  processed_samples: 75.166667%\n",
      "  Batch   451/  600 - avrg_Loss: 0.582404  processed_samples: 75.333333%\n",
      "  Batch   452/  600 - avrg_Loss: 0.582365  processed_samples: 75.500000%\n",
      "  Batch   453/  600 - avrg_Loss: 0.582356  processed_samples: 75.666667%\n",
      "  Batch   454/  600 - avrg_Loss: 0.582367  processed_samples: 75.833333%\n",
      "  Batch   455/  600 - avrg_Loss: 0.582338  processed_samples: 76.000000%\n",
      "  Batch   456/  600 - avrg_Loss: 0.582300  processed_samples: 76.166667%\n",
      "  Batch   457/  600 - avrg_Loss: 0.582301  processed_samples: 76.333333%\n",
      "  Batch   458/  600 - avrg_Loss: 0.582260  processed_samples: 76.500000%\n",
      "  Batch   459/  600 - avrg_Loss: 0.582245  processed_samples: 76.666667%\n",
      "  Batch   460/  600 - avrg_Loss: 0.582199  processed_samples: 76.833333%\n",
      "  Batch   461/  600 - avrg_Loss: 0.582299  processed_samples: 77.000000%\n",
      "  Batch   462/  600 - avrg_Loss: 0.582316  processed_samples: 77.166667%\n",
      "  Batch   463/  600 - avrg_Loss: 0.582318  processed_samples: 77.333333%\n",
      "  Batch   464/  600 - avrg_Loss: 0.582282  processed_samples: 77.500000%\n",
      "  Batch   465/  600 - avrg_Loss: 0.582283  processed_samples: 77.666667%\n",
      "  Batch   466/  600 - avrg_Loss: 0.582307  processed_samples: 77.833333%\n",
      "  Batch   467/  600 - avrg_Loss: 0.582270  processed_samples: 78.000000%\n",
      "  Batch   468/  600 - avrg_Loss: 0.582313  processed_samples: 78.166667%\n",
      "  Batch   469/  600 - avrg_Loss: 0.582353  processed_samples: 78.333333%\n",
      "  Batch   470/  600 - avrg_Loss: 0.582368  processed_samples: 78.500000%\n",
      "  Batch   471/  600 - avrg_Loss: 0.582395  processed_samples: 78.666667%\n",
      "  Batch   472/  600 - avrg_Loss: 0.582401  processed_samples: 78.833333%\n",
      "  Batch   473/  600 - avrg_Loss: 0.582401  processed_samples: 79.000000%\n",
      "  Batch   474/  600 - avrg_Loss: 0.582393  processed_samples: 79.166667%\n",
      "  Batch   475/  600 - avrg_Loss: 0.582363  processed_samples: 79.333333%\n",
      "  Batch   476/  600 - avrg_Loss: 0.582321  processed_samples: 79.500000%\n",
      "  Batch   477/  600 - avrg_Loss: 0.582348  processed_samples: 79.666667%\n",
      "  Batch   478/  600 - avrg_Loss: 0.582335  processed_samples: 79.833333%\n",
      "  Batch   479/  600 - avrg_Loss: 0.582307  processed_samples: 80.000000%\n",
      "  Batch   480/  600 - avrg_Loss: 0.582370  processed_samples: 80.166667%\n",
      "  Batch   481/  600 - avrg_Loss: 0.582401  processed_samples: 80.333333%\n",
      "  Batch   482/  600 - avrg_Loss: 0.582398  processed_samples: 80.500000%\n",
      "  Batch   483/  600 - avrg_Loss: 0.582367  processed_samples: 80.666667%\n",
      "  Batch   484/  600 - avrg_Loss: 0.582390  processed_samples: 80.833333%\n",
      "  Batch   485/  600 - avrg_Loss: 0.582400  processed_samples: 81.000000%\n",
      "  Batch   486/  600 - avrg_Loss: 0.582407  processed_samples: 81.166667%\n",
      "  Batch   487/  600 - avrg_Loss: 0.582394  processed_samples: 81.333333%\n",
      "  Batch   488/  600 - avrg_Loss: 0.582376  processed_samples: 81.500000%\n",
      "  Batch   489/  600 - avrg_Loss: 0.582359  processed_samples: 81.666667%\n",
      "  Batch   490/  600 - avrg_Loss: 0.582371  processed_samples: 81.833333%\n",
      "  Batch   491/  600 - avrg_Loss: 0.582414  processed_samples: 82.000000%\n",
      "  Batch   492/  600 - avrg_Loss: 0.582471  processed_samples: 82.166667%\n",
      "  Batch   493/  600 - avrg_Loss: 0.582459  processed_samples: 82.333333%\n",
      "  Batch   494/  600 - avrg_Loss: 0.582476  processed_samples: 82.500000%\n",
      "  Batch   495/  600 - avrg_Loss: 0.582476  processed_samples: 82.666667%\n",
      "  Batch   496/  600 - avrg_Loss: 0.582489  processed_samples: 82.833333%\n",
      "  Batch   497/  600 - avrg_Loss: 0.582492  processed_samples: 83.000000%\n",
      "  Batch   498/  600 - avrg_Loss: 0.582517  processed_samples: 83.166667%\n",
      "  Batch   499/  600 - avrg_Loss: 0.582546  processed_samples: 83.333333%\n",
      "  Batch   500/  600 - avrg_Loss: 0.582507  processed_samples: 83.500000%\n",
      "  Batch   501/  600 - avrg_Loss: 0.582537  processed_samples: 83.666667%\n",
      "  Batch   502/  600 - avrg_Loss: 0.582507  processed_samples: 83.833333%\n",
      "  Batch   503/  600 - avrg_Loss: 0.582494  processed_samples: 84.000000%\n",
      "  Batch   504/  600 - avrg_Loss: 0.582525  processed_samples: 84.166667%\n",
      "  Batch   505/  600 - avrg_Loss: 0.582484  processed_samples: 84.333333%\n",
      "  Batch   506/  600 - avrg_Loss: 0.582398  processed_samples: 84.500000%\n",
      "  Batch   507/  600 - avrg_Loss: 0.582385  processed_samples: 84.666667%\n",
      "  Batch   508/  600 - avrg_Loss: 0.582405  processed_samples: 84.833333%\n",
      "  Batch   509/  600 - avrg_Loss: 0.582345  processed_samples: 85.000000%\n",
      "  Batch   510/  600 - avrg_Loss: 0.582298  processed_samples: 85.166667%\n",
      "  Batch   511/  600 - avrg_Loss: 0.582273  processed_samples: 85.333333%\n",
      "  Batch   512/  600 - avrg_Loss: 0.582253  processed_samples: 85.500000%\n",
      "  Batch   513/  600 - avrg_Loss: 0.582235  processed_samples: 85.666667%\n",
      "  Batch   514/  600 - avrg_Loss: 0.582201  processed_samples: 85.833333%\n",
      "  Batch   515/  600 - avrg_Loss: 0.582204  processed_samples: 86.000000%\n",
      "  Batch   516/  600 - avrg_Loss: 0.582153  processed_samples: 86.166667%\n",
      "  Batch   517/  600 - avrg_Loss: 0.582177  processed_samples: 86.333333%\n",
      "  Batch   518/  600 - avrg_Loss: 0.582148  processed_samples: 86.500000%\n",
      "  Batch   519/  600 - avrg_Loss: 0.582154  processed_samples: 86.666667%\n",
      "  Batch   520/  600 - avrg_Loss: 0.582111  processed_samples: 86.833333%\n",
      "  Batch   521/  600 - avrg_Loss: 0.582108  processed_samples: 87.000000%\n",
      "  Batch   522/  600 - avrg_Loss: 0.582115  processed_samples: 87.166667%\n",
      "  Batch   523/  600 - avrg_Loss: 0.582103  processed_samples: 87.333333%\n",
      "  Batch   524/  600 - avrg_Loss: 0.582079  processed_samples: 87.500000%\n",
      "  Batch   525/  600 - avrg_Loss: 0.582079  processed_samples: 87.666667%\n",
      "  Batch   526/  600 - avrg_Loss: 0.582081  processed_samples: 87.833333%\n",
      "  Batch   527/  600 - avrg_Loss: 0.582056  processed_samples: 88.000000%\n",
      "  Batch   528/  600 - avrg_Loss: 0.582035  processed_samples: 88.166667%\n",
      "  Batch   529/  600 - avrg_Loss: 0.582011  processed_samples: 88.333333%\n",
      "  Batch   530/  600 - avrg_Loss: 0.582020  processed_samples: 88.500000%\n",
      "  Batch   531/  600 - avrg_Loss: 0.582017  processed_samples: 88.666667%\n",
      "  Batch   532/  600 - avrg_Loss: 0.582035  processed_samples: 88.833333%\n",
      "  Batch   533/  600 - avrg_Loss: 0.581971  processed_samples: 89.000000%\n",
      "  Batch   534/  600 - avrg_Loss: 0.581970  processed_samples: 89.166667%\n",
      "  Batch   535/  600 - avrg_Loss: 0.581967  processed_samples: 89.333333%\n",
      "  Batch   536/  600 - avrg_Loss: 0.581915  processed_samples: 89.500000%\n",
      "  Batch   537/  600 - avrg_Loss: 0.581934  processed_samples: 89.666667%\n",
      "  Batch   538/  600 - avrg_Loss: 0.581932  processed_samples: 89.833333%\n",
      "  Batch   539/  600 - avrg_Loss: 0.581932  processed_samples: 90.000000%\n",
      "  Batch   540/  600 - avrg_Loss: 0.581926  processed_samples: 90.166667%\n",
      "  Batch   541/  600 - avrg_Loss: 0.581935  processed_samples: 90.333333%\n",
      "  Batch   542/  600 - avrg_Loss: 0.581935  processed_samples: 90.500000%\n",
      "  Batch   543/  600 - avrg_Loss: 0.581955  processed_samples: 90.666667%\n",
      "  Batch   544/  600 - avrg_Loss: 0.581929  processed_samples: 90.833333%\n",
      "  Batch   545/  600 - avrg_Loss: 0.581962  processed_samples: 91.000000%\n",
      "  Batch   546/  600 - avrg_Loss: 0.581949  processed_samples: 91.166667%\n",
      "  Batch   547/  600 - avrg_Loss: 0.582001  processed_samples: 91.333333%\n",
      "  Batch   548/  600 - avrg_Loss: 0.581988  processed_samples: 91.500000%\n",
      "  Batch   549/  600 - avrg_Loss: 0.581988  processed_samples: 91.666667%\n",
      "  Batch   550/  600 - avrg_Loss: 0.581948  processed_samples: 91.833333%\n",
      "  Batch   551/  600 - avrg_Loss: 0.581937  processed_samples: 92.000000%\n",
      "  Batch   552/  600 - avrg_Loss: 0.581935  processed_samples: 92.166667%\n",
      "  Batch   553/  600 - avrg_Loss: 0.581906  processed_samples: 92.333333%\n",
      "  Batch   554/  600 - avrg_Loss: 0.581908  processed_samples: 92.500000%\n",
      "  Batch   555/  600 - avrg_Loss: 0.581906  processed_samples: 92.666667%\n",
      "  Batch   556/  600 - avrg_Loss: 0.581904  processed_samples: 92.833333%\n",
      "  Batch   557/  600 - avrg_Loss: 0.581921  processed_samples: 93.000000%\n",
      "  Batch   558/  600 - avrg_Loss: 0.581924  processed_samples: 93.166667%\n",
      "  Batch   559/  600 - avrg_Loss: 0.581930  processed_samples: 93.333333%\n",
      "  Batch   560/  600 - avrg_Loss: 0.581901  processed_samples: 93.500000%\n",
      "  Batch   561/  600 - avrg_Loss: 0.581888  processed_samples: 93.666667%\n",
      "  Batch   562/  600 - avrg_Loss: 0.581870  processed_samples: 93.833333%\n",
      "  Batch   563/  600 - avrg_Loss: 0.581871  processed_samples: 94.000000%\n",
      "  Batch   564/  600 - avrg_Loss: 0.581860  processed_samples: 94.166667%\n",
      "  Batch   565/  600 - avrg_Loss: 0.581821  processed_samples: 94.333333%\n",
      "  Batch   566/  600 - avrg_Loss: 0.581854  processed_samples: 94.500000%\n",
      "  Batch   567/  600 - avrg_Loss: 0.581845  processed_samples: 94.666667%\n",
      "  Batch   568/  600 - avrg_Loss: 0.581832  processed_samples: 94.833333%\n",
      "  Batch   569/  600 - avrg_Loss: 0.581864  processed_samples: 95.000000%\n",
      "  Batch   570/  600 - avrg_Loss: 0.581886  processed_samples: 95.166667%\n",
      "  Batch   571/  600 - avrg_Loss: 0.581882  processed_samples: 95.333333%\n",
      "  Batch   572/  600 - avrg_Loss: 0.581909  processed_samples: 95.500000%\n",
      "  Batch   573/  600 - avrg_Loss: 0.581926  processed_samples: 95.666667%\n",
      "  Batch   574/  600 - avrg_Loss: 0.581891  processed_samples: 95.833333%\n",
      "  Batch   575/  600 - avrg_Loss: 0.581887  processed_samples: 96.000000%\n",
      "  Batch   576/  600 - avrg_Loss: 0.581854  processed_samples: 96.166667%\n",
      "  Batch   577/  600 - avrg_Loss: 0.581879  processed_samples: 96.333333%\n",
      "  Batch   578/  600 - avrg_Loss: 0.581899  processed_samples: 96.500000%\n",
      "  Batch   579/  600 - avrg_Loss: 0.581891  processed_samples: 96.666667%\n",
      "  Batch   580/  600 - avrg_Loss: 0.581875  processed_samples: 96.833333%\n",
      "  Batch   581/  600 - avrg_Loss: 0.581884  processed_samples: 97.000000%\n",
      "  Batch   582/  600 - avrg_Loss: 0.581864  processed_samples: 97.166667%\n",
      "  Batch   583/  600 - avrg_Loss: 0.581875  processed_samples: 97.333333%\n",
      "  Batch   584/  600 - avrg_Loss: 0.581877  processed_samples: 97.500000%\n",
      "  Batch   585/  600 - avrg_Loss: 0.581893  processed_samples: 97.666667%\n",
      "  Batch   586/  600 - avrg_Loss: 0.581899  processed_samples: 97.833333%\n",
      "  Batch   587/  600 - avrg_Loss: 0.581872  processed_samples: 98.000000%\n",
      "  Batch   588/  600 - avrg_Loss: 0.581880  processed_samples: 98.166667%\n",
      "  Batch   589/  600 - avrg_Loss: 0.581898  processed_samples: 98.333333%\n",
      "  Batch   590/  600 - avrg_Loss: 0.581903  processed_samples: 98.500000%\n",
      "  Batch   591/  600 - avrg_Loss: 0.581902  processed_samples: 98.666667%\n",
      "  Batch   592/  600 - avrg_Loss: 0.581938  processed_samples: 98.833333%\n",
      "  Batch   593/  600 - avrg_Loss: 0.581871  processed_samples: 99.000000%\n",
      "  Batch   594/  600 - avrg_Loss: 0.581857  processed_samples: 99.166667%\n",
      "  Batch   595/  600 - avrg_Loss: 0.581841  processed_samples: 99.333333%\n",
      "  Batch   596/  600 - avrg_Loss: 0.581860  processed_samples: 99.500000%\n",
      "  Batch   597/  600 - avrg_Loss: 0.581843  processed_samples: 99.666667%\n",
      "  Batch   598/  600 - avrg_Loss: 0.581815  processed_samples: 99.833333%\n",
      "  Batch   599/  600 - avrg_Loss: 0.581831  processed_samples: 100.000000%\n",
      "@eval_loop_avg_loss=0.580431\n",
      "@eval_loop_avg_loss=0.578471\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "#5.8) y 5.9)\n",
    "num_epochs = 30\n",
    "list_train_avg_loss_incorrecta = []\n",
    "list_train_avg_loss = []\n",
    "list_valid_avg_loss = []\n",
    "list_train_precisiom_incorrecta = []\n",
    "list_train_precision = []\n",
    "list_valid_precision = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\\n-------------------------------\")\n",
    "    train_avg_loss_incorrecta = train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    train_avg_loss = valid_loop(train_loader, model, loss_fn)\n",
    "    valid_avg_loss = valid_loop(valid_loader, model, loss_fn)\n",
    "\n",
    "    list_train_avg_loss_incorrecta.append(train_avg_loss_incorrecta)\n",
    "\n",
    "    list_train_avg_loss.append(train_avg_loss)\n",
    "    list_valid_avg_loss.append(valid_avg_loss)\n",
    "\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado como: model_20251209_000451.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#cargamos el modelo guardado\\nmodel = NeuralNetwork(128, 0.2)\\nnombre = \"./TP_FINAL/caso02/caso02.pth\"\\nmodel.load_state_dict(torch.load(nombre))\\nmodel = model.to(device)\\nmodel.eval()'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"model_{timestamp}.pth\"\n",
    "torch.save(model.state_dict(), filename)\n",
    "print(\"Guardado como:\", filename)\n",
    "'''\n",
    "#cargamos el modelo guardado\n",
    "model = NeuralNetwork(128, 0.2)\n",
    "nombre = \"./TP_FINAL/caso02/caso02.pth\"\n",
    "model.load_state_dict(torch.load(nombre))\n",
    "model = model.to(device)\n",
    "model.eval()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# probando la red entrenada con un ejemplito\n",
    "numero_img = 0\n",
    "imgs_before = []\n",
    "imgs_after = []\n",
    "for i in range(5):  # Cambiamos el rango para probar varias imágenes\n",
    "    dataiter = iter(valid_loader)\n",
    "    images, labels = next(dataiter)\n",
    "\n",
    "    img = images[numero_img]  # Agregar dimensión de batch\n",
    "    imgs_before.append(img.cpu().squeeze())\n",
    "    # Pasar la imagen por el modelo\n",
    "    with torch.no_grad():\n",
    "        img = img.to(device)\n",
    "        output = model(img.unsqueeze(0))  # Agregar dimensión de batch\n",
    "        imgs_after.append(output.cpu().squeeze())\n",
    "\n",
    "#comparacion imagen original vs reconstruida\n",
    "#imagen:\n",
    "figure = plt.figure()\n",
    "#ajustamos el tamaño de la figura\n",
    "figure.set_size_inches(10, 5)  # Ajusta el tamaño de la figura\n",
    "cols,rows = 5,2\n",
    "#graficamos arriba las 5 figuras originales y abajo las 5 reconstruidas\n",
    "for i in range(len(imgs_before)):\n",
    "    figure.add_subplot(rows,cols,i+1)\n",
    "    plt.imshow(imgs_before[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "for i in range(len(imgs_after)):\n",
    "    figure.add_subplot(rows,cols,i+1+5)  # Agregamos las imágenes reconstruidas en la segunda fila\n",
    "    plt.imshow(imgs_after[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nplt.xlabel(\"Epoch\")\\nplt.ylabel(\"Precision\")\\nplt.plot(range(1,len(list_train_precisiom_incorrecta)+1),  list_train_precisiom_incorrecta, label=\"Train Precision Incorrecta\",linestyle=\\'-\\', c=\\'red\\')\\nplt.plot(range(1,len(list_train_precision)+1),  list_train_precision, label=\"Train Precision\",linestyle=\\'-\\', c=\\'green\\')\\nplt.plot(range(1,len(list_valid_precision)+1), list_valid_precision, label=\"Valid Precision\",linestyle=\\'--\\', c=\\'blue\\')\\nplt.legend()\\n#plt.title(\"\")\\nplt.show() '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.10)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.plot(range(1,len(list_train_avg_loss_incorrecta)+1), list_train_avg_loss_incorrecta, label=\"Train Loss Incorrecta\",linestyle='-', c='red')\n",
    "plt.plot(range(1,len(list_train_avg_loss)+1), list_train_avg_loss, label=\"Train Loss\",linestyle='-.', c='green')\n",
    "plt.plot(range(1,len(list_valid_avg_loss)+1), list_valid_avg_loss, label=\"Valid Loss\",linestyle='--', c='blue')\n",
    "plt.legend()\n",
    "#plt.title(\"\")\n",
    "plt.show()\n",
    "'''\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.plot(range(1,len(list_train_precisiom_incorrecta)+1),  list_train_precisiom_incorrecta, label=\"Train Precision Incorrecta\",linestyle='-', c='red')\n",
    "plt.plot(range(1,len(list_train_precision)+1),  list_train_precision, label=\"Train Precision\",linestyle='-', c='green')\n",
    "plt.plot(range(1,len(list_valid_precision)+1), list_valid_precision, label=\"Valid Precision\",linestyle='--', c='blue')\n",
    "plt.legend()\n",
    "#plt.title(\"\")\n",
    "plt.show() '''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
