{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRYEofSD0xoF"
   },
   "source": [
    "# Aprendiendo Fashion-MNIST con PyTorch\n",
    "\n",
    "## Refs.\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "\n",
    "* https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "* https://github.com/pranay414/Fashion-MNIST-Pytorch/blob/master/fashion_mnist.ipynb\n",
    "\n",
    "## **Ejercicio 1)** Importando librerías\n",
    "\n",
    "**0)** De ser necesario, **instale PyTorch** escribiendo\n",
    "\n",
    "    !pip3 install torch torchvision torchaudio torchviz\n",
    "\n",
    "**1)** Importe las librerías estandard de Python: `os`, `datetime`, `collections` y `pickle`.\n",
    "\n",
    "**2)** Importe las siguientes librerías third party de Python: `matplotlib.pyplot`, `numpy`, `scipy`, `sklearn`, `pandas`, `dill` y `json`.\n",
    "\n",
    "**3)** Importe las librerias necesarias de **PyTorch**: `torch` y `torchvision`.\n",
    "\n",
    "**4)** Importe la librería: `google.colab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D79v2F3-s7vu",
    "outputId": "ff535901-d1c7-4a5a-8c11-d22d452985d3"
   },
   "outputs": [],
   "source": [
    "# 1.0)\n",
    "!pip3 install torch torchvision torchaudio torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8N3D_nU1_oT"
   },
   "outputs": [],
   "source": [
    "# 1.1)\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QsfFvPYhkCGl"
   },
   "outputs": [],
   "source": [
    "# 1.2)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg as linalg\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "#import dill\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uot5sVNnkCNa"
   },
   "outputs": [],
   "source": [
    "# 1.3)\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "#from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVCiYt-1kCUi"
   },
   "outputs": [],
   "source": [
    "# 1.4)\n",
    "#import google.colab\n",
    "#from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcaGEHAd10sb"
   },
   "source": [
    "## **Ejercicio 2)**\n",
    "\n",
    "Bajando y Jugando con el dataset **Fashion-MNIST**.\n",
    "\n",
    "**1)** Baje y transforme (i.e. normalize los valores de los pixeles) los conjuntos de entrenamiento y testeo de FashionMNIST.\n",
    "\n",
    "**2)** Explore algunos ejemplos de estos conjuntos. Que formato poseen?\n",
    "\n",
    "**3)** Visitando la página web de FashionMNIST, cree un diccionario de Python `Dict()` asociando cada categoría a un nombre adecuado de la misma.\n",
    "\n",
    "**4)** Grafique un mosaico de 3x3 imagenes de FashionMNIST, cada una titulada con su respectiva clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUoQ9bnwaZ7O",
    "outputId": "d6389205-99a6-43d1-b620-e7de4f58808b"
   },
   "outputs": [],
   "source": [
    "# 2.1)\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor()\n",
    "                                ,transforms.Normalize((0.5,), (0.5,))\n",
    "                                #,transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                               ])\n",
    "\n",
    "# Download and load the training data\n",
    "train_set = datasets.FashionMNIST('MNIST_data/', download = True, train = True,  transform = transform)\n",
    "valid_set = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)\n",
    "\n",
    "# Los dataset son como listas que contienen en cada posicion una imagen y su label asociado. \n",
    "# La diferencia con las listas es que los dataset tienen metodos adicionales para facilitar su uso en deep learning. \n",
    "# Si quisieramos iterar un dataset sin un dataloader, tendriamos que hacer algo como:\n",
    "# for i in range(len(train_set)):\n",
    "#     image, label = train_set[i]\n",
    "# En realidad no es una lista, es una clase que implementa los metodos __len__ y __getitem__ para poder acceder a sus elementos como si fuera una lista. \n",
    "# Lista con esteroides. Permite cargar y transformar datos de manera eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 \n",
    "i = 600\n",
    "img, label = train_set[i]\n",
    "\n",
    "#2.3\n",
    "label_dict = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}\n",
    "\n",
    "# Como tiene forma [1, 28, 28], quitamos la dimensión del canal\n",
    "\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.title(f\"Etiqueta: {label_dict[label]}\")\n",
    "plt.show()\n",
    "print(f\"Forma del tensor de la imagen: {img.shape}\")\n",
    "#img tiene shape [C, H, W]. Si C = 1 sólo existe img[0], \n",
    "# para acceder a un píxel: img[0, y, x].\n",
    "#cuando es rgb es como si tuvieras 3 matrices, una por canal, \n",
    "# cada una de ellas indica la cantidad de cada color en cada píxel.\n",
    "#como aca hay un solo canal, ya que es escala de grises, hay una dimension innecesaria.\n",
    "#por eso se usa squeeze, para eliminar dimensiones de tamaño 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#2.4\n",
    "#mosaico 3x3 de imagenes random\n",
    "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "for ax in axes.flatten():\n",
    "    i = np.random.randint(len(train_set))\n",
    "    img, label = train_set[i]\n",
    "    ax.imshow(img.squeeze(), cmap='gray')\n",
    "    ax.set_title(f\"{label_dict[label]}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OWYnfxWz8RS"
   },
   "source": [
    "## Ejercicio 3)\n",
    "\n",
    "Creando un `DataLoader` para alimentar el modelo con batchs (lotes) de entrenamiento.\n",
    "\n",
    "**1)** Cree los `DataLoader`s para cada conjunto. Defínalos con un `batch_size` de 100 y con el flag `shuffle` seteado a `True`.\n",
    "\n",
    "**2)** Use uno de los `DataLoader`s creados anteriormente para explorar algunos elementos del conjunto.\n",
    "\n",
    "Notar que, el iterador devuelve el batch en un par `(image,label)`.\n",
    "\n",
    "El objeto `images` es un tensor de dimensiones `(100,1,28,28)`.\n",
    "El 100 es el tamaño del batch.\n",
    "El 1 porque hay un solo canal (en este caso, un canal de escala de grises, pero podría haber varios, p. ej. uno por cada color de {Red, Green Blue} en caso que fuesen imagenes a color).\n",
    "Luego, 28 y 28 porque cada imagen del dataset es de 28 x 28 píxeles.\n",
    "\n",
    "El objeto `labels` es un tensor de dimensiones `(100,)`.\n",
    "La $i$-ésima entrada `labels[i]` de `labels` es un número en $\\{0,1,...,9\\}$ indicando la categoría a la que pertenece la $i$-ésima imagen en el batch, guardada en `images[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lK7gqh7lrTi8"
   },
   "outputs": [],
   "source": [
    "# 3.1)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 100, shuffle = True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size = 100, shuffle = True)\n",
    "\n",
    "#Un dataloader empaqueta el dataset en batches, permite aleatorizacion y mayor eficiencia, dejando una estructura iterable por batches.\n",
    "# es como una estructura que tiene en cada \"slot\"(que representaria un batch) un tensor con imagenes y otro con labels\n",
    "#osea que por ejemplo en la primer posicion de la estructura tendrias 100 imagenes y 100 labels del primer batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" num_samples : {len(train_loader.dataset)}\")\n",
    "print(f\" num_batches : {len(train_loader)}\")\n",
    "dataiter = iter(train_loader)\n",
    "#si shuffle esta en false da siempre lo mismo, porque siempre creo el iterador \n",
    "# de nuevo. Si no, como shuffle los crea distinto cada vez, da distinto.\n",
    "# next(dataiter) # si pongo esto antes, entonces muestro el segundo\n",
    "images, labels = next(dataiter)\n",
    "print(f\"Forma del batch de imágenes: {images.shape}\")\n",
    "print(f\"Forma del batch de etiquetas: {labels.shape}\")\n",
    "\n",
    "#img example\n",
    "img = images[0]  # Agregar dimensión de batch\n",
    "label = label_dict[labels[0].item()]\n",
    "\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.title(f\"Etiqueta: {label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REToccG127zI"
   },
   "source": [
    "## Ejercicio 4)\n",
    "\n",
    "Defina una red neuronal de 4 capas, una de entrada, dos ocultas de $n_1=128$ y $n_2=64$ neuronas, respectivamente, y una de salida de 10 neuronas.\n",
    "\n",
    "En las capas intermedias utilice neuronas tipo ReLU y agregueles un *dropout* de p=0.2.\n",
    "En la capa de salida no utilice funciones de activación ni dropout.\n",
    "\n",
    "Las capas sucesivas tienen que estar totalmente conectadas entre si."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C17Tib9G_k-q"
   },
   "outputs": [],
   "source": [
    "# 4)\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,n1,n2,p=0.2):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        #capa0\n",
    "        self.flatten = nn.Flatten() \n",
    "\n",
    "        #capa 1\n",
    "        self.fc1 = nn.Linear(28*28,n1)  \n",
    "        self.relu = nn.ReLU() #modulo relu1\n",
    "        self.dropout = nn.Dropout(p) #modulo dropout1\n",
    "\n",
    "        #capa2\n",
    "        self.fc2 = nn.Linear(n1,n2)      #capa 2\n",
    "        #self.relu2 = nn.ReLU()           #modulo relu2 (se reutilizan las del 1 asi q las comento)\n",
    "        #self.dropout2 = nn.Dropout(p)    #modulo dropout2\n",
    "\n",
    "        #capa3\n",
    "        self.fc3 = nn.Linear(n2,10)     #capa 3\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #capa0\n",
    "        x = self.flatten(x)\n",
    "        #capa1\n",
    "        x = self.fc1(x)             \n",
    "        x = self.relu(x)            #modulo relu1\n",
    "        x = self.dropout(x)         #modulo dropout1\n",
    "        #capa2\n",
    "        x = self.fc2(x)             \n",
    "        x = self.relu(x)            #modulo relu2\n",
    "        x = self.dropout(x)         #modulo dropout2\n",
    "        #capa3\n",
    "        x = self.fc3(x)             \n",
    "        return x\n",
    "\n",
    "mi_red = NeuralNetwork(128,64,p=0.2)\n",
    "mi_red(img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9uINlg69OTw"
   },
   "source": [
    "## Ejercicio 5)\n",
    "\n",
    "Entrenamos el modelo\n",
    "\n",
    "**1)** Implemente, en una función, un loop de entrenamiento que recorra los batchs (lotes).\n",
    "\n",
    "**2)** Implemente, en una función, un loop de validación que recorra los batchs.\n",
    "\n",
    "**3)** Inicialize dos `DataLoader`s llamados `train_loader` y `valid_loader` a partir del `train_set` (conjunto de entranmiento) y del `valid_set` (conjunto de validación) de Fashion-MNIST, respectivamente, y que usen batchs de 100 ejemplos.\n",
    "\n",
    "**4)** Cree una función de pérdida usando la **Cross Entropy Loss**.\n",
    "\n",
    "**IMPORTANTE:** Notar que la **Cross Entropy Loss** aplica automáticamente una `log_softmax`.\n",
    "\n",
    "**5)** Cree un optimizador que utilice el método de **Stochastic Gradient Descent** con un learning rate igual a $10^{-3}$.\n",
    "\n",
    "**6)** Cree una instancia del modelo.\n",
    "\n",
    "**7)** Especifique en que dispositivo (`device`) va a trabajar: en una **CPU** o en una **GPU**.\n",
    "\n",
    "**8)** Implemente un loop de entrenamiento y validación que trabaje con el `train_loader` y el `valid_loader`, respectivamente, usando un numero arbitrario de épocas.\n",
    "Este loop debe guardar en cuatro listas los valores de los promedios del **Cross Entropy Loss** y las fracciones de clasificaciones correctas o **precisión** (accuracy) sobre el conjunto de **entrenamiento** y el de **validación**, respectivamente.\n",
    "\n",
    "**IMPORTANTE:** No olvide copiar los batchs al dispositivo de trabajo.\n",
    "\n",
    "**9)** Entrene y valide el modelo.\n",
    "\n",
    "**10)** Use las listas del inciso anterior para graficar en función de las épocas la **Cross Entropy Loss** de **entrenamiento** y de **validación**.\n",
    "Realize un gráfico análogo pero con la **precisión**.\n",
    "Discuta y comente, cual es el número óptimo de épocas de entrenamiento?\n",
    "\n",
    "**11)** Repita los experimentos variando hiperparámetros. Por ejemplo:\n",
    "\n",
    "- El learning-rate.\n",
    "- El optimizador (ej. puede usar ADAM).\n",
    "- El valor de dropout.\n",
    "- El número de neuronas en las capas intermedias.\n",
    "- El número de épocas de entrenamiento.\n",
    "- El tamaño de los lotes.\n",
    "\n",
    "Discuta los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyuXv-0x29Xw"
   },
   "outputs": [],
   "source": [
    "# 5.1)\n",
    "def train_loop(dataloader,model,loss_fn,optimizer):\n",
    "    model.train()\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    sum_loss = 0\n",
    "    sum_correct = 0\n",
    "    sum_samples = 0\n",
    "    for batch, (X,y) in enumerate(dataloader): \n",
    "        #enumerate devuelve una lista de tuplas (indice, valor), entonces al hacer\n",
    "        # for batch, (X,y) desestructura la tupla en indice(batch) y valor(X(imagenes), y(etiquetas))\n",
    "\n",
    "        # Copiamos las salidas y entradas al dispositivo de trabajo\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        batch_size = len(X)\n",
    "        # calculamos la perdida promedio del batch y lo agregamos a una suma correspondiente\n",
    "        sum_loss += loss.item() * batch_size # loss = suma de perdidas en el batch / batch_size => loss.item() * batch_size = suma de perdidas en el batch\n",
    "\n",
    "        # calculamos la cantidad de predicciones correctas en el batch y lo agregamos a una suma correspondiente\n",
    "        sum_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        # actualizamos la cantidad de muestras procesadas\n",
    "        sum_samples += batch_size\n",
    "\n",
    "        \n",
    "        if batch % (num_batches / 10) == 0: # evaluamos en el 10% de los batches, para no saturar\n",
    "            avrg_loss = sum_loss / sum_samples\n",
    "            precision = sum_correct / sum_samples\n",
    "            print(f\"  Batch {batch:>5d}/{num_batches:>5d} - avrg_Loss: {avrg_loss:>7f}  processed_samples: {100*sum_samples/num_samples:>5f}%\") #5d ?\n",
    "        \n",
    "    assert num_samples == sum_samples, \"Error en el conteo de muestras procesadas\"\n",
    "    avrg_loss = sum_loss / sum_samples\n",
    "    precision = sum_correct / sum_samples\n",
    "\n",
    "    return avrg_loss, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2)\n",
    "def valid_loop(dataloader,model,loss_fn):\n",
    "    model.eval()\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    sum_loss = 0\n",
    "    sum_correct = 0\n",
    "    sum_samples = 0\n",
    "    with torch.no_grad(): # es un context manager que desactiva el cálculo del gradiente momentáneamente, \n",
    "        #para ahorrar memoria y mejorar el rendimiento durante la evaluación del modelo.\n",
    "\n",
    "        for X,y in dataloader: #iteramos sobre los batches del dataloader, esto es posible ya que si bien dataloader no es una lista,\n",
    "            # implementa el protocolo iterable de python, por lo que se puede usar en un for, y en cada iteracion genera un batch nuevo\n",
    "\n",
    "            # Copiamos las salidas y entradas al dispositivo de trabajo\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            batch_size = len(X)\n",
    "            sum_samples += batch_size\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            sum_loss += loss.item() * batch_size\n",
    "            sum_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    assert num_samples == sum_samples, \"Error en el conteo de muestras procesadas\"\n",
    "    avrg_loss = sum_loss / sum_samples\n",
    "    precision = sum_correct / sum_samples\n",
    "    print(f\"@eval_loop_avg_loss={avrg_loss:>8f}  precision={100*precision:0.1f}%\")\n",
    "\n",
    "    return avrg_loss, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(dataloader, model, loss_fn):\n",
    "    \"\"\"\n",
    "    Evaluates model performance on a dataset\n",
    "\n",
    "    Args:\n",
    "        dataloader: PyTorch DataLoader with validation/test data\n",
    "        model: Neural network model\n",
    "        loss_fn: Loss function\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy)\n",
    "    \"\"\"\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # Disable gradient computation for efficiency\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # Move data to correct device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            pred = model(X)\n",
    "\n",
    "            # Accumulate batch loss\n",
    "            total_loss += loss_fn(pred, y).item() * len(X)\n",
    "\n",
    "            # Count correct predictions\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_loss = total_loss / size\n",
    "    accuracy = correct / size\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3)\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.4)\n",
    "#Creamos una instancia de una funcion de perdida, en este caso Cross Entropy Loss\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.6)\n",
    "#valores segun ej4\n",
    "n1 = 128\n",
    "n2 = 64\n",
    "p = 0.2\n",
    "model = NeuralNetwork(n1,n2,p = p)\n",
    "\n",
    "#5.5)\n",
    "#definimos el optimizador, en este caso SGD\n",
    "learning_rate = 1e-2\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate,eps=1e-08,weight_decay=0,amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.7)\n",
    "#definimos el dispositivo de trabajo, una cpu o una gpu si esta disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#pasamos el modelo al dispositivo\n",
    "model = model.to(device)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.8) y 5.9)\n",
    "num_epochs = 30\n",
    "list_train_avg_loss_incorrecta = []\n",
    "list_train_avg_loss = []\n",
    "list_valid_avg_loss = []\n",
    "list_train_precisiom_incorrecta = []\n",
    "list_train_precision = []\n",
    "list_valid_precision = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\\n-------------------------------\")\n",
    "    train_avg_loss_incorrecta, train_precision_incorrecta = train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    train_avg_loss, train_precision = valid_loop(train_loader, model, loss_fn)\n",
    "    valid_avg_loss, valid_precision = valid_loop(valid_loader, model, loss_fn)\n",
    "\n",
    "    list_train_avg_loss_incorrecta.append(train_avg_loss_incorrecta)\n",
    "    list_train_precisiom_incorrecta.append(train_precision_incorrecta)\n",
    "\n",
    "    list_train_avg_loss.append(train_avg_loss)\n",
    "    list_valid_avg_loss.append(valid_avg_loss)\n",
    "\n",
    "    list_train_precision.append(train_precision)\n",
    "    list_valid_precision.append(valid_precision)\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probando la red entrenada con un ejemplito\n",
    "dataiter = iter(valid_loader)\n",
    "images, labels = next(dataiter)\n",
    "numero_img = 16\n",
    "img = images[numero_img]  # Agregar dimensión de batch\n",
    "label = labels[numero_img].item()\n",
    "# Pasar la imagen por el modelo\n",
    "with torch.no_grad():\n",
    "    img = img.to(device)\n",
    "    output = model(img.unsqueeze(0))  # Agregar dimensión de batch\n",
    "    predicted_label = output.argmax(1).item()\n",
    "\n",
    "#imagen:\n",
    "plt.imshow(img.cpu().squeeze(), cmap='gray')\n",
    "plt.title(f\"Etiqueta real: {label_dict[label]}\\nEtiqueta predicha: {label_dict[predicted_label]}\")\n",
    "plt.show()\n",
    "\n",
    "img.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora saque una imagen random que creo gemini de una bota y voy  a ver que dice el modelo que es\n",
    "from PIL import Image\n",
    "# 1. Definir la ruta de la imagen (ajusta esto si estás en Colab/local)\n",
    "# Nota: Si la imagen está guardada en tu entorno de trabajo\n",
    "image_path = \"commonsneaker.jpg\" \n",
    "\n",
    "# 2. Definir las transformaciones necesarias\n",
    "# Tienes que replicar las transformaciones que usaste en tu dataset de entrenamiento\n",
    "transform = transforms.Compose([\n",
    "    # Asegura que esté en escala de grises (1 canal)\n",
    "    transforms.Grayscale(num_output_channels=1), \n",
    "    # Asegura el tamaño (aunque ya sea 28x28)\n",
    "    transforms.Resize((28, 28)), \n",
    "    # Convierte la imagen a tensor (el valor va de [0, 255] a [0.0, 1.0])\n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "# 3. Cargar y transformar\n",
    "try:\n",
    "    img = Image.open(image_path)\n",
    "    input_tensor = transform(img)\n",
    "\n",
    "    print(f\"Tensor de entrada listo. Dimensiones: {input_tensor.shape}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: No se encontró el archivo en {image_path}. Asegúrate de guardar la imagen primero.\")\n",
    "\n",
    "\n",
    "plt.imshow(input_tensor.squeeze(), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "# Mueve el tensor de entrada al dispositivo\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "# Poner el modelo en modo de evaluación\n",
    "model.eval() \n",
    "\n",
    "# 5. Obtener la predicción\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor.unsqueeze(0))\n",
    "    #predicted_label = output.argmax(1).item()\n",
    "\n",
    "# 6. Interpretar la salida\n",
    "# La salida es un tensor de 10 valores (los logits).\n",
    "# Aplicamos softmax para obtener probabilidades y argmax para la clase con mayor probabilidad.\n",
    "probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "predicted_class = probabilities.argmax(1).item()\n",
    "confidence = probabilities.max(1)[0].item()\n",
    "\n",
    "print(\"\\n--- Resultados de la Predicción ---\")\n",
    "print(f\"Probabilidades (logits): {output.squeeze().tolist()}\")\n",
    "print(f\"Clase Predicha (Índice): {predicted_class}\")\n",
    "print(f\"Confianza: {confidence * 100:.2f}%\")\n",
    "\n",
    "\n",
    "print(f\"Predicción: {label_dict[predicted_class]}\")\n",
    "\n",
    "#print(f\"predicted_label = {label_dict[predicted_label]}\")\n",
    "\n",
    "\n",
    "#Logits : salidas directas, sin procesar, de la capa final de la red neuronal (que tiene 10 salidas).Son valores que representan el puntaje que el modelo calcula para cada label.\n",
    "#softmax transforma logits a probabilidades\n",
    "# la confianza es el porcentaje que da la salida mas alta, si el porcentaje es bajo es porque las otras salidas tambien tienen \"una proporcion significativa de probabilidad de ser correctas\"\n",
    "#cuando eso pasa tiene sentido que sea menos confiable\n",
    "#asi que la confiabilidad es basicamente el porcentaje del valor que dio mas alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.10)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.plot(range(1,len(list_train_avg_loss_incorrecta)+1), list_train_avg_loss_incorrecta, label=\"Train Loss Incorrecta\",linestyle='-', c='red')\n",
    "plt.plot(range(1,len(list_train_avg_loss)+1), list_train_avg_loss, label=\"Train Loss\",linestyle='-.', c='green')\n",
    "plt.plot(range(1,len(list_valid_avg_loss)+1), list_valid_avg_loss, label=\"Valid Loss\",linestyle='--', c='blue')\n",
    "plt.legend()\n",
    "#plt.title(\"\")\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.plot(range(1,len(list_train_precisiom_incorrecta)+1),  list_train_precisiom_incorrecta, label=\"Train Precision Incorrecta\",linestyle='-', c='red')\n",
    "plt.plot(range(1,len(list_train_precision)+1),  list_train_precision, label=\"Train Precision\",linestyle='-', c='green')\n",
    "plt.plot(range(1,len(list_valid_precision)+1), list_valid_precision, label=\"Valid Precision\",linestyle='--', c='blue')\n",
    "plt.legend()\n",
    "#plt.title(\"\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recolectar predicciones y etiquetas verdaderas\n",
    "from sklearn.metrics import confusion_matrix\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for X, y in valid_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        out = model(X)\n",
    "        preds = out.argmax(dim=1)\n",
    "        y_true.append(y.cpu().numpy())\n",
    "        y_pred.append(preds.cpu().numpy())\n",
    "\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "\n",
    "# matriz de confusión (conteos)\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(10)))\n",
    "\n",
    "# plot de la matriz de confusión (conteos)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "cax = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.colorbar(cax, ax=ax)\n",
    "classes = [label_dict[i] for i in range(10)]\n",
    "ax.set_xticks(np.arange(len(classes)))\n",
    "ax.set_yticks(np.arange(len(classes)))\n",
    "ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "ax.set_yticklabels(classes)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion matrix (counts)')\n",
    "# Anotar celdas\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# matriz de confusión normalizada por fila (recall por clase)\n",
    "cm_norm = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "cax = ax.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.colorbar(cax, ax=ax)\n",
    "ax.set_xticks(np.arange(len(classes)))\n",
    "ax.set_yticks(np.arange(len(classes)))\n",
    "ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "ax.set_yticklabels(classes)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion matrix (normalized by true class)')\n",
    "# Anotar celdas con porcentaje\n",
    "for i in range(cm_norm.shape[0]):\n",
    "    for j in range(cm_norm.shape[1]):\n",
    "        ax.text(j, i, f\"{cm_norm[i, j]:.2f}\",\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm[i, j] > 0.5 else \"black\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
